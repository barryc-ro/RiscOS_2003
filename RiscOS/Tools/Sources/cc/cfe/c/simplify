/*
 * simplify.c: tree optimisation phase of C compiler
 * Copyright (C) Codemist Ltd, 1988-1992.
 * Copyright (C) Acorn Computers Ltd., 1988-1990.
 * Copyright (C) Advanced RISC Machines Limited, 1990-1992.
 */

/*
 * RCS $Revision$  Codemist 13
 * Checkin $Date$
 * Revising $Author$
 */

#include "globals.h"
#include "simplify.h"
#include "sem.h"
#include "bind.h"
#include "aetree.h"
#include "builtin.h"
#include "store.h"
#include "aeops.h"
#include "errors.h"

/* AM nov-88: add code to allow mcrep fns to return a flag if the     */
/* object requires double alignment (e.g. some structs)               */
/* As a transition this is only enabled if alignof_double > alignof_int. */
/* AM 24-sep-87: created from sem.c, but the idea is soon to put tree */
/* replacement bits of cg.c in here too.                              */
/* Fix (unreleased) bug in *(int *)&x caused by over-keen optimisation */
/* Re-fix to kill bug in (LDS's) extern int a[]; return *a;            */

/* optimise0() is called after parsing an expression (generally by syn.c) */
/* which has been type-checked on the way by sem.c.  It does tree-like    */
/* optimisations, such as removing casts between objects which have the   */
/* same run-time representation (e.g. char* -> int* -> long)              */

/* expression optimiser:
 * Current aims for optimise():
 *  0) Remove s_invisible nodes introduced while parsing for error messages.
 *  1) reduce constant operations.  Most (e.g. 1+2) is done when
 *     building tree nodes, however, this is a good place to spot
 *     (x+1)+2, or (x.a).b.  Unfortunately this is not done yet so
 *     genpointer() in vargen.c and the CG both do similar things with the
 *     result of optimise().  Also turn x+0 to x soon.
 *  2) Transform &*x to x, and &x.a to &x + a.
 *  3) Regroup certain arithmetic expressions so as to allow more
 *     constant folding to occur.
 * The resultant tree is normalised to some extent.  E.g. & is only
 * applied to s_binder's.
 */

/* forward references... */
static Expr *optimisefnap(Expr *);

/* The following routine fixes LDS's bug (in 1.57) alluded to above.  */
/* It is not the final word, since we can clearly sometimes do better */
/* at detecting same pointers, but is intended to keep LDS happy with */
/* 'minimal change to code'.                                          */
static bool same_pointedto_types(Expr *e, Expr *e1)
{   TypeExpr *x = prunetype(typeofexpr(e));
    TypeExpr *x1 = prunetype(typeofexpr(e1));
    if (x == x1) return 1;
    /* Careful not to pass arrays/structs/fns to mcrepofexpr()      */
    /* (and thence sizeoftype which can issue error messages).      */
    /* The next line duplicates previous behaviour on t_fnap types. */
    if (h0_(x) == t_fnap && h0_(x1) == t_fnap)
        return 1;
    if (h0_(x) == t_subscript || h0_(x) == t_fnap || isclasstype_(x))
        return 0;
    if (h0_(x1) == t_subscript || h0_(x1) == t_fnap || isclasstype_(x1))
        return 0;
    return mcrepofexpr(e) == mcrepofexpr(e1);
}

bool is_same(Expr *a, Expr *b)
/* Expressions are considered the same if they compute the same value    */
/* and do not have any side-effects.                                     */
{
    AEop op;
    for (;;)
    {   if ((op = h0_(a)) != h0_(b)) return NO;
        if (isvolatile_expr(a) || isvolatile_expr(b)) return NO;
        switch (op)
        {
    case s_binder:
            return a == b;  /* volatile attribute already checked */
    case s_integer:
            return intval_(a) == intval_(b);
    case_s_any_string
    case s_floatcon:
            return a == b;  /* improve? */
    case s_dot:
            if (exprdotoff_(a) != exprdotoff_(b)) return NO;
            a = arg1_(a), b = arg1_(b);
            continue;
    case s_cast:
/* equivtype is probably too strong on the next line (we should         */
/* probably use a more machine-oriented test on types) but, before      */
/* changing it to the logical mcrepofexpr()=mcrepofexpr(), note that    */
/* casts on empty arrays to pointers can cause mcrepofexpr() to cc_err. */
/* @@@ Then again, perhaps is_same should be elided by cse.c now?       */
            if (!equivtype(type_(a), type_(b))) return NO;
    case s_addrof:
    case s_bitnot:
    case s_boolnot:
    case s_neg:
    case s_content:
    case s_monplus:
            a = arg1_(a);
            b = arg1_(b);
            continue;
    case s_andand:
    case s_oror:
    case s_equalequal:
    case s_notequal:
    case s_greater:
    case s_greaterequal:
    case s_less:
    case s_lessequal:
    case s_comma:
    case s_and:
    case s_times:
    case s_plus:
    case s_minus:
    case s_div:
    case s_leftshift:
    case s_or:
    case s_rem:
    case s_rightshift:
    case s_xor:
            if (!is_same(arg1_(a), arg1_(b))) return NO;
            a = arg2_(a);
            b = arg2_(b);
            continue;
    default:
            return NO;
        }
    }
}

static Expr *optimise_cast(Expr *e)
{   Expr *a1 = arg1_(e);
    int32 e_mode = mcrepofexpr(e), e_len;
    int32 a_mode = mcrepofexpr(a1), a_len;
    TypeExpr *te = princtype(typeofexpr(e));
    if (h0_(te) == t_content) te = typearg_(te);
    if (isfntype(te)) return e;  /* leave in casts to fn type */

/* a cast to the same type is ineffectual                                */
    if (e_mode == a_mode) return a1;

    e_len = e_mode & MCR_SIZE_MASK;
    e_mode >>= MCR_SORT_SHIFT;
    a_len = a_mode & MCR_SIZE_MASK;
    a_mode >>= MCR_SORT_SHIFT;

/* A cast is ineffectual if it does not change the m/c representation.   */
    if (e_mode < 2 && a_mode < 2)        /* cast of integral to integral */
    {
        if (e_mode == a_mode && e_len > a_len)
            return a1;         /* vacuous signedness-preserving widening */

/* Things like (int)(unsigned char)x are NOT vacuous, even though cg     */
/* will generate no code for them, because (double)(int)(unsigned char)x */
/* (double)(unsigned char)x and (double)(signed char)x are all different.*/
/* Even (unsigned int)(int) has a role: consider:-                       */
/* double d;  (double)(unsigned)(int)d; - what can be elided? Nothing!   */
    }

    if (h0_(a1) == s_cast)
    {
/* The inner casts are irrelevant in the following cases:                */
/*     (float) (double) x                                                */
/*     (char)  (short)  x   (char) (int) x   (short) (int) x             */
/* So are the corresponding unsigned cases.                              */
        if (e_mode <  2 && a_mode <  2 && e_len < a_len ||
            e_mode == 2 && a_mode == 2 && e_len < a_len)
        {
            arg1_(e) = arg1_(a1);
        }
    }
    return e;
}
/*
   AM: expressions such as  structfn().a[i]  are odd -- the ANSI spec seems
   to be very unclear about whether they illegally require the address
   of a function result.  To ease implementation all calls to structfn()
   are mapped to  (let t; t=structfn(),t)  but this transformation is
   undone if we know where the result is going, e.g. x = structfn().
*/

static SynBindList *new_binders;

static bool Div_SignBitClear(Expr *x, int32 rep) {
 /* We don't try too hard here at present: look for just widening of an
    unsigned type and positive constants.
  */
    if (h0_(x) == s_cast) {
        int32 xrep = mcrepofexpr(arg1_(x));
        return (xrep >> MCR_SORT_SHIFT) == 1 &&
               (xrep & MCR_SIZE_MASK) < (rep & MCR_SIZE_MASK);
    } else if (h0_(x) == s_integer)
        return intval_(x) > 0;
    else
        return NO;
}

static Expr *Div_CastToUnsigned(Expr *x, TypeExpr *t) {
/* (signbitclear(x, ..) is true) */
    return (h0_(x) == s_cast) ?
        mk_expr1(s_cast, t, arg1_(x)) :
        mkintconst(t, intval_(x), 0);
}

static Expr *NonPointerInteger(Expr const *e) {
/* e is an expr with h0_(e) == s_integer; return e if type_(e) is integral,
   else an integer of integral type with the same value as e.
 */
    TypeExpr *te = type_(e);
    if (h0_(te) != s_content) return (Expr *)e;
    return mkintconst(primtype_(TARGET_ADDRESSES_UNSIGNED ?
                        bitoftype_(s_int)|bitoftype_(s_unsigned) :
                        bitoftype_(s_int)|bitoftype_(s_signed)),
                      intval_(e), 0);
}

/* Beware highly: optimise currently side-effects the tree.
   Moreover, s_invisible and (more serious) nodes for ++, += etc can
   share sub-structure.  Only binders I believe in the latter case
   so that all should be OK.  Also the use of recursive use of optimise()
   in case s_addrof requires it to be idempotent.
*/

static int in_args = 0;

static Expr *optimise1(Expr *e, bool valneeded)
{   AEop op = h0_(e);
    Expr *e1;
    if (debugging(DEBUG_AETREE) && syserr_behaviour > 0) {
#ifndef NO_RETURN_EXPRESSIONS
      if (op != s_return) {
#endif
        cc_msg("optimise1: "); pr_expr(e);
        cc_msg(" of type "); pr_typeexpr(typeofexpr(e), 0);
        cc_msg("\n");
      }
    }
    switch (op)
    {
#ifdef PASCAL /*ECN*/
        case s_error:
            return mkintconst(te_int, 0, 0);
#endif
        case s_integer:
        case s_floatcon:
        case_s_any_string
#ifdef EXTENSION_VALOF
        case s_valof:
#endif
        case s_binder:
            break;
#ifdef C99_COMPLEX
        case s_complex:
            arg1_(e) = optimise1(arg1_(e), YES);
            arg2_(e) = optimise1(arg2_(e), YES);
            break;
#endif
        case s_invisible:
            e = optimise1(arg2_(e), valneeded);
            break;
        case s_throw:
            if (arg1_(e)) arg1_(e) = optimise1(arg1_(e), YES);
            break;
#ifndef NO_RETURN_EXPRESSIONS  /* perhaps soon dropped for C too.       */
        case s_return:
            e = arg1_(e);
            /* KJB super special - eliminate casts of structures, like  */
            /* signed long long -> unsigned long long                   */
            while (h0_(e) == s_cast)
            {   Expr *e1 = e;
                e = optimise_cast(e1);
                if (e == e1) break;
            }
            if (h0_(e) != s_fnap) { e = optimise1(e, YES); break; }
#endif
        case s_fnap:
            e = optimisefnap(e);
#ifndef NO_RETURN_EXPRESSIONS
            if (op == s_return) break;
#endif
            /*
             * Does this function return a struct ?.  If so carry out a
             * transformation from 'fn()' to (let x; x=fn(),x)'.
             * Note: Temp binders are allocated in optimise0().
             * CPLUSPLUS: beware _ctor/_dtor and temps.
             */
            if ((mcrepofexpr(e) >> MCR_SORT_SHIFT) == 3)
            {   TypeExpr *t = typeofexpr(e);
                Binder *gen = gentempbinder(t);
                new_binders = mkSynBindList(new_binders, gen);
                e = mk_expr2(s_assign, t, (Expr*)gen, e);
                if (valneeded)
                    e = mk_expr2(s_comma, type_(e), e, (Expr*) gen);
            }
            break;
        case s_init:
        case s_assign:
            arg1_(e) = optimise1(arg1_(e), YES);
/* Nastiness here in C++: consider:                                     */
/*      class B: virtual A { ...};                                      */
/*      class D:B { ... };                                              */
/*      B f() { ... }                                                   */
/*      main() { D d; B &b = d; b = f(); }                              */
/* In general f() will CONSTRUCT a B in its implicit extra arg.         */
/* It must also construct vbases/vfns for a B since it does not know    */
/* the use the caller will make of it.  Hence eliding the b = f()       */
/* would corrupt b's and hence d's vbases/vfns.                         */
/* However, we could remove a 'struct_result = f()' copy ctor.          */
/* Use 'isproperclass()' to determine this.                             */
/* @@@ hmm, for such a b with a vbase, we would have generated a fncall */
/* instead of an assign already (or a partial assign).                  */
            if (h0_(arg2_(e)) == s_fnap &&
/* AM finds it hard to believe the following disjunction can fail.      */
                (h0_(arg1_(e)) == s_binder  ||
                 h0_(arg1_(e)) == s_content ||
                 h0_(arg1_(e)) == s_dot))               /* s_dotstar?   */
            {
/* Specifically avoid the temp introduction (case s_fnap above) for     */
/* struct-returning functions whose result is directly                  */
/* assigned to a binder or via s_content...                             */
                arg2_(e) = optimisefnap(arg2_(e));
            } else {
                Expr *a1 = arg1_(e),
                     *a2 = optimise1(arg2_(e), YES);
                if ( !valneeded &&
                     h0_(a2) == s_cast &&
                     mcrepofexpr(arg1_(a2)) < MCR_SORT_FLOATING &&
                     (mcrepofexpr(a1) & MCR_SIZE_MASK) == 1 &&
                     h0_(a1) != s_binder)
                  a2 = arg1_(a2);
                arg2_(e) = a2;
            }
            break;
        case s_addrof:
            e1 = optimise1(arg1_(e), YES);
            if (h0_(e1) == s_comma || h0_(e1) == s_let || h0_(e1) == s_cmplit)
            {   /* & (a, b) -> (a, & b); & (let x in e) -> (let x in & e) */
                e = mk_expr2(h0_(e1), type_(e), arg1_(e1),
                        optimise1(mk_expr1(s_addrof, type_(e), arg2_(e1)), YES));
                break;
            }
            if (h0_(e1) == s_assign)
            {   /* & a = b -> (a = b, & a) */
/* @@@ AM: this is wrong for side-effects in 'a'!!!?                    */
                e = mk_expr2(s_comma, type_(e), e1,
                    optimise1(mk_expr1(s_addrof, type_(e), arg1_(e1)), YES));
                break;
            }
/* The following line fixes a problem that shouldn't occur, as &(cast)   */
/* is illegal. However, it can occur because we recover from ++(type *)p */
/* even though ANSI disallow. Either way, a diagnostic has already been  */
/* issued (or a warning in -pcc mode) so there seems to be little excuse */
/* for generating a syserr(). Note that it also legitimises &(cast)var;  */
/* but not silently. Win some, lose some.                                */
            while (h0_(e1) == s_cast) e1 = arg1_(e1);
            arg1_(e) = e1;
            if (h0_(e1) == s_content) { e = arg1_(e1); break; }
            if (isstring_(h0_(e1))) {
                e = e1;                     /* cg thinks addr already */
                break;
            }
/* Even though s_dot is not optimised out in general it needs to be      */
/* looked after in a special way when I do something like &(a . b)       */
/* Note this can only be legal if a as an lvalue so the result (&a)+nb   */
/* will still be OK - so things like structure-returning functions are   */
/* not involved here.                                                    */
/* AM Nov 92: Hmm, struct fn results now have temps, so OK?              */
            if (h0_(e1) == s_dot) {
                e = mk_expr2(s_plus, type_(e),
/* beware - this means optimise() is invoked twice on arg1_(e) */
                      optimise1(mk_expr1(s_addrof, type_(e), arg1_(e1)), YES),
                      mkintconst(te_int, exprdotoff_(e1), 0));
                break;
            }
            if ((h0_(e1) != s_binder) && (h0_(e1) != s_comma)
#ifdef SOFTWARE_FLOATING_POINT
                && !(software_floating_point_enabled && h0_(e1) == s_floatcon)
#endif
#ifdef SOFTWARE_LONG_LONG
                && !(h0_(e1) == s_integer && islonglong_type(type_(e1)))
#endif
#ifdef C99_COMPLEX
                && h0_(e1) != s_complex
#endif
               )
                /*
                 * Check that we have a binder for &.  However, beware we
                 * might have a structure returning function which will
                 * get transformed above.  Should test for this fully but
                 * testing for s_comma is probably ok !.
                 */
                syserr("optimise&(%ld,$s)", (long)h0_(e1), h0_(e1));
                /* syserr(syserr_optimise, (long)h0_(e1)); */
            break;
#ifdef CPLUSPLUS
        case_content:
#endif
        case s_content:  /* get rid of extra &'s and *'s introduced above */
            arg1_(e) = e1 = optimise1(arg1_(e), YES);
            if (h0_(e1) == s_addrof &&
                /* the next line ensures *(int*)&d -> d only if types match */
                same_pointedto_types(e, arg1_(e1)))
              e = arg1_(e1);
            break;
#ifndef CPLUSPLUS       /* Nov 92: leave old code for C for now.        */
        case s_dot:  /* s_arrow already removed */
            e1 = optimise1(arg1_(e), YES);
            if (h0_(e1) == s_dot) {
                exprdotoff_(e) += exprdotoff_(e1);
                e1 = arg1_(e1);
            } else if (h0_(e1) == s_content) {
                /* turn *(&foo + x) . y into &foo . (x+y) */
                Expr *e2 = arg1_(e1);
                if (h0_(e2) == s_plus && h0_(arg2_(e2)) == s_integer) {
                    exprdotoff_(e) += intval_(arg2_(e2));
                    e1 = mk_expr1(s_content, type_(e1), arg1_(e2));
                }
            }
            arg1_(e) = e1;
            break;
#else
        case s_dot:     /* replace s_dot with s_content */
/* NB. all s_dot code can be removed from cg.                           */
            if ((mcrepofexpr(arg1_(e)) & MCR_SORT_MASK) != MCR_SORT_STRUCT)
            {   /* Fetching a word from a single-word struct!.          */
                /* Probably just e (see cg_content_for_dot).            */
                /* @@@ Check 'volatile'.                                */
                /* Insert cast so types are right (e.g. for cg_fnap).   */
                /* This code wouldn't work for a byte in a union!       */
                if (mcrepofexpr(arg1_(e)) == 0x00000004 && exprdotoff_(e)==0)
                {   e = optimise1(mk_expr1(s_cast, type_(e), arg1_(e)), YES);
                    break;
                }
                else
                    syserr("optimise(dot one word)");
            }
            else
            {   TypeExpr *tp = ptrtotype_(type_(e));
                Expr *e2 = mkintconst(te_int, exprdotoff_(e), 0);
/* Beware, assumes optimise(s_fnap(struct)) is address takeable!.       */
                e = mk_expr1(s_content, type_(e),
                      mk_expr2(s_plus, tp,
                        mk_expr1(s_addrof, tp, arg1_(e)), e2));
            }
            goto case_content;
        case s_dotstar:
            if ((mcrepofexpr(arg1_(e)) >> MCR_SORT_SHIFT) != 3)
            {   /* Fetching a word from a single-word struct!.          */
                /* Replace with (e2, e1), i.e. eval e2 for side-effects */
                /* and return e1.  Implies p->*NULL == p->*(&S::s)!!    */
                /* This code wouldn't work for a byte in a union!       */
                if (mcrepofexpr(arg1_(e)) == 0x00000004)
                {   e = optimise1(
                            mk_expr2(s_comma, type_(e), arg2_(e), arg1_(e)),
                            YES);
                    break;
                }
                else
                    syserr("optimise(dotstar one word)");
            }
            else
            {   TypeExpr *tp = ptrtotype_(type_(e));
                Expr *e2 = arg2_(e);
                /* follow [ES] suggestion for ptr-to-member rep.        */
                e2 = mk_expr2(s_minus, typeofexpr(e2), e2,
                              mkintconst(te_int, 1, 0));
/* Beware, assumes optimise(s_fnap(struct)) is address takeable!.       */
                e = mk_expr1(s_content, type_(e),
                      mk_expr2(s_plus, tp,
                        mk_expr1(s_addrof, tp, arg1_(e)), e2));
            }
            goto case_content;
#endif
        case s_cond:
            e1 = e;
            arg1_(e) = optimise1(arg1_(e), YES);
            if ((mcrepofexpr(e) >> MCR_SORT_SHIFT) == 3)
            {   /* The expression is struct-valued */
                TypeExpr *te = type_(e);
                TypeExpr *pt = ptrtotype_(te);
                type_(e) = pt;
                e1 = mk_expr1(s_content, te, e);
                arg2_(e) = mk_expr1(s_addrof, pt, arg2_(e));
                arg3_(e) = mk_expr1(s_addrof, pt, arg3_(e));
            }
            arg2_(e) = optimise1(arg2_(e), valneeded);
            arg3_(e) = optimise1(arg3_(e), valneeded);
            e = e1;
            break;
        case s_let:
        case s_cmplit:
            arg2_(e) = optimise1(arg2_(e), valneeded);
            break;
        case s_cast:
            arg1_(e) = optimise1(arg1_(e), valneeded && mcrepofexpr(e) != 0);
            e = optimise_cast(e);
            break;
        case s_div:
        case s_and:
        case s_times:
        case s_plus:
        case s_or:
        case s_xor:        /* these are both commutative and associative */
        case s_minus:      /* this isn't -- see goto below */
            {   Expr *a1 = optimise1(arg1_(e), YES);
                Expr *a2 = optimise1(arg2_(e), YES);
/* floating point tree optimisations moved here from cfe/sem.c          */
/* beware IEEE conformance, in that we optimise X+0.0 to X (NaN/-0).    */
                if (op == s_minus)
                {   if (is_fpzero(a1))
                        { h0_(e) = s_neg; arg1_(e) = a2; break; }
                    if (is_fpzero(a2)) { e = a1; break; }
                    if (is_intzero(a2)) { e = a1; break; }
                    if (is_intzero(a1)) { e = mkunary(s_neg, a2); break; }
                    if (h0_(a2) == s_neg)
                        /* a - -b => a + b */
                        h0_(e) = s_plus, a2 = arg1_(a2);
                    /* should also do -a - b => -(a + b)? */
                    goto symmetric_done;
                }
                if (op == s_div) {
                /* We deliberately avoid doing anything with 0/x here  */
                /* else a divide by zero could go undetected at runtime*/
                /* (we could turn it into (divcheck(x), 0), but        */
                /* probably to little gain)                            */
                    TypeExpr *t = prunetype(type_(e));
                    int32 rep = mcrepoftype(t);
                    /* Turn a signed division whose operands are both  */
                    /* known to be positive into an unsigned division  */
                    /* whose result is cast to signed. Rationale: s/w  */
                    /* implementations of unsigned divide are likely to*/
                    /* be a little faster, and if the divisor is a     */
                    /* constant power of two the improvement is        */
                    /* substantial                                     */
                    if ((rep & MCR_SORT_MASK) == 0 &&
                        Div_SignBitClear(a1, rep) &&
                        Div_SignBitClear(a2, rep) &&
                        h0_(t) == s_typespec) {
                        TypeExpr *t1 = primtype_(typespecmap_(t) | bitoftype_(s_unsigned));
                        a1 = Div_CastToUnsigned(a1, t1);
                        a2 = Div_CastToUnsigned(a2, t1);
                        e = optimise1(mk_expr1(s_cast,
                                               t,
                                               mk_expr2(s_div, t1, a1, a2)),
                                      valneeded);
                        break;
                    }
                    if (h0_(a2) == s_integer) {
                        if (h0_(a1) == s_div && h0_(arg2_(a1)) == s_integer) {
                            a2 = mkbinary(s_times, arg2_(a1), a2);
                            a1 = arg1_(a1);
                        }
                        if (intval_(a2) == 1) { e = a1; break; }
                        if (intval_(a2) == -1 &&
                            (mcrepofexpr(e) >> MCR_SORT_SHIFT) == 0) {
                            e = mkunary(s_neg, a1); break;
                        }
                    }
                    goto symmetric_done;
                }
/* N.B. symmetric things only until symmetric_done...                   */
                if (h0_(a1) == s_integer || h0_(a1) == s_floatcon)
                {   Expr *w = a1;       /* move any const to arg2       */
                    a1 = a2;            /* note both can't be consts.   */
                    a2 = w;
                }
                if (op == s_and)
                {   if (is_intzero(a2)) { e = mkintconst(type_(e), 0, 0); break; }
                    if (is_intminusone(a2)) { e = a1; break; }
                }
                if (op == s_or)
                {   if (is_intzero(a2)) { e = a1; break; }
                    if (is_intminusone(a2)) { e = mkintconst(type_(e), -1, 0); break; }
                }
                if (op == s_xor)
                {   if (is_intzero(a2)) { e = a1; break; }
                    if (is_intminusone(a2)) { e = mkunary(s_bitnot, a1); break; }
                }
                if (op == s_plus)
                {   if (is_fpzero(a2)) { e = a1; break; }
                    if (is_intzero(a2)) { e = a1; break; }
                }
                if (op == s_times)
                {   if (is_fpone(a2)) { e = a1; break; }
                    if (is_fpminusone(a2))
                        { h0_(e) = s_neg; arg1_(e) = a1; break; }
                    if (is_intzero(a2)) { e = mkintconst(type_(e), 0, 0); break; }
                    if (is_intone(a2)) { e = a1; break; }
                    if (is_intminusone(a2)) { e = mkunary(s_neg, a1); break; }
                    if (h0_(a2) == s_integer) {
                        if ((h0_(a1) == s_plus || h0_(a1) == s_minus) &&
                            h0_(arg2_(a1)) == s_integer)
                            return optimise1(mkbinary(h0_(a1),
                                                      mkbinary(s_times, arg1_(a1), a2),
                                                      mkbinary(s_times, arg2_(a1), a2)),
                                             valneeded);
                    }
                }
                if (h0_(a1) == op || (op == s_plus && h0_(a1) == s_minus)) {
                    if (h0_(arg2_(a1)) == s_integer) {
                        if (h0_(a2) == s_integer) {
                         /* ((a op n) op m)  => a op (n op m) */
                /* We call mkbinary here to do the constant reduction on (n op m);
                 * care is needed in case one of n and m has a pointer type (as
                 * for example after
                 *   struct x { int a, b[]; }; offsetof(struct x, b[i+1]);
                 * which sem.c manages to reduce only to
                 *   (int *)(0 . 4) + ((i + 1) * 4)
                 * and which eventually arrives here as
                 *   ((i * 4) + 4<int>) + 4<int *>
                 * If we leave the type of the second 4 unchanged, mkbinary will
                 * insert an unwanted extra multiplication by 4 for the first.
                 */
                            a2 = mkbinary(h0_(a1), NonPointerInteger(a2),
                                                   NonPointerInteger(arg2_(a1)));
                            a1 = arg1_(a1);
/* This can convert (e.g.)  (a + 1) + (-1) into  (a + 0) which does not  */
/* get simplified further here. The codegenerator will treat this as     */
/* just a, and the seemingly spurious +0 will serve to preserve the      */
/* proper type of the expression.                                        */
                        } else if (h0_(a2) == op && h0_(arg2_(a2)) == s_integer) {
                         /* ((a op1 n) op (b op m)) => (a op b) op (m op1 n)) */
                         /* op == op1 or op == +, op1 == - */
                            Expr *x1 = a1;
                            a1 = mk_expr2(op, type_(e), arg1_(x1), arg1_(a2));
                            a2 = mkbinary(h0_(x1), NonPointerInteger(arg2_(a2)),
                                                   NonPointerInteger(arg2_(x1)));
                        } else if ((op == s_plus && h0_(a2) == s_minus) && h0_(arg2_(a2)) == s_integer) {
                            Expr *x1 = a1;
                            a1 = mk_expr2(op, type_(e), arg1_(x1), arg1_(a2));
                            if (h0_(x1) == s_minus)
                                h0_(e) = op = s_minus;
                            a2 = mkbinary(op == s_minus ? s_plus : s_minus,
                                            NonPointerInteger(arg2_(x1)),
                                            NonPointerInteger(arg2_(a2)));
                        } else {
                            AEop op2 = h0_(a1);
                            Expr *x1 = a1;
                            a1 = mk_expr2(op, type_(e), arg1_(x1), a2);
                            a2 = arg2_(x1);
                            h0_(e) = op = op2;
                        }
                    }
                }
                if ((h0_(a2) == op || (op == s_plus && h0_(a2) == s_minus)) &&
                    h0_(arg2_(a2)) == s_integer) {
                    AEop op2 = h0_(a2);
                    a1 = mk_expr2(op, type_(e), a1, arg1_(a2));
                    a2 = arg2_(a2);
                    h0_(e) = op = op2;
                }
                /* (a & ~k) | k gets transformed here to a | k, to cheer up
                 * a common bitfield-setting case
                 */
                if (op == s_or && h0_(a2) == s_integer &&
                    h0_(a1) == s_and && h0_(arg2_(a1)) == s_integer &&
                    intval_(a2) == ~intval_(arg2_(a1)))
                    a1 = arg1_(a1);

                if (op == s_times && h0_(a2) == s_integer)
                {   if (h0_(a1) == s_leftshift && h0_(arg2_(a1)) == s_integer)
                    {   int32 shift = intval_(arg2_(a1));
                        int32 n1 = intval_(a2), n2 = ((unsigned32)1 << shift);
                        int32 n3 = n1 * n2;
                        if ((n1 ^ n3 >= 0) && (n3 / n2 == n1)) {
                            a1 = arg1_(a1);
                            a2 = mkintconst(te_int, n3, 0);
                        }
                    }
                    if (h0_(a1) == s_neg) {
                        e = mkunary(s_neg, mkbinary(s_times, arg1_(a1), a2));
                        break;
                    }
                }
                if (op == s_plus) {
                /* a + -b => a - b; -a + b => b-a */
                    if (h0_(a2) == s_neg)
                        h0_(e) = s_minus, a2 = arg1_(a2);
                    else if (h0_(a1) == s_neg) {
                        Expr *t = a2;
                        h0_(e) = s_minus, a2 = arg1_(a1);
                        a1 = t;
                    }
                }
symmetric_done: arg1_(e) = a1;
                arg2_(e) = a2;
            }
            break;
#ifdef RANGECHECK_SUPPORTED
        case s_rangecheck:
            if (arg3_(e) != NULL) arg3_(e) = optimise1(arg3_(e), YES);
            /* drop through */
        case s_checknot:
            arg1_(e) = optimise1(arg1_(e), YES);
            if (arg2_(e) != NULL) arg2_(e) = optimise1(arg2_(e), YES);
            break;
#endif
        case s_equalequal:
        case s_notequal:
            /* in comparison of signed char for (in)equality against positive
               constant <= SCHAR_MAX, cast the signed char to unsigned char
               (in the belief that zero extension is cheaper than sign extn).
             */
            {   Expr *a1 = optimise1(arg1_(e), YES);
                Expr *a2 = optimise1(arg2_(e), YES);
                if (h0_(a1) == s_integer) { Expr *w = a1; a1 = a2; a2 = w; }
                if (h0_(a2) == s_integer &&
                    intval_(a2) >= 0 && intval_(a2) < (1 << 7))
                {   TypeExpr *t = prunetype(typeofexpr(a1));
                    if (h0_(t) == s_typespec) {
                        SET_BITMAP tm = typespecmap_(t);
                        if ((tm & (bitoftype_(s_char)|bitoftype_(s_signed))) ==
                                  (bitoftype_(s_char)|bitoftype_(s_signed)))
                        {   tm ^= (bitofstg_(s_signed)|bitofstg_(s_unsigned));
                            a1 = optimise1(mkcast(s_cast, a1, primtype_(tm)), YES);
                        }
                    }
                }
                arg1_(e) = a1;
                arg2_(e) = a2;
                break;
            }
        default:
            if (ismonad_(op))
                arg1_(e) = optimise1(arg1_(e), YES);
            else if (isdiad_(op))
                arg1_(e) = optimise1(arg1_(e), YES),
                arg2_(e) = optimise1(arg2_(e), YES);
            else syserr(syserr_optimise1, (long)op);
            break;
    }
    if (debugging(DEBUG_AETREE) && syserr_behaviour > 0) {
#ifndef NO_RETURN_EXPRESSIONS
      if (op != s_return) {
#endif
        cc_msg("optimise1= "); pr_expr(e);
        cc_msg(" of type "); pr_typeexpr(typeofexpr(e), 0);
        cc_msg("\n");
      }
    }
    return e;
}

static SynBindList *optimiselist(ExprList *x)
{   SynBindList *letbindings = NULL;
    for (; x != 0; x = cdr_(x)) {
        Expr *e = exprcar_(x);
        if (h0_(e) == s_fnap) {
        /* Avoid introduction of the temporary done by case s_fnap in        */
        /* optimise1 for structure-returning functions (produces an          */
        /* unnecessary and hard to remove structure copy). cg will cause the */
        /* called function to return its results directly to the argument    */
        /* place                                                             */
            e = optimisefnap(e);
        } else if (h0_(e) == s_let && h0_(arg2_(e)) == s_fnap) {
            arg2_(e) = optimisefnap(arg2_(e));
        } else {
            if ((mcrepofexpr(e) & MCR_SORT_MASK) == MCR_SORT_STRUCT &&
                h0_(e) == s_let && h0_(arg2_(e)) == s_comma) {
                SynBindList *bl = exprletbind_(e);
                Expr *a2 = arg2_(e);
                if (bl->bindlistcdr == NULL &&
                    (Expr *)bl->bindlistcar == arg2_(a2)) {
                    letbindings = mkSynBindList(letbindings, bl->bindlistcar);
                    e = a2;
                }
            }
            in_args++;
            e = optimise1(e, YES);
            in_args--;
        }
        exprcar_(x) = e;
    }
    return letbindings;
}

static Expr *optimisefnap(Expr *e) {
    SynBindList *b;
    arg1_(e) = optimise1(arg1_(e), YES);
    b = optimiselist(exprfnargs_(e));
    return (b == NULL) ? e : mk_exprlet(s_let, type_(e), b, e);
}

#define U_Read 1
#define U_Write 2

typedef struct BindUseList BindUseList;
struct BindUseList {
     BindUseList *cdr;
     Binder *b;
     int use;
};

/* Very nice, AM had wanted to do something like this for some time!    */

static void warnifusage(BindUseList *bu, Binder *b, int flag) {
    for (; bu != NULL; bu = cdr_(bu))
        if (bu->b == b && (bu->use & flag)) {
            if (bu->use & flag & U_Read)
                cc_warn(warn_usage_rw, b);
            else
                cc_warn(warn_usage_ww, b);
            return;
        }
}

static BindUseList *mergeuselists(BindUseList *b1, BindUseList *b2, BindUseList *oldb) {
    if (b1 == oldb)
        return b2;
    else if (b2 != oldb) {
        BindUseList *p = b1, *next;
        for (; (next = cdr_(p)) != oldb; p = next) /* nothing */;
        cdr_(p) = b2;
     }
     return b1;
}

static BindUseList *checkvaruse(BindUseList *b, Expr *e) {
if (debugging(DEBUG_AETREE) && syserr_behaviour > 0) {
  cc_msg("checkvaruse "); pr_expr(e); cc_msg("\n");
}
    switch (h0_(e)) {
    default: if (h0_(e) > s_binder)
               cc_warn("syserr soon: checkvar use %ld", h0_(e));
    case s_addrof:              /* not if &a[b]; though! */
             break;
/* Hmm, I'd rather do via isdiad_ ismonad_, possible? */
    case s_binder:
        warnifusage(b, (Binder *)e, U_Write);
        b = (BindUseList *)syn_list3(b, e, U_Read);
        break;

    case s_andequal: case s_orequal: case s_xorequal:
    case s_timesequal: case s_plusequal: case s_minusequal: case s_divequal:
    case s_idivequal: case s_remequal:
    case s_leftshiftequal: case s_rightshiftequal:
    case s_assign:
        {   Expr *lhs = arg1_(e);
            b = checkvaruse(b, arg2_(e));
            if (h0_(lhs) != s_binder)
                b = checkvaruse(b, lhs);
            else {
                warnifusage(b, (Binder *)lhs, U_Write);
                b = (BindUseList *)syn_list3(b, lhs, U_Write);
            }
            break;
        }
    case s_plusplus: case s_minusminus: case s_postinc: case s_postdec:
    case s_displace:
        {   Expr *a1 = arg1_(e);
            if (h0_(a1) != s_binder)
                b = checkvaruse(b, a1);
            else {
                warnifusage(b, (Binder *)a1, U_Read+U_Write);
                b = (BindUseList *)syn_list3(b, a1, U_Write);
            }
            break;
        }
    case s_subscript:
    case s_equalequal: case s_notequal:
    case s_greater: case s_greaterequal: case s_less: case s_lessequal:
    case s_less_ieee: case s_lessequal_ieee: case s_greater_ieee: case s_greaterequal_ieee:
    case s_lessgreater_ieee: case s_unordered_ieee:
    case s_plus: case s_minus: case s_times: case s_div:
    case s_ptrdiff:
    case s_idiv: case s_rem: case s_power:
    case s_and: case s_or: case s_xor: case s_leftshift: case s_rightshift:
    case s_dotstar:
#ifdef C99_COMPLEX
    case s_complex:
#endif
        b = checkvaruse(b, arg2_(e));
        /* drop though */

#ifndef NO_RETURN_EXPRESSIONS
    case s_return:
#endif
    case s_cast: case s_invisible:
    case s_content:
    case s_monplus: case s_neg: case s_bitnot: case s_boolnot:
    case s_dot:
    case s_ctor:                /* a monad protecting a s_comma */
        b = checkvaruse(b, arg1_(e));
    case_s_any_string
        break;

    case s_throw:
        if (arg1_(e)) b = checkvaruse(b, arg1_(e));
        break;

    case s_let:
    case s_cmplit:
        b = checkvaruse(b, arg2_(e));
        break;

    case s_andand: case s_comma: case s_oror:
        {   BindUseList *b1 = checkvaruse(b, arg1_(e));
            BindUseList *b2 = checkvaruse(b, arg2_(e));
            b = mergeuselists(b1, b2, b);
            break;
        }
    case s_fnap:
        {   ExprList *args = exprfnargs_(e);
            for (; args != NULL; args = cdr_(args))
                b = checkvaruse(b, exprcar_(args));
            b = checkvaruse(b, arg1_(e));
            break;
        }
    case s_cond:
        {   BindUseList *b1 = checkvaruse(b, arg2_(e));
            BindUseList *b2 = checkvaruse(b, arg3_(e));
            BindUseList *b3 = checkvaruse(b, arg1_(e));
            b = mergeuselists(mergeuselists(b1, b2, b), b3, b);
            break;
        }
    }

if (debugging(DEBUG_AETREE) && syserr_behaviour > 0) {
  BindUseList *p;
  cc_msg("=>");
  for (p = b; p != NULL; p = cdr_(p))
    cc_msg(" $b,%s", p->b, (p->use-1)*3+"R\0\0W\0\0RW");
  cc_msg("\n");
}
    return b;
}

Expr *optimise0(Expr *e)
/* exported - yields 0 if a 'serious' error message has already been
   printed (we know this by the s_error at the top of the tree).
   The semantic routines *SHOULD* all be strict in s_error.
*/
{   Expr *res;
    if (h0_(e) == s_error) return 0;
    checkvaruse(NULL, e);
    new_binders = 0;
    res = optimise1(e, YES);
    /*
     * If there are any structure returning functions allocate temp binders
     * here at the root of the expression tree.
     */
    return (new_binders == 0) ? res :
        mk_expr2(s_let, typeofexpr(res), (Expr*)new_binders, res);
}

/* The following routine detects when a struct/union has suitable members
   that it can be considered an integer and thus be slavable in a register.
   A first requirement is that all (union, total for struct) members are
   size 4 or less.  The total size of 4 has been checked by caller.
   However, not all such structs are suitable - consider
   struct { short a,b;}.  Moreover since C requires that the address of
   struct/union first element is the same as the address of the
   aggregate this poses problems (and that this problem extends to
   non-address-taken structs via assignment, this means that on some
   machines we cannot put  struct { char c; } in a register.
   However,  struct { int c:8;} is always OK.
   For now the rule is that every sub-object only contains int/enum/pointer.
*/
static bool integerlikestruct(TagBinder *b)
{   ClassMember *l;
    if (!integerlike_enabled) return 0;
    for (l = tagbindmems_(b); l != 0; l = memcdr_(l))
    {
#ifdef CPLUSPLUS
        if (!is_datamember_(l))
        {   /* Reject non-static member functions (particularly ctors)  */
            /* since we can't just copy corresponding objects: consider */
            /* e.g. class A { A *p; A() { p = this; }};                 */
            if (!(bindstg_(l) & (bitofstg_(s_static)|bitofstg_(s_typedef))))
                /* need a macro for non-static member fn?               */
                return 0;
        }
        else
#endif
        if (isbitfield_type(memtype_(l)))
        {   /* bits are OK (sem.c turns to int)                         */
            /* @@@ beware PCC mode/C++ char bitfields &c                */
        }
        else
        {   TypeExpr *t = princtype(memtype_(l));
            SET_BITMAP m;
            switch (h0_(t))
            {   default: return 0;                  /* array not OK     */
                case t_content: break;              /* pointers are OK  */
                case t_ref:     break;              /* and so are refs  */
                case t_vla:     break;              /* and VLAs         */
                case t_fnap:    break;              /* so are mem fns   */
                case s_typespec:
                    m = typespecmap_(t);
                    switch (m & -m)
                    {   default: return 0;          /* includes char    */
                        case bitoftype_(s_int):
                        case bitoftype_(s_enum):
                            if (m & bitoftype_(s_short)) return 0;
                            break;                  /* 4 bit int ok     */
                        case bitoftype_(s_struct):
                        case bitoftype_(s_class):
                        case bitoftype_(s_union):
                            if (!integerlikestruct(typespectagbind_(t)))
                                return 0;
                            break;
                    }
                    break;
            }
        }
    }
    return 1;
}

static int32 mcrepofexpr1(Expr *e)
/* keep in step with sizeoftype */
{   TypeExpr *x = prunetype(typeofexpr(e));
    SET_BITMAP m;
    switch (h0_(x))
    {
case s_typespec:
        m = typespecmap_(x);
        switch (m & -m)    /* LSB - unsigned/long etc. are higher */
        {
    case bitoftype_(s_char):
            if ((m & (bitoftype_(s_signed)|bitoftype_(s_unsigned))) == 0)
                m |= (feature & FEATURE_SIGNED_CHAR) ?
                         bitoftype_(s_signed) : bitoftype_(s_unsigned);
            /* drop through */
    case bitoftype_(s_int):
    case bitoftype_(s_longlong):
    case bitoftype_(s_enum):
            {
                return sizeoftype(x) +
                    (m & bitoftype_(s_unsigned) ?
                     m & bitoftype_(s_signed) ? 0x4000000 : 0x1000000 : 0);
            }
    case bitoftype_(s_double):
            {   int32 n = sizeoftype(x);
#ifdef C99_COMPLEX
                if (m & bitoftype_(s_complex))
                    return (alignof_double > alignof_int && n == 2*sizeof_double) ?
                           0x3000000 + MCR_ALIGN_DOUBLE + n : 0x3000000 + n;
#endif
/* The tests here generate no code if alignof_double==alignof_int.      */
                return (alignof_double > alignof_int && n == sizeof_double) ?
                       0x2000000 + MCR_ALIGN_DOUBLE + n : 0x2000000 + n;
            }
    case bitoftype_(s_struct):
    case bitoftype_(s_class):
    case bitoftype_(s_union):
            {   int32 n = sizeoftype(x);
                if (n == 4 && integerlikestruct(typespectagbind_(x)))
                    return 0x0000000 + n;
                else
                    return (alignof_double > alignof_int &&
                            alignoftype(x) == alignof_double) ?
                           0x3000000 + MCR_ALIGN_DOUBLE + n : 0x3000000 + n;
            }
    case bitoftype_(s_void):
                /*
                 * BEWARE: Other parts of the compiler use mcrepoftype==0
                 * as a test for 'void' types.
                 */
                return 0x0000000;
    default: break;
            }
            /* drop through */
default:
/*      case t_fnap: */
            syserr(syserr_mcrepofexpr, (long)h0_(x),(long)typespecmap_(x));
            return 0x0000000 + sizeof_ptr;
case t_subscript:
/* The following checks that restriction that mcrepofexpr() spiritually     */
/* should never be applied to array typed expressions.  Two exceptions:     */
/* s_binder's (for flowgraf.c sizing) and s_strings (optimise removes their */
/* implicit '&').                                                           */
            if (h0_(e)!=s_binder && !isstring_(h0_(e)))
                syserr(syserr_mcreparray, (long)h0_(e));
            if (h0_(e) == s_binder)
            {   int32 n = sizeoftype(x);
                if (n & ~MCR_SIZE_MASK)
                    cc_err(simplify_err_outsizearray, (Binder *)e),
                    n = MCR_SIZE_MASK;
                return (alignof_double > alignof_int &&
                        alignoftype(x) == alignof_double) ?
                       0x3000000 + MCR_ALIGN_DOUBLE + n : 0x3000000 + n;
            }
            /* s_string falls into pointer code */
case t_content:
case t_ref:
case t_vla:
            return TARGET_ADDRESSES_UNSIGNED ? 0x1000000 + sizeof_ptr :
                                               0x0000000 + sizeof_ptr;
    }
}

int32 mcrepofexpr(Expr *e)
{
#ifdef CPLUSPLUS
    /* temp. nasty hack for optimise(s_dot/s_dotstar) and cppfe/vargen  */
    /* solution: make type of datasegment struct-of-size 0x00ffffff?    */
    int32 r = (e == (Expr *)datasegment || e == (Expr *)constdatasegment)
              ? 0x03000000 : mcrepofexpr1(e);
#else
    int32 r = mcrepofexpr1(e);
#endif
#ifdef SOFTWARE_FLOATING_POINT
/* Fake floating point values so that they are thought of as structures. */
    if (software_floating_point_enabled) {
        if (r == MCR_SORT_FLOATING + 4)
            return MCR_SORT_SIGNED + 4;
        if (r == MCR_SORT_FLOATING + 8 ||
            r == MCR_SORT_FLOATING + MCR_ALIGN_DOUBLE + 8)
            return MCR_SORT_STRUCT + 8;
    }
#endif
#ifdef SOFTWARE_LONG_LONG
    if ((r & MCR_SIZE_MASK) == sizeof_longlong &&
        ((r & MCR_SORT_MASK) == MCR_SORT_SIGNED ||
         (r & MCR_SORT_MASK) == MCR_SORT_UNSIGNED ||
         (r & MCR_SORT_MASK) == MCR_SORT_PLAIN))
        return MCR_SORT_STRUCT + sizeof_longlong;
#endif
    return r;
}

int32 mcrepoftype(TypeExpr *t)
{
/* This returns the machine representation of a type. Done by forgery of */
/* an expression and a call to mcrepofexpr().                            */
    return mcrepofexpr(mk_expr2(s_invisible, t, 0, 0));
}

bool returnsstructinregs_t(TypeExpr *t) {
    if (typefnaux_(t).flags & bitoffnaux_(s_structreg)) {
        int32 resultwords = sizeoftype(typearg_(t)) / MEMCPYQUANTUM;
        return (resultwords >= 1 && resultwords <= NARGREGS);
    } else {
#if defined SOFTWARE_LONG_LONG || \
    (defined SOFTWARE_FLOATING_POINT && \
     defined SOFTWARE_FLOATING_POINT_RETURNS_DOUBLES_IN_REGISTERS)
    /* The return value is already known of sort struct, so no check for */
    /* software_floating_point_enabled is required here                  */
        t = prunetype(typearg_(t));
#ifdef SOFTWARE_LONG_LONG
        if (islonglong_(typespecmap_(t))) return YES;
#endif
#if defined SOFTWARE_FLOATING_POINT && \
    defined SOFTWARE_FLOATING_POINT_RETURNS_DOUBLES_IN_REGISTERS
    /* The return value is already known of sort struct, so no check for */
    /* software_floating_point_enabled is required here                  */
        return isprimtype_(t, s_double);
#endif
#else
        return NO;
#endif
    }
}

bool returnsstructinregs(Expr *fn) {
    TypeExpr *t = prunetype(typeofexpr(fn));
    if (h0_(t) != s_content) return NO; /* syserr will follow */
    return returnsstructinregs_t(typearg_(t));
}

/* end of simplify.c */
