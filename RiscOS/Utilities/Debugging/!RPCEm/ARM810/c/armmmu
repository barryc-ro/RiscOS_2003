/* armmmu.c - MMUlator main source
 * Copyright (c) 1993-1996 Advanced RISC Machines Ltd. All rights reserved.
 *
 * RCS $Revision$
 * Checkin $Date$
 * Revising $Author$
 */

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <time.h>               /* For a seed value */
#include <assert.h>

/* #define NDEBUG */
#include <assert.h>

#include "prof.h"               /* extra profiling - compile -DMARK */

/* @@@ debug @@@ */
#define NOIO
#define BENCHMARKING

#include "armmmuP.h"            /* Private header file */
#include "armpu.h"
#include "toolconf.h"
#include "armcopro.h"

#ifdef DEBUG
static int watch;
#endif

/* Possibly inline some functions */
#ifdef DONT_INLINE
#  define INLINE
#else
#  if defined(__GNUC__)
#    define INLINE __inline__
#  elif defined(_MSC_VER) || defined(__CC_NORCROFT)
#    define INLINE __inline
#  else
#    define INLINE
#  endif
#endif

#ifdef LRU_SUPPORT
#  define ARMul_MMUConfigMemory ARMul_LRUConfigMemory
#endif

static int SetClockSpeed(Memory *mem);


/*
 * Shared Variables
 */

/* A range of flag pages. On a failure we compare values with these as a
 * quick check. Removes the need for comparisons on fast paths.
 *
 * Flag levels
 *   NotFastAccess => FastAccess is currently barred on this page. Otherwise
 *                    you can do a cache replace.
 *   OutOfDate => The MMU's status has changed recently, and these pages
 *                have not been modified yet.
 *   Aborting => An abort occured on the last N-cycle. Subsequent S-cycles
 *               should cause aborts iff a 1Kb page is crossed. i.e. the MMU
 *               is in the abort state. */
static VirtLevel2 *NotFastAccess=NULL;
static VirtLevel1 *OutOfDate=NULL;
static VirtMemory *Aborting=NULL;
/* Dummies
 *   Used in place of "NULL"s at various points, so that the read
 *   can take place and later be checked for an incomplete memory tree after
 *   an exceptional case occurs. */
static VirtLevel1 *DummyV1=NULL;
static VirtLevel2 *DummyV2=NULL;
#if 0
static PhysLevel1 *DummyP1=NULL;
static PhysLevel2 *DummyP2=NULL;
#endif
static TFlags DummyAccessBits=0;

/* Array of access masks to be used when updating access bits */
static TFlags MMUAccess[64];



/*
 * Internal functions
 */

static unsigned long PhysAccess(Memory *mem,ARMword address,
                                ARMword *w,ARMul_acc acc);

static int MemAccess(void *handle,
                     ARMword address,
                     ARMword *data,
                     ARMul_acc acc);
static int MemAccess2(void *handle,
                      ARMword address,
                      ARMword *data,ARMword *data2,
                      ARMul_acc acc);

static void ResetClock(Memory *mem);

/*
 * Miscellaneous utility functions
 */

/* Allocate a block of memory */
#define New(M,T) ( (T *)Allocate(M,sizeof(T)) )
/* ...zero initialised. */
#define New0(M,T) ( (T *)Allocate0(M,sizeof(T)) )

#define NewFail(V,M,T) (( V = New(M,T)) == NULL)
#define NewFail0(V,M,T) (( V = New0(M,T)) == NULL)

/* Allocates a block of memory and exits on failure. */
static void *Allocate(Memory *mem,size_t n)
{
  void *p=malloc(n);
  if (p) return p;
  else {
    ARMul_State *state=mem->state;
    ARMul_ConsolePrint(state,"MMUlator failed to allocate %ld bytes.\n",n);
    ARMul_ModelBroken(state);
  }
  return NULL;
}

/* Zero initialised. */
static void *Allocate0(Memory *mem,size_t n)
{
  void *p=calloc(1,n);
  if (p) return p;
  else {
    ARMul_State *state=mem->state;
    ARMul_ConsolePrint(state,"MMUlator failed to allocate %ld bytes.\n",n);
    ARMul_ModelBroken(state);
  }
  return NULL;
}


/*
 * Initialisation routines
 */

/* Initialise DummyV1, NotFastAccess, etc. */
static int AllocateNulls(Memory *mem)
{
  int i;
  
  FUNCTION("AllocateNulls");
  
  if (NewFail0(NotFastAccess,mem,VirtLevel2) ||
      NewFail(OutOfDate,mem,VirtLevel1) ||
      NewFail0(DummyV1,mem,VirtLevel1) ||
      NewFail0(DummyV2,mem,VirtLevel2) ||
#if 0
      NewFail0(DummyP1,mem,PhysLevel1) ||
      NewFail0(DummyP2,mem,PhysLevel2) ||
#endif
      NewFail0(Aborting,mem,VirtMemory))
    return FALSE;

  for (i=0;i<MEMSIZE;i++) Aborting->level[i]=DummyV1;
  
  /* Now set all the level1 pointers, and level1/4 for the virtual levels */
  for (i=0;i<LEVEL1SIZE;i++) {
    DummyV1->phys_addr[i]=BAD_PHYS_ADDR;
    DummyV1->cache[i]=DummyV2;
    DummyV1->access[i]=DummyAccessBits;
    DummyV1->read[i]=NotFastAccess;
    DummyV1->write[i]=NotFastAccess;
#if 0
    DummyP1->page[i].page=DummyP2;
    DummyP1->page[i].access.fn.access=NULL; /* could be an undummy function... */
    DummyP1->page[i].access.fn.time=NULL;
    DummyP1->page[i].access.handle=NULL;
    DummyP1->page[i].access.model=NULL;
    DummyP1->page[i].access.real=NULL;
#endif
  }
  for (;i<LEVEL1SIZE*4;i++) {
    DummyV1->access[i]=DummyAccessBits;
    DummyV1->read[i]=NotFastAccess;
    DummyV1->write[i]=NotFastAccess;
  }
  *OutOfDate=*DummyV1;
  
#if (defined ERROR) || (defined DEBUG)
  fprintf(stderr,"Null values:\n\
  NotFastAccess = %p\n\
  OutOfDate     = %p\n\
  DummyV1       = %p\n\
  DummyV2       = %p\n\
  DummyP1       = %p\n\
  DummyP2       = %p\n",
          NotFastAccess,OutOfDate,DummyV1,DummyV2,DummyP1,DummyP2);
#endif
  return TRUE;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Initialise the MMUAccess array. This array contains the default access   */
/* masks for all combinations of the "ap" (access permissions), "df"         */
/* (domain flags) and "S" (MMU 'special' flag) bits. Further more, since     */
/* these bits are also required in the TFlags themselves, it contains them.  */
static void InitialiseMMUAccess(void)
{
  ARMword R,S,ap,df,count=0;
  
  FUNCTION("InitialiseMMUAccess");
  
  for (R=0;R<2;R++)
    for (S=0;S<2;S++)
      for (ap=0;ap<4;ap++)
        for (df=0;df<4;df++) {
          TFlags access;
          access=count<<TFaccess_index_shift;
          access=access | (access>>TFother_mode_shift);
          switch (df) {
          case 0: case 2:     /* Domain is No Access/Reserved */
            MMUAccess[count]=TFnone | access;
            break;
          case 3:             /* Domain is "Manager" */
            MMUAccess[count]=TFarw | access;
            break;
          default:
            switch (ap) {     /* Domain is "Client" */
            case 0:               /* No access unless S bit is set */
              MMUAccess[count]=(S ? TForead|TFofastr
                                : R ? TForead|TFofastr|TFread|TFfastr
                                : TFnone)|access;
              break;
            case 1:         /* SVC mode read-only */
              MMUAccess[count]=TFsvcrw | access;
              break;
            case 2:         /* USR mode read-only */
              MMUAccess[count]=TFsvcrw | TFread | TFfastr | access;
              break;
            case 4: default: /* All access (check for compilers...) */
              MMUAccess[count]=TFarw | access;
              break;
            }
          }
          count++;
        }
}

#ifdef VERIFY
static ARMul_State verify;
#endif


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
 *                                                                             *
 *                                Memory model                                 *
 *                                                                             *
 \* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

extern unsigned int ARMul_MMUConfigMemory(ARMul_State *state,
                                          Memory *mem,
                                          toolconf config);

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
 *                               Useful macros                                 *
 \* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
#if 0
/* Macro to "undummy" a PhysLevel1 pointer */
static PhysLevel1 *UndummyPL1(Memory *mem,ARMword offset);
#define UNDUMMIEDP1(MEM,PHYS,OFFSET) \
  (((PHYS)->level[OFFSET]==DummyP1) ? UndummyPL1(MEM,OFFSET) : \
   (PHYS)->level[OFFSET])
#endif

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * Macro for sorting out access permission bits.
 * Semantics are:
 *   IF ("cache is enabled" AND "page is cacheable") THEN
 *     SET "can be cached"
 *     IF ("write back cache")
 *       SET "can be buffered"
 *   ELSE
 *     CLEAR "fast read"
 *   IF ("virtual page is dummy")
 *     CLEAR "fast read"
 *   IF ("page is memory-mapped I/O") THEN
 *     CLEAR "fast read", "fast write"
 *   ELIF ("page is not updateable" OR "page is really a dummy") THEN
 *     CLEAR "fast write". 
 *   IF ("buffer is enabled" AND "page is bufferable") THEN
 *     IF ("write-back cache" AND "can be buffered")
 *       SET "write-back"
 *     ELSE
 *       SET "can be buffered"
 */
#define ACCESS(acc,old,vl2) \
  if ((mem->mmu.control & MMU_C) && ((old) & TFcache)) {                  \
    if (mem->prop & Cache_WriteBack_Prop)                                 \
      (acc) |= TFrealbuff | TFrealcache;                                  \
    else                                                                  \
      (acc) |= TFrealcache;                                               \
  } else (acc) &= ~(TFfastr | TFofastr);                                  \
  if ((vl2)==DummyV2) (acc) &= ~(TFfastr | TFofastr);                     \
  if ((old) & TFhandler)                                                  \
    (acc) &= ~(TFfastr | TFofastr | TFfastw | TFofastw);                  \
  else if ( !((old) & TFupdate) || ((old) & TFdummy) )                    \
    (acc) &= ~(TFfastw | TFofastw);                                       \
  if ((mem->mmu.control & MMU_W) && ((old) & TFbuffer)) {                 \
    if ((mem->prop & Cache_WriteBack_Prop) && ((acc) & TFrealbuff))       \
      (acc) |= TFwriteback;                                               \
    else                                                                  \
      (acc) |= TFrealbuff;                                                \
  }


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Map an area of memory. */

#if 0                           /* not supported */
static int get_memory(ARMul_State *state,
                      const char name[8],
                      void *config,
                      ARMword low_addr,ARMword high_addr)
{
  Memory *mem=(Memory *)state;
  ARMul_MemoryModel **mod=ARMul_MemoryModels;

  if ((low_addr & 0x3ff) || (high_addr & 0x3ff)) {
    ARMul_ConsolePrint(state,"\nParameters to get_memory should be page aligned.\n");
    low_addr&=~0x3ff;
    high_addr&=~0x3ff;
  }

  if (high_addr<=low_addr && high_addr!=0) {
    ARMul_ConsolePrint(state,"\nget_memory: High address lower than (or same as) Low address\n");
    return 0;
  }

  while (*mod!=NULL) {
    if (strcmp(name,(*mod)->name)==0) {
      /* found the memory type... */
      PhysMemory *phys=PHYSICAL(state);
      unsigned int i,hi_lim;
      AccessBlockList *ab;

      ab=New(mem,AccessBlockList);

      ab->blk.real=mem->chain;  /* chain together in a free list */

      ab->blk.model=*mod;
      ab->blk.handle=(*mod)->init_proc(state,config,NULL,
                                       low_addr,high_addr,
                                       1,&ab->blk.fn);
      ab->mem=mem;

      /* Ensure wraparound works (address 0 = 4Gb for HIGH) */
      hi_lim=(high_addr==0) ? MEMSIZE : LEVEL1inMEM(high_addr);
      
      if (LEVEL2in1(low_addr)) { /* split the low level1 */
        PhysLevel1 *pl1;
        unsigned int limit=LEVEL1SIZE;
        
        pl1=UNDUMMIEDP1(state,phys,LEVEL1inMEM(low_addr));
        
        if (hi_lim==LEVEL1inMEM(low_addr)) limit=LEVEL2in1(high_addr);
        
        for (i=LEVEL2in1(low_addr);i<limit;i++) {
          pl1->page[i].access.real=ab;
        }
      }
      
      if (LEVEL2in1(high_addr) && (hi_lim!=LEVEL1inMEM(low_addr) ||
                                   LEVEL2in1(low_addr)==0)) {
                                /* split the high level1 */
        PhysLevel1 *pl1;
        
        pl1=UNDUMMIEDP1(state,phys,hi_lim);
        
        for (i=0;i<LEVEL2in1(high_addr);i++) {
          pl1->page[i].access.real=ab;
        }
      }
      
      for (i=LEVEL1inMEM(low_addr);i<hi_lim;i++) {
        /* fill in the pages inbetween */
        phys->access[i]=ab;
      }

      mem->chain=ab;

      return 1;
    }
    mod++;
  }
  return 0;
}

#endif

/*
 * Stubs exported by MMUlator
 */
static ARMul_Error MemInit(ARMul_State *state,ARMul_MemInterface *interf,
                           ARMul_MemType type,toolconf config);

#ifndef LRU_SUPPORT

#define ModelName "MMUlator"

ARMul_MemStub ARMul_MMUlator = {
  MemInit,
  ModelName
  };

#else

#define ModelName "LRU-MMUlator"

ARMul_MemStub ARMul_LRUMMUlator = {
  MemInit,
  ModelName
  };

static const ARMul_MemStub *me=&ARMul_LRUMMUlator;

#endif

static ARMul_Error CPInit(ARMul_State *state,unsigned num,
                          ARMul_CPInterface *interf,
                          toolconf config,void *sibling);

static ARMul_Error CPBusInit(ARMul_State *state,unsigned num,
                             ARMul_CPInterface *interf,
                             toolconf config,void *sibling);

/*
 * Predeclare the memory access functions so that the initialise function
 * can fill them in
 */
static int MemAccess(void *,ARMword,ARMword *,ARMul_acc);
static int MemAccess2(void *,ARMword,ARMword *,ARMword *,ARMul_acc);
static void MemExit(void *);
static unsigned long ReadClock(void *handle);
static const ARMul_Cycles *ReadCycles(void *handle);
static void CoreException(void *handle,ARMword address,ARMword penc);

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Initialise the memory interface */
static ARMul_Error MemInit(ARMul_State *state,
                           ARMul_MemInterface *interf,
                           ARMul_MemType type,
                           toolconf config)
{
  Memory *mem;
  VirtMemory *this_mode,*other_mode,*raw_this,*raw_other;
  unsigned long i,j;
  armul_MemInit *child_init;
  toolconf child;
  ARMul_Error err;

  FUNCTION("ARMul_MemoryInit");

  interf->read_clock=ReadClock;
  interf->read_cycles=ReadCycles;

  /* Fill in my functions */
  switch (type) {
  case ARMul_MemType_Basic:
    type=ARMul_MemType_BasicCached;
    interf->x.basic.access=MemAccess;
    break;
  case ARMul_MemType_16Bit:
    type=ARMul_MemType_16BitCached;
    interf->x.basic.access=MemAccess;
    break;
  case ARMul_MemType_Thumb:
    type=ARMul_MemType_ThumbCached;
    interf->x.basic.access=MemAccess;
    break;
  case ARMul_MemType_ARM8:
    interf->x.arm8.access=MemAccess;
    interf->x.arm8.access2=MemAccess2;
    interf->x.arm8.core_exception=CoreException;
    type=ARMul_MemType_16BitCached;
    break;
  default:
    return ARMul_RaiseError(state,ARMulErr_MemTypeUnhandled,ModelName);
  }

  /* Initialise the memory tree */
  mem=(Memory *)malloc(sizeof(Memory));
  if (mem==NULL) {
    ARMul_ConsolePrint(state,"MMUlator failed to allocate its state.\n");
    return ARMul_RaiseError(state,ARMulErr_OutOfMemory);
  }

  mem->state=state;

  /* initialise static structures */
  if (DummyV1==NULL) {
    if (!AllocateNulls(mem)) {
      free(mem);
      return ARMul_RaiseError(state,ARMulErr_OutOfMemory);
    }
    InitialiseMMUAccess();
  }

  /* Configuration */
  if (ARMul_MMUConfigMemory(state,mem,config)) {
    free(mem);
    return ARMul_RaiseError(state,ARMulErr_OutOfMemory);
  }

  /*
   * Install the MMU
   */
  err=ARMul_CoProAttach(state,15,CPInit,config,mem);
  if (err!=ARMulErr_NoError) {
    free(mem);
    return err;
  }

  /*
   * Install the co-processor bus
   */
  mem->cp.init=ARMul_CoProBus(state,CPBusInit,config,(void *)mem,
                              &mem->cp.config,&mem->cp.sibling);

  /*
   * Child memory interface
   */
  child_init=ARMul_FindMemoryInterface(state,(void *)ToolConf_Lookup(config,"MEMORY"),
                                       &child);
  if (child_init==NULL || child_init==MemInit) {
    ARMul_CoProDetach(state,15);
    free(mem);
    return ARMul_RaiseError(state,ARMulErr_NoMemoryChild,ModelName);
  }
  if (child==NULL) child=config;
  if (mem->clock.conf_mclk) {
    char optbuffer[32];
    sprintf(optbuffer,"MCLK=%ld",mem->clock.conf_mclk);
    ToolConf_Add(child,optbuffer);
  }
  ARMul_PrettyPrint(state,", (Physical memory");
  err=child_init(state,&mem->child,type,child);
  ARMul_PrettyPrint(state,")");
  if (err!=ARMulErr_NoError) {
    ARMul_CoProDetach(state,15);
    free(mem);
    return err;
  }

  SetClockSpeed(mem);

  DEBUGDO(ARMul_PrettyPrint(state, "config_done "));

  SETVIRTUAL(mem,this_mode=&mem->svc_mode);
  mem->othermode=other_mode=&mem->usr_mode;

  /* This is the *default* access block for all memory. i.e. it does
   * nothing */
#if 0
  mem->access.blk.fn.access=NULL;
  mem->access.blk.fn.time=NULL;
  mem->access.blk.handle=(void *)mem;
  mem->access.blk.real=NULL;
  mem->access.mem=mem;
  mem->chain=NULL;              /* no memory blocks allocated */
#endif

  raw_this=&mem->raw_svc; raw_other=&mem->raw_usr;

  DEBUGDO(ARMul_PrettyPrint(state, "init_done "));

  for (i=0;i<MEMSIZE;i++) {
    other_mode->level[i]=this_mode->level[i]=OutOfDate;
    raw_this->level[i]=raw_other->level[i]=DummyV1;
  }
  
  DEBUGDO(ARMul_PrettyPrint(state, "mode_ptrs_done "));

#if 0
  /* Set memory size - all pages over the limit return aborts. Memory size */
  /* is rounded up to the megabyte. */
  if (initsize==0) initsize=0x80000000;
  himem+=((himem<<20)!=initsize);
  if (himem==0) himem=MEMSIZE;
  for (i=0;i<himem;i++) {
    physical->level[i]=DummyP1;
#if 0
    physical->access[i]=&mem->access;
#endif
  }
  for (;i<MEMSIZE;i++) {
    physical->level[i]=DummyP1;
#if 0
    physical->access[i]=&mem->access;
#endif
  }

  mem->size=(himem<<20);

  DEBUGDO(ARMul_PrettyPrint(state, "phys_ptrs_done "));
#else
{
  unsigned long memsize=0;
  char *option;
  option=(void *)ToolConf_Lookup(config,"MEMORYSIZE");
  if (option) memsize=ToolConf_Power(option,TRUE);
  else memsize=0x80000000;
  ARMul_SetMemSize(state,memsize);
}
#endif

  /* Initialise the cache */
  for (i=0;i<CACHE_WORK_WORDS;i++) {
    mem->cache.work[i]=mem->cache.seed[i];
  }
  mem->cache.lock_down.base=0;
  mem->cache.lock_down.flag=0;
  for (i=0;i<mem->cache.blocks;i++) {
    for (j=0;j<mem->cache.size;j++) {
      mem->cache.block[i].line[j].page=DummyV2;
      mem->cache.block[i].line[j].phys_addr=BAD_PHYS_ADDR;
      mem->cache.block[i].line[j].address=0;
    }
  }
  mem->cache.victim.phys_addr=BAD_PHYS_ADDR;
  mem->cache.fetching_line=0;

  DEBUGDO(ARMul_PrettyPrint(state, "cache_initialised "));

  /* Initialise the mmu */
  mem->mmu.ttb=0;
  for (i=0;i<16;i++)
    mem->mmu.dac[i]=0;
  mem->mmu.control=0;           /* All control bits forced low by reset */
  mem->mmu.state=3;
  for (i=0;i<mem->tlb.size;i++) {
    mem->tlb.buffer[i].offset=0;
    mem->tlb.buffer[i].usr=mem->tlb.buffer[i].svc=DummyV1;
    mem->tlb.buffer[i].pagesize=0;     /* No page entries... */
  }

  DEBUGDO(ARMul_PrettyPrint(state, "mmu_initialised "));

  /* Initialise the benchmarking data. */
  ResetClock(mem);
  /* Start the clock - is necessary on some systems */
  (void)clock();
  
  DEBUGDO(ARMul_PrettyPrint(state, "benchmarking_initialised "));

  ARMul_InstallExitHandler(state,MemExit,mem);

  SETFASTL2(mem,NotFastAccess,0,0);

  interf->handle=mem;

  return ARMulErr_NoError;
}

#undef LOGCACHEBLOCKS
#  undef CACHEBLOCKS
#undef CACHESIZE
#undef LOGCACHEWORDS
#  undef CACHEWORDS
#undef TLBSIZE
#undef MAX_WB_WORDS
#undef MAX_WB_ADDRS
#undef HAS_R_FLAG
#undef HAS_WB
#undef HAS_UPDATEABLE
#undef BUFFERED_SWAP
#undef ARM6_RNG
#undef ARM7_RNG

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Finalise the memory unit (free pointers) */
static void MemExit(void *handle)
{
  Memory *mem=(Memory *)handle;
  unsigned long i,j;

  FUNCTION("ARMul_MemoryExit");

#if 0
  if (himem==0) himem=MEMSIZE;

  /* Scan the memory map for allocated pages */
  /* Free all physical memory... */
  for (i=0;i<himem;i++) {
    if (phys->level[i]!=DummyP1) {
      for (j=0;j<LEVEL1SIZE;j++)
        if (phys->level[i]->page[j].page!=DummyP2)
          free(phys->level[i]->page[j].page);
      /* @@@ call code to unregister the page */
      free(phys->level[i]);
    }
  }
#endif

  /* ...and the virtual memory */
  for (i=0;i<MEMSIZE;i++) {
    if (mem->raw_usr.level[i]!=DummyV1) {
      for (j=0;j<LEVEL1SIZE;j++)
        if (mem->raw_usr.level[i]->cache[j]!=DummyV2 &&
            mem->raw_usr.level[i]->cache[j]!=NotFastAccess)
          free(mem->raw_usr.level[i]->cache[j]);
      free(mem->raw_svc.level[i]);
      free(mem->raw_usr.level[i]);
    }
  }

#ifdef VERIFY
  verify_MemoryExit(&verify);
#endif

  /* Finally, the memory itself */
  free(mem);
}


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Allocate a new PhysLevel1 */

#if 0
static ARMul_result UndummyOnAccess(void *my_ref, ARMul_acc acc,
                                    ARMword address, ARMword *data_ptr);
static ns FatalTimeFunction(void *my_ref, ARMul_acc acc,
                            ARMword address);

static PhysLevel1 *UndummyPL1(Memory *mem,ARMword offset)
{
  PhysMemory *phys=mem->phys;
  PhysLevel1 *p1;
#if 0
  AccessBlockList *ab;
#endif
  int i;

  if (NewFail(p1,mem,PhysLevel1)) return p1;

  phys->level[offset]=p1;
#if 0
  ab=phys->access[offset];
#endif

  for (i=0;i<LEVEL1SIZE;i++) {
    p1->page[i].page=DummyP2;
    p1->page[i].address=(offset*LEVEL1SIZE+i)*LEVEL2SIZE*sizeof(ARMword);
#if 0
    p1->page[i].access.fn.access=UndummyOnAccess;
    p1->page[i].access.fn.time=FatalTimeFunction;
    p1->page[i].access.handle=&p1->page[i];
    p1->page[i].access.model=NULL;
    p1->page[i].access.real=ab;
#endif
  }
  return p1;
}
#endif

/* macro to merge a physical and virtual address to give the real physical
 * address
 */
#define PHYS_ADDR(PHYS,VIRT) \
  ((PHYS) & 0xfffff000) | ((VIRT) & 0xfff)


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*                           Benchmarking functions                            *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

#ifdef DEBUG
static void debug_timing(Memory *mem)
{
  debug3("  fclk ticks %d  mclk ticks %d (%d equivalent)\n",
         mem->fclk,mem->mclk,mem->mclk*mem->mdiv)l
  debug2("  GCLK %d %s\n",mem->bench.delta_gclk,
         mem->cache.fetching_line ? "Fetching line" : "");
  debug1("  Write operation to finish at %d\n",mem->wb.fclk);
  debug3("  %d/%d in write buffer. Bitfield %02x\n",
         mem->wb.words,mem->wb.addrs,mem->wb.bitfield);
}
#else
#  define debug_timing(X)
#endif

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * Inlined/macro functions are:
 *
 * sort_out_gclk() - ensures that the master clock is uptodate with respect to
 * any gclk ticks that have recently occured. FinishLineFetch() should
 * otherwise be called, if there is a danger of a line fetch occuring (in which
 * case some of the gclks may be at memory speed).
 * clock_write_buffer() - shifts a word out of the write buffer into memory,
 * and sets the target time to be the time at which the next word in the write
 * will finish.
 * sort_out_clock() - resets the master clock after a series of writes. If the
 * next (final) write is to occur in the future then the master clock is set
 * to be the first fclk edge after that write occurs.
 * catch_up_write_buffer() - brings the write buffer state uptodate. It clocks
 * out all words from the buffer to the point where the next write will finish
 * some time in the future, or until it is empty.
 */

#if 0                           /* not needed - we're not allowing async */
#define SyncToFCLK(mem) \
  ((mem)->clock.next_mem_cycle=(((mem)->clock.next_mem_cycle % (mem)->clock.fdiv)-\
                                (mem)->clock.fdiv))
#endif

/*
 * EmptyWriteBuffer writes the contents of the buffer out to memory and
 * then synchronises the master clock onto the next fclk.
 */
static int EmptyWriteBuffer(Memory *mem)
{
  FUNCTION("EmptyWriteBuffer");
  debug_timing(mem);
  
  /* Remove any outstanding words from the write buffer */
  if (mem->wb.words!=0) {
    WriteBuff *wb=&(mem->wb);
    wb->idx_in=wb->idx_out=0;
    wb->words=wb->addrs=0;
    wb->bitfield=0;
    mem->clock.next_mem_cycle=0;
    mem->clock.wb_cycle=0;
debug4("%5d %d %d %08x  Empty end\n",wb_fclk,wb->words,wb->addrs,wb->bitfield);
    return FALSE;
  } else {
    return TRUE;
  }
}

/*
 * AddSEQToBuffer adds a sequential write to the buffer, stalling the
 * processor if there is not room.
 */
static void AddSEQToBuffer(Memory *mem,ARMword phys_addr,ARMword *data,
                           ARMul_acc acc)
{
  ARMword t;

  t=PhysAccess(mem,phys_addr,data,acc);

  if (mem->prop & MMU_IdleCycles_Prop) {
    WriteBuff *wb=&(mem->wb);
    unsigned int words=wb->words;
    unsigned int max_words=wb->max_words;
    
    FUNCTION("AddSEQToBuffer");
    debug_timing(mem);

    if (words==max_words) {
      /* Need a space for the word */
      debug4("%5d %d %d %08x  WB full S\n",wb_fclk,words,addrs,bitfield);
      if ((wb->bitfield>>=1) & 1)
        wb->addrs--;
      words--;
      wb->idx_out=(wb->idx_in==0) ? max_words-1 : wb->idx_out-1;
        mem->clock.next_mem_cycle=words ? wb->time[wb->idx_out] : t;
    } else {
      if (mem->clock.wb_cycle==0 && words==0) {
        mem->clock.next_mem_cycle+=t;
        mem->clock.wb_cycle=1;
      }
    }
    
    wb->words=words+1;
    wb->idx_in=(wb->idx_in==0) ? max_words-1 : wb->idx_in-1;
    wb->time[wb->idx_in]=t;
    
    debug4("%5d %d %d %08x  End S\n",wb_fclk,words+1,addrs,bitfield);
  }
}

/*
 * AddNonSEQToBuffer does essentially the same as AddSEQToBuffer
 * except that it also ensures that there is room for the address. Note that
 * if there is room for an address then there is not necessarily room for a
 * word, and vice-versa. However, note that creating room for the address
 * necessarily creates room for the word.
 */
static void AddNonSEQToBuffer(Memory *mem,ARMword phys_addr,ARMword *data,
  ARMul_acc acc)
{
  ARMword t;

  t=(PhysAccess(mem,phys_addr,data,acc_Icycle)+
     PhysAccess(mem,phys_addr,data,acc | acc_seq));

  if (mem->prop & MMU_IdleCycles_Prop) {
    WriteBuff *wb=&(mem->wb);
    unsigned int words=wb->words,addrs=wb->addrs;
    unsigned int max_words=wb->max_words,max_addrs=wb->max_addrs;
    unsigned long bitfield=wb->bitfield;
    
    FUNCTION("AddNonSEQToBuffer");
    debug_timing(mem);
    
    if (addrs==max_addrs) {
      /* There isn't room for the address of this N-cycle */
      debug0("TAB full");
      while (addrs==max_addrs) {
        debug4("%5d %d %d %08x  TAB full NS\n",wb_fclk,words,addrs,bitfield);
        if ((bitfield>>=1) & 1)
          addrs--;
        words--;
        wb->idx_out=(wb->idx_in==0) ? max_words-1 : wb->idx_out-1;
      }
      mem->clock.next_mem_cycle=words ? wb->time[wb->idx_out] : t;
    } else if (words==max_words) {
      /* There isn't room for the word */
      debug0("WB full");
      debug4("%5d %d %d %08x  WB full NS\n",wb_fclk,words,addrs,bitfield);
      if ((bitfield>>=1) & 1)
        addrs--;
      words--;
      wb->idx_out=(wb->idx_in==0) ? max_words-1 : wb->idx_out-1;
      mem->clock.next_mem_cycle=words ? wb->time[wb->idx_out] : t;
    } else {
      if (mem->clock.wb_cycle==0 && words==0) {
        mem->clock.next_mem_cycle+=t;
        mem->clock.wb_cycle=1;
      }
    }
    
    wb->bitfield=bitfield | (1<<(words+1));
    wb->words=words+1;
    wb->addrs=addrs+1;
    wb->idx_in=(wb->idx_in==0) ? max_words-1 : wb->idx_in-1;
    wb->time[wb->idx_in]=t;
    
    debug4("%5d %d %d %08x  End NS\n",wb_fclk,words+1,addrs+1,wb->bitfield);
  }
}

/*
 * Remove a word from the write-buffer
 */

static int RemoveWordFromBuffer(Memory *mem)
{
  WriteBuff *wb=&mem->wb;
  if ((wb->bitfield=wb->bitfield>>1) & 1)
    wb->addrs--;
  wb->idx_out=(wb->idx_out==0) ? wb->max_words-1 : wb->idx_out-1;
  if (--wb->words) {
    mem->clock.next_mem_cycle=wb->time[wb->idx_out];
    return FALSE;
  } else {
    mem->clock.wb_cycle=0;
    return TRUE;
  }
}
    

#if 0                           /* Handle timing for non-WB machines */

static int AddNonSEQToBuffer(Memory *mem,ns t)
{
  /* sort_out_gclk() */
  if (mem->delta_gclk) {  /* GCLK values outstanding - add them */
    mem->fclk+=mem->delta_gclk*mem->fdiv;
    mem->cycle+=mem->delta_gclk;
    mem->delta_gclk=0;
  }

  /* Synchronise to mclk */
  mem->sync++;
  mem->mclk+=t;

  return TRUE;
}

static void AddSEQToBuffer(Memory *mem,ns t)
{
  mem->mclk+=t;
}

#define EmptyWriteBuffer(mem)

#endif

/* Read/Write a word to a level2 physical memory pointer. */
static unsigned long PhysAccess(Memory *mem,ARMword address,
                                ARMword *w,ARMul_acc acc)
{
  armul_MemAccess *mem_access=mem->child.x.basic.access;
  void *handle=mem->child.handle;
  long n=0;
  unsigned long mdiv=mem->clock.mdiv;
  int hourglass_counter=8192;

  /* Might be called with a ARM8 double-word thing */
  if (acc_WIDTH(acc)==BITS_64) {
    acc=acc-1;                  /* convert to bits_32 */
  }

  mem->abortSig=FALSE;

  do {
    switch (mem_access(handle,address,w,acc)) {
    case -1:
      mem->abortSig=TRUE;
      return n;
    case 0:
      if (--hourglass_counter==0) {
        ARMul_ModelBroken(mem->state);
        return n;
      }
      n+=mdiv;
      break;
    case 1: default:
      return n+mdiv;
    }
  } while (1);
}

/* Do a "fast" cycle */

static void IdleCycle(Memory *mem)
{
  /* can't use "PhysAccess" because it honours "Nwait" */
  mem->child.x.basic.access(mem->child.handle,0,NULL,acc_Icycle);
  mem->clock.next_mem_cycle+=mem->clock.mdiv;
}

static void FastCycle(Memory *mem)
{
  if ((mem->clock.next_mem_cycle-=mem->clock.fdiv)<=0 &&
      (!mem->clock.wb_cycle || RemoveWordFromBuffer(mem))) {
    IdleCycle(mem);
  }

  mem->NumFcycles++;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * WriteOutVictim does the job of writing out dirty data which has been
 * buffered, either from a ReadCacheReplace or from a 'Clean entry' cache
 * operation. */
static int WriteOutVictim(Memory *mem)
{
  /* We have some data here that we'd like to be written out please... */
  ARMword phys_addr,address;
  ARMword *read=mem->cache.dirty;
  ARMword words=mem->cache.words;
  unsigned int i;

  address=mem->cache.victim.address;
  ARMul_RaiseEvent(mem->state,MMUEvent_LineWB,address,0);

  phys_addr=PHYS_ADDR(mem->cache.victim.phys_addr,
                      address);

  AddNonSEQToBuffer(mem,phys_addr,read,acc_StoreWordN);
  phys_addr+=4; read++;
    
  for (i=1;i<words;i++,phys_addr+=4,read++) {
    AddSEQToBuffer(mem,phys_addr,read,acc_StoreWordS);
  }

  mem->cache.victim.phys_addr=BAD_PHYS_ADDR;
  
  return TRUE;          /* signal writebuffer non-empty */
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * FinishLineFetch accounts for a line fetch, and for all cycles since. It
 * stalls the processor if there have not been sufficient cycles for the fetch
 * i.e. the fetch has not terminated yet. */
static int FinishLineFetch(Memory *mem,
                           ARMword new_address,int cache_check)
{
  FUNCTION("FinishLineFetch");
  debug_timing(mem);

  if (mem->cache.fetching_line==0) return FALSE;

  if ((mem->prop & MMU_IdleCycles_Prop)==0)
    cache_check=0;
  else
    mem->clock.next_mem_cycle=0;

  if (mem->cache.fetching_line<mem->cache.words) {
    /* part way through a slow line fetch */
    CacheLine *fetching=mem->cache.fetching;
    VirtLevel2 *vl2=fetching->page;
    ARMword address=fetching->address+(mem->cache.fetching_line<<2);
    ARMword phys_addr;
    ARMword *write=&(vl2->page.t.word[CACHEBLOCKin2(mem,address) <<
                                      mem->cache.log_words]);
    int words=mem->cache.words;
    int i;

    phys_addr=PHYS_ADDR(fetching->phys_addr,address);

    MARKCACHE(mem,fetching->address,vl2);
    for (i=mem->cache.fetching_line;i<words;i++,phys_addr+=4,address+=4) {
      PhysAccess(mem,phys_addr,&write[i],acc_LoadWordS);
      if (mem->abortSig) mem->cache.purge=1;
    }

    ARMul_RaiseEvent(mem->state,MMUEvent_DCacheStall,new_address,address);

    if (cache_check) {
      flag_word prop=mem->prop;
      /* Now check to see if there is an interlock cycle on cache
       * lookup */
      if ((prop & Cache_WBInterlock_Prop) ||
          /* the entire cache is interlocked for the cycle following */
          ((prop & Cache_BlockInterlock_Prop) &&
           /* just the block where the write occured to is interlocked */
           Assoc(mem,address ^ new_address)==0))
        IdleCycle(mem);
    }
  } else if (cache_check) {
    /* A fast line fetch, or a completed slow line fetch. */
    flag_word prop=mem->prop;
    CacheLine *fetching=mem->cache.fetching;
    ARMword address=fetching->address;

    if (((prop & Cache_WBInterlock_Prop) ||
         /* the entire cache is interlocked for the cycle following */
         ((prop & Cache_BlockInterlock_Prop) &&
          /* just the block where the write occured to is interlocked */
          Assoc(mem,address ^ new_address)==0)))
      IdleCycle(mem);
    
    debug0("Cache line-fetch stall\n");
  }

  if (mem->cache.purge) {
    /* purge this line - it has an error */
    /* must have resulted from a slow line fetch, so 'fetching' is valid */
    assert(mem->cache.fetching!=NULL);
    UNCACHE(mem,mem->cache.fetching->address,mem->cache.fetching->page);
    
    /* clear up */
    mem->abortSig=FALSE;        /* must not get through to core */
    mem->cache.purge=0;
  }

  mem->cache.fetching_line=0;   /* linefetch completed */
  mem->cache.fetch_type=fetch_NONE; /*     "         "     */
  mem->cache.fetching=NULL;     /* not strictly necessary. makes asserts() possible */

  if (mem->cache.victim.phys_addr!=BAD_PHYS_ADDR) return WriteOutVictim(mem);

  return FALSE;                 /* signal writebuffer empty */
}


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*             Functions for dealing with state change aftermaths              *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

/* Updates a TFlags value given a change in the MMU control register/TLB
 * flush/undummying etc. */
static void UpdateTFlags(Memory *mem,VirtLevel1 *vl1_usr,VirtLevel1 *vl1_svc,
                         TFlags tf,VirtLevel2 *fast,ARMword i)
{
  ARMword domain=TFdomain_get(tf);
  /* Get access bits out of the lookup table */
  ARMword df=(mem->mmu.dac[domain]); /* domain flags in 00011 */
  ARMword ap=TFapflags_get_1100(tf); /* access protect in 01100 */
  /* MMU S bit in 10000 */
  ARMword RS=(mem->mmu.control & MMU_RS)>>(MMU_RS_bit-4);
  ARMword access_index=RS | ap | df;
  ARMword access=MMUAccess[access_index];
  ARMword otf=(tf & TFmergemask);

  tf=TFthis_mode(access) | otf;

  ACCESS(tf,otf,fast);
    
  /* Write back new access bits */
  vl1_usr->access[i] = tf;
  /* Set the fast read/write paths */
  /* Old flags are valid => fast!=DummyV2 */
  vl1_usr->read[i] = (tf & TFfastr) ? fast : NotFastAccess;
  vl1_usr->write[i] = (tf & TFfastw) ? fast : NotFastAccess;
  
  tf=TFother_mode(access) | otf;
  
  ACCESS(tf,otf,fast);

  /* Write back new access bits */
  vl1_svc->access[i] = tf;
  /* Set the fast read/write paths */
  /* Old flags are valid => fast!=DummyV2 */
  vl1_svc->read[i] = (tf & TFfastr) ? fast : NotFastAccess;
  vl1_svc->write[i] = (tf & TFfastw) ? fast : NotFastAccess;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* MMU control has changed and things are out of date */
static VirtLevel1 *UpdateVL1(Memory *mem,ARMword address,
                             ARMword offset)
{
  VirtMemory *usr=&mem->usr_mode;
  VirtMemory *svc=&mem->svc_mode;
  VirtLevel1 *vl1_usr;
  VirtLevel1 *vl1_svc;
  int i,j;

  FUNCTION("UpdateVL1");

  IGNORE(address);

  /* Is the MMU enabled? */
  if (!(mem->mmu.control & MMU_M)) { /* No */
    VirtLevel1 *vl1;
    ARMword phys_addr=(address & ~0xfffff);

    debug0("  MMU is disabled\n");

    /* When the MMU has been disabled, we change the memory map to be a */
    /* set of flat vl1's with invalid page sizes. */
    if (NewFail(vl1=usr->level[offset],mem,VirtLevel1)) return vl1;
    svc->level[offset]=vl1;
    for (i=0;i<LEVEL1SIZE;i++,phys_addr+=0x1000) {
      /* Copy physical pointers across */
      vl1->phys_addr[i]=phys_addr;
      vl1->cache[i]=DummyV2;
      vl1->read[i]=vl1->write[i]=NotFastAccess;
      vl1->access[i]=TFread | TFwrite | TFvalid | TFpagesize; /* invalid */
    }
    for (;i<LEVEL1SIZE*4;i++) {
      vl1->read[i]=vl1->write[i]=NotFastAccess;
      vl1->access[i]=TFread | TFwrite | TFvalid | TFpagesize; /* invalid */
    }
    return vl1;
  }

  usr->level[offset]=vl1_usr=mem->raw_usr.level[offset];
  svc->level[offset]=vl1_svc=mem->raw_svc.level[offset];

  if (vl1_usr==DummyV1) return DummyV1;

  /* Update access permissions after MMU change */
  for (j=0;j<LEVEL1SIZE*4;j+=4) {
    VirtLevel2 *fast=vl1_usr->cache[j>>2];
    for (i=j;i<j+4;i++) {
      TFlags tf=vl1_usr->access[i];
      if (tf & TFvalid) {               /* Old flags were valid - update */
        UpdateTFlags(mem,vl1_usr,vl1_svc,tf,fast,i);
     } else {
        /* Clear all read/write permissions */
        vl1_svc->access[i] = vl1_usr->access[i] = (tf & ~TFusrrw);
        vl1_svc->read[i] = vl1_svc->write[i] = NotFastAccess;
        vl1_usr->read[i] = vl1_usr->write[i] = NotFastAccess;
      }
    }
  }
  return (mem->priv_mode) ? vl1_svc : vl1_usr;
}


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*              Functions for reading/writing to physical memory               *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * Macros for defining the "slow" write functions */

/* Code to undummy a level2p */
/* @@@ avoid this by using the access function to undummy it the
 * first time. */

#if 0
static PhysLevel2Ptr *UndummyPL2(Memory *mem,ARMword address,PhysLevel2Ptr *pl2)
{
  VirtLevel1 *vl1_usr=mem->usr_mode.level[LEVEL1inMEM(address)];
  VirtLevel1 *vl1_svc=mem->svc_mode.level[LEVEL1inMEM(address)];
  ARMword level2=LEVEL2in1(address)<<2;
  VirtLevel2 *vl2=vl1_usr->cache[level2>>2];
  TFlags tf,mask=TFdummy;
  
  /* Need to "undummy" any level 2p that we come across */       
  if (pl2->page==DummyP2) {      /* Dummy page */                 
    if (NewFail(pl2->page,mem,PhysLevel2)) return pl2->page;
    *(pl2->page)=*DummyP2;                                        
  }

#if 0
  if (pl2->access.fn.access==NULL) /* has not got access function */
    mask|=TFhandler;
#endif

  tf=vl1_usr->access[level2];   /* Check dummy flag */           
  if (tf & mask) {           /* Uh-oh, its wrong! */          
    tf&=~mask;
    UpdateTFlags(mem,vl1_usr,vl1_svc,tf,vl2,level2);  
    level2++;                                                    
    tf=vl1_usr->access[level2] & ~mask;
    UpdateTFlags(mem,vl1_usr,vl1_svc,tf,vl2,level2);  
    level2++;                                                    
    tf=vl1_usr->access[level2] & ~mask;
    UpdateTFlags(mem,vl1_usr,vl1_svc,tf,vl2,level2);  
    level2++;                                                    
    tf=vl1_usr->access[level2] & ~mask;
    UpdateTFlags(mem,vl1_usr,vl1_svc,tf,vl2,level2);  
  }

  return pl2;
}

/* Undummies a PL2, but looks like an access function */
static ARMul_result UndummyOnAccess(void *my_ref, ARMul_acc acc,
                                    ARMword address, ARMword *data_ptr)
{
  PhysLevel2Ptr *l2=(PhysLevel2Ptr *)my_ref;

  IGNORE(acc);
  IGNORE(data_ptr);

  if (l2->access.real) {
    AccessBlockList *abl=l2->access.real;
    Memory *mem=abl->mem;
    l2->access=abl->blk;

    UndummyPL2(mem,address,l2);
    
    return ARMul_ResPRIVATE;
  } else {
    /* this isn't possible? */
    l2->access.fn.access=NULL;  /* don't call me again */

    return ARMul_ResABORT;
  }
}

/* Before UndummyOnAccess is called, a block has an invalid handle, so
 * the time function should NEVER be called. This function catches that
 * mistake
 */
static ns FatalTimeFunction(void *my_ref,ARMul_acc acc,ARMword address)
{
  IGNORE(my_ref); IGNORE(acc); IGNORE(address);
  fprintf(stderr,"Fatal MMUlator internal error: FatalTimeFunction called\n");
  exit(1);
}

/* Four fast access macros. The five variants are:
 * - word
 * - word, by number
 *   By number means "get the nth word" rather than "get word at address n"
 * - half word
 * - byte */
#define FetchP2(state,address,l2)                                   \
   (*GETWORDin2((l2)->page->t.word,address))
#define FetchP2_word(state,n,l2)                                    \
   ((l2)->page->t.word[n])
#define FetchHalfP2(ST,AD,L2)                                       \
   (*GETHALFin2((L2)->page->t.word,address,HostEndian!=(ST)->bigendSig))
#define FetchByteP2(ST,AD,L2)                                       \
   (*GETBYTEin2((L2)->page->t.word,address,HostEndian!=(ST)->bigendSig))

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *
 * Write a word to physical memory using a Level 2 pointer
 * Fast version is guaranteed not to have a dummy l2 or an io pointer passed */

#define WriteP2(ST,AD,WO,L2) \
  (*GETWORDin2((L2)->page->t.word,AD)=(WO))

/* Write a halfword to physical memory using a Level 2 pointer */
#define WriteHalfP2(ST,AD,HF,L2) \
  (*GETHALFin2((L2)->page->t.word,AD,HostEndian!=(ST)->bigendSig)=(HF))

/* Write a byte to physical memory using a Level 2 pointer */
#define WriteByteP2(ST,AD,BY,L2) \
  (*GETBYTEin2((L2)->page->t.word,AD,HostEndian!=(ST)->bigendSig)=(BY))
#endif


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*                       Address translation functions                         *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

/* Kill an entry in the TLB */
/* This function could be a macro, but is rarely called (I believe) and so   */
/* is not critical. */
static TLBEntry *ReplaceTLBEntry(Memory *mem,
                                 VirtLevel1 *usr,VirtLevel1 *svc,
                                 ARMword offset,ARMword pagesize)
{
  unsigned nexttodie;
  TLBEntry kill,*this;
  unsigned j;
  
  nexttodie=mem->tlb.nexttodie;
  this=&mem->tlb.buffer[nexttodie];
  kill=*this;

  FUNCTION("ReplaceTLBEntry");

  /* Invalidate all the marked pages */
  for (j=kill.offset;j<kill.offset+kill.pagesize;j++) {
    kill.usr->access[j] = kill.svc->access[j] = 0;
    kill.usr->read[j] = kill.usr->write[j] = NotFastAccess;
    kill.svc->read[j] = kill.svc->write[j] = NotFastAccess;
  }

  kill.offset=offset;
  kill.usr=usr;
  kill.svc=svc;
  kill.pagesize=pagesize;
  *this=kill;

  if (!mem->tlb.lock_down.flag) {
    nexttodie++;
    mem->tlb.nexttodie=(nexttodie==mem->tlb.size) ? mem->tlb.lock_down.base
                                                  : nexttodie;
  }

  return this;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Translation table walk functions:                                         */
/*   There are two versions, one that is called from the real memory model   */
/* and one for use from the RDI code (that does not affect the TLB contents) */

static void CP15Reg4(Memory *mem,ARMword value);

static VirtLevel1 *TranslationWalk(Memory *mem,ARMword address,
                                    ARMul_acc acc)
{
  VirtMemory *vm_usr=&mem->usr_mode,*vm_svc=&mem->svc_mode;
  VirtLevel1 *vl1_usr,*vl1_svc;
  ARMword level1d;
  TFlags access;
  ARMword domain;
  ARMword lookup;
  unsigned int i,j;             /* G.P. counters */
  ARMword w;
  
/*printf("TranslationWalk(%08x,%d)\n",address,acc);
CP15Reg4(mem,3);*/
  
  ARMul_RaiseEvent(mem->state,
                   acc_OPC(acc) ? MMUEvent_ITLBWalk
                   : MMUEvent_DTLBWalk,
                   address,
                   mem->tlb.buffer[mem->tlb.nexttodie].virt);
  
  vl1_usr=vm_usr->level[LEVEL1inMEM(address)];
  vl1_svc=vm_svc->level[LEVEL1inMEM(address)];
  
  debug0((mem->priv_mode) ? "  SVC mode\n" : "  USR mode\n");
  
  /* Undummy the level1v */
  if (vl1_usr==DummyV1) {
    ARMword off=LEVEL1inMEM(address);
    debug0("  Undummying vl1\n");
    if (NewFail(mem->raw_usr.level[off]=vm_usr->level[off]=vl1_usr,
                mem,VirtLevel1) ||
        NewFail(mem->raw_svc.level[off]=vm_svc->level[off]=vl1_svc,
                mem,VirtLevel1))
      return NULL;
    *vl1_usr=*vl1_svc=*DummyV1;
  }
  
  /* If benchmarking, prepare for a direct memory access */
  if (mem->wb.words || (mem->cache.fetching_line &&
                        FinishLineFetch(mem,0,FALSE)))
    EmptyWriteBuffer(mem);
  
  /* call access fn. @@@ */
  FastCycle(mem);
  PhysAccess(mem,(mem->mmu.ttb | ((address>>20)<<2)),NULL,acc_Icycle);
  PhysAccess(mem,(mem->mmu.ttb | ((address>>20)<<2)),&w,acc_LoadWordS);
  level1d=w;

  mem->clock.next_mem_cycle=0;
  
  if (mem->abortSig) {                /* case ABORT: @@@ */
    error0("Bus error on level1 fetch.\n");
    if (acc_nOPC(acc)) {
      FAULT(mem,0xc,0,address);
      SETABORTING(mem);
    }
    return NULL;
  }
  
  /* Get domain, U and possibly C,B bits from level1d */
  if (!(mem->prop & MMU_Updateable_Prop))
    level1d |= (1<<4);           /* Set U-bit... */
  
  access=(level1d & 0x1fc);
  domain=(level1d>>5)&0xf;
  /* Lookup value for access array without the ap bits */
  lookup=((mem->mmu.dac[domain]) |
          ((mem->mmu.control & MMU_RS)>>(MMU_RS_bit-4)));
  
  debug3("  Level1d %08x Domain %d Lookup %d\n",
         level1d,domain,lookup);
  
  /* Switch on type of descriptor */
  switch (level1d & 3) {
  case 0: case 3:             /* Fault */
    /* Generate section translation fault */
    error2("Section translation fault (address %08x) in TranslationWalk%s\n",
           address,acc_OPC(acc) ? " OPC" : "");
    if (acc_nOPC(acc)) {
      FAULT(mem,5,domain,address);
      SETABORTING(mem);
    }
    return NULL;
    
  case 1: {                   /* Page table */
    ARMword sld_addr=(level1d & ~0x3ff) | (address<<12>>22);
    ARMword level2d;
    ARMword aps;
    TFlags access_mask;
    ARMword offset;
    
    debug0("  Page table fetched\n");
    
    level1d &= ~0x020c;       /* Clear undef bits */
    
    /* do access_fn thing. @@@ */
    FastCycle(mem);
    PhysAccess(mem,sld_addr & ~3,NULL,acc_Icycle);
    PhysAccess(mem,sld_addr & ~3,&w,acc_LoadWordS);
    level2d=w;
    mem->clock.next_mem_cycle=0;
    
    if (mem->abortSig) {
      error0("Bus error on level2 fetch.\n");
      if (acc_nOPC(acc)) {
        FAULT(mem,0xe,domain,address);
        SETABORTING(mem);
      }
      return NULL;
    }
    
    debug1("  Level2d %08x\n",level2d);
    
    /* Get ap bits into bits 2/3 ready... */
    aps=level2d>>2;
    
#ifdef COUNT_TRANSLATIONS
    mem->TranslationCount++;
#endif
    
    /* Add C/B flags to access permissions (clear those two bits first) */
    access= (access & ~(TFbuffer | TFcache)) | (level2d & 0xc);
    /* Based on the ACCESS() macro */
    if ((mem->mmu.control & MMU_C) && (access & TFcache)) {
      access_mask=~0;
      if (mem->prop & Cache_WriteBack_Prop)
        access |= TFrealbuff | TFrealcache;
      else
        access |= TFrealcache; /* small optimisation? */
    } else                    /* Set mask to clear fast read path */
      access_mask = ~(TFfastr | TFofastr);
    if (!(access & TFupdate))
      access_mask &= ~(TFfastw | TFofastw);
    if ((mem->mmu.control & MMU_W) && (access & TFbuffer)) {
      if ((mem->prop & Cache_WriteBack_Prop) && (access & TFrealbuff))
        access |= TFwriteback;
      else
        access |= TFrealbuff;
    }
    
    /* Switch on level2 page type */
    switch (level2d & 3) {
    case 0: case 3:         /* Translation fault */
      error1("Page translation fault (address %08x)\n",address);
      if (acc_nOPC(acc)) {
        FAULT(mem,7,domain,address);
        SETABORTING(mem);
      }
      return NULL;
    case 1: {           /* large page */
      ARMword phys_addr;
      TLBEntry *tlb;
      
      debug0("  Large pages\n");
      
      level2d &= ~0xf000;
      
      phys_addr=(level2d & ~0xffff);
      
      offset=LEVEL2in1(address) & 0xf0; /* Virt. offset aligned to 64Kb */
      tlb=ReplaceTLBEntry(mem,vl1_usr,vl1_svc,offset<<2,64);
      tlb->l1=level1d; tlb->l2=level2d;
      tlb->virt=address & ~0xffff;
      
      /* ....size,valid */
      access |= TFpagesize_large | TFvalid;
      
      /* Fill in the access for the 64 1Kb pages */
      for (i=offset<<2;i<(offset<<2)+64;i+=16) {
        TFlags mode_part=MMUAccess[lookup | (aps & 0x0c)] & access_mask;
        TFlags page_access=access,mode_access;
        
        for (j=i;j<i+16;j+=4,phys_addr+=0x1000) {
          VirtLevel2 *fastrw=vl1_usr->cache[j>>2];
          
          if (fastrw==DummyV2) {
            mode_part &= ~(TFfastr | TFofastr);
          }
          
          /* Set the VM bits (access, fast paths) */
          mode_access=TFthis_mode(mode_part) | page_access;
          vl1_usr->access[j]=vl1_usr->access[j+1]=
            vl1_usr->access[j+2]=vl1_usr->access[j+3]=mode_access;
          vl1_usr->read[j]=vl1_usr->read[j+1]=
            vl1_usr->read[j+2]=vl1_usr->read[j+3]=
              (mode_access & TFfastr) ? fastrw : NotFastAccess;
          vl1_usr->write[j]=vl1_usr->write[j+1]=
            vl1_usr->write[j+2]=vl1_usr->write[j+3]=
              (mode_access & TFfastw) ? fastrw : NotFastAccess;
          
          mode_access=TFother_mode(mode_part) | page_access;
          vl1_svc->access[j]=vl1_svc->access[j+1]=
            vl1_svc->access[j+2]=vl1_svc->access[j+3]=mode_access;
          vl1_svc->read[j]=vl1_svc->read[j+1]=
            vl1_svc->read[j+2]=vl1_svc->read[j+3]=
              (mode_access & TFfastr) ? fastrw : NotFastAccess;
          vl1_svc->write[j]=vl1_svc->write[j+1]=
            vl1_svc->write[j+2]=vl1_svc->write[j+3]=
              (mode_access & TFfastw) ? fastrw : NotFastAccess;
          
          vl1_usr->phys_addr[j>>2]=vl1_svc->phys_addr[j>>2]=phys_addr;
        }
        aps>>=2;
      }
    }
      /*CP15Reg4(mem,3);*/
      return (mem->priv_mode) ? vl1_svc : vl1_usr;
      
    case 2: {               /* Small page */
      ARMword phys_addr;
      TLBEntry *tlb;
      VirtLevel2 *fastrw;
      
      debug0("  Small pages\n");
      
      phys_addr=(level2d & ~0x0fff);
      
      offset=LEVEL2in1(address); /* Virtual offset */
      tlb=ReplaceTLBEntry(mem,vl1_usr,vl1_svc,offset<<2,4);
      tlb->l1=level1d; tlb->l2=level2d;
      tlb->virt=address & ~0x0fff;
      
      /* ....size,valid */
      access |= TFpagesize_small | TFvalid;
      
      fastrw=vl1_usr->cache[offset];
      
      if (fastrw==DummyV2) {
        debug0("  DummyV2\n");
        access_mask &= ~(TFfastr | TFofastr);
      }
      
      debug0(" default:\n"); ShowAccess(state,access,FALSE);
      debug0(" mask:\n"); ShowAccess(state,access_mask,FALSE);
      
      /* Fill in the access for the 4 1Kb pages */
      for (i=offset<<2;i<(offset<<2)+4;i++) {
        TFlags mode_part=MMUAccess[lookup | (aps & 0x0c)] & access_mask;
        TFlags page_access=access;
        
        debug1("  Page %d\n",i); ShowAccess(state,page_access,FALSE);
        
        page_access=TFthis_mode(mode_part) | access;
        vl1_usr->access[i]=page_access;
        vl1_usr->read[i]=(page_access&TFfastr)?fastrw:NotFastAccess;
        vl1_usr->write[i]=(page_access&TFfastw)?fastrw:NotFastAccess;
        
        page_access=TFother_mode(mode_part) | access;
        vl1_svc->access[i]=page_access;
        vl1_svc->read[i]=(page_access&TFfastr)?fastrw:NotFastAccess;
        vl1_svc->write[i]=(page_access&TFfastw)?fastrw:NotFastAccess;
        
        aps>>=2;
      }
      
      /* Set the physical memory bits (PM pointer) */
      vl1_svc->phys_addr[offset]=vl1_usr->phys_addr[offset]=phys_addr;
    }
      /*CP15Reg4(mem,3);*/
      return (mem->priv_mode) ? vl1_svc : vl1_usr;
    }
  }
    
  case 2: {                   /* Section */
    TFlags mode_part;
    ARMword phys_addr;
    TLBEntry *tlb;
    
    debug0("  Section entry fetched\n");
    
    level1d &= ~0x0ff000;     /* Clear undef bits */
    
    phys_addr=(level1d & ~0xfffff);
    
    tlb=ReplaceTLBEntry(mem,vl1_usr,vl1_svc,0,1024);
    tlb->l1=level1d; tlb->l2=0;
    tlb->virt=address & ~0xfffff;
    
    access |= TFpagesize_sectn | TFvalid;
    mode_part = MMUAccess[lookup | ((level1d & 0x0c00)>>8)];
    
    if ((mem->mmu.control & MMU_C) && (access & TFcache)) {
      if (mem->prop & Cache_WriteBack_Prop)
        access |= TFrealbuff | TFrealcache;
      else
        access |= TFrealcache;
    } else mode_part &= ~(TFfastr | TFofastr);
    if (!(access & TFupdate))
      mode_part &= ~(TFfastw | TFofastw);
    if ((mem->mmu.control & MMU_W) && (access & TFbuffer)) {
      if ((mem->prop & Cache_WriteBack_Prop) && (access & TFrealbuff))
        access |= TFwriteback;
      else
        access |= TFrealbuff;
    }
    
    debug0("  Default access bits:\n");
    ShowAccess(state,access,FALSE);
    
    /* Fill in the 1024 pages */
    for (i=0;i<LEVEL1SIZE;i++,phys_addr+=0x1000) {
      VirtLevel2 *fastrw=vl1_usr->cache[i];
      TFlags page_access,mode_access=mode_part,def=access;
      
      vl1_usr->phys_addr[i]=vl1_svc->phys_addr[i]=phys_addr;
      
      if (fastrw==DummyV2) 
        mode_access &= ~(TFfastr | TFofastr);
      
      j=i<<2;
      
      page_access=TFthis_mode(mode_access) | def;
      vl1_usr->access[j]=vl1_usr->access[j+1]=
        vl1_usr->access[j+2]=vl1_usr->access[j+3]=page_access;
      vl1_usr->read[j]=vl1_usr->read[j+1]=
        vl1_usr->read[j+2]=vl1_usr->read[j+3]=
          (page_access & TFfastr) ? fastrw : NotFastAccess;
      vl1_usr->write[j]=vl1_usr->write[j+1]=
        vl1_usr->write[j+2]=vl1_usr->write[j+3]=
          (page_access & TFfastw) ? fastrw : NotFastAccess;
      
      page_access=TFother_mode(mode_access) | def;
      vl1_svc->access[j]=vl1_svc->access[j+1]=
        vl1_svc->access[j+2]=vl1_svc->access[j+3]=page_access;
      vl1_svc->read[j]=vl1_svc->read[j+1]=
        vl1_svc->read[j+2]=vl1_svc->read[j+3]=
          (page_access & TFfastr) ? fastrw : NotFastAccess;
      vl1_svc->write[j]=vl1_svc->write[j+1]=
        vl1_svc->write[j+2]=vl1_svc->write[j+3]=
          (page_access & TFfastw) ? fastrw : NotFastAccess;
    }
  }
    /*CP15Reg4(mem,3);*/
    return (mem->priv_mode) ? vl1_svc : vl1_usr;
  }
  return NULL;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* This is the rdi (remote debug) access version */
static ARMword TranslationWalkPure(Memory *mem,ARMword address)
{
  VirtMemory *vm_usr=&mem->usr_mode,*vm_svc=&mem->svc_mode;
  VirtLevel1 *vl1_usr,*vl1_svc;
  ARMword level1d;
  ARMword domain;
  
  FUNCTION("TranslationWalkPure");
  
  vl1_usr=vm_usr->level[LEVEL1inMEM(address)];
  vl1_svc=vm_svc->level[LEVEL1inMEM(address)];
  
  /* VERY Nasty hack for testing use only, really. */
#ifdef OS_HAS_ENSURE
  ARMul_OSEnsure(state,address);
#endif
  
  if (vl1_usr==DummyV1) {
    ARMword off=LEVEL1inMEM(address);
    debug0("  Undummying vl1\n");
    if (NewFail(mem->raw_usr.level[off]=vm_usr->level[off]=vl1_usr,
                mem,VirtLevel1) ||
        NewFail(mem->raw_svc.level[off]=vm_svc->level[off]=vl1_svc,
                mem,VirtLevel1))
      return BAD_PHYS_ADDR;
    *vl1_usr=*vl1_svc=*DummyV1;
  }
  
  /* Fetch the level 1 descriptor */
{ ARMword w;
  PhysAccess(mem,(mem->mmu.ttb | ((address>>20)<<2)),&w,acc_ReadWord);
  level1d=w;
}
  if (mem->abortSig) {
    error0("Bus error on level1d fetch\n");
    return BAD_PHYS_ADDR;
  }

  debug1("  Level1d %08x\n",level1d);

  domain=(level1d>>5) & 0xf;

  switch (level1d & 3) {
  case 1: {                   /* Page table */
    ARMword sld_addr=(level1d & ~0x3ff) | (address<<12>>22);
    ARMword level2d;
    
    level1d &= ~0x020c;       /* Clear undef bits */
    
    /* Fetch the level 2 descriptor */
  { ARMword w;
    PhysAccess(mem,sld_addr & ~3,&w,acc_ReadWord);
    level2d=w;
  }
    if (mem->abortSig) {
      error0("Bus error on level2 fetch.\n");
      return BAD_PHYS_ADDR;
    }

    debug3("  Address %08x -> Level2d %08x pl2 %08x\n",
           sld_addr,level2d,pl2);
    
    switch (level2d & 3) {
    case 1:                 /* Large page */
      return (level2d & ~0xffff) | (address & 0xffff);
    case 2:                 /* Small pages */
      return (level2d & ~0xfff) | (address & 0xfff);
    default:                /* Fault (0/3) */
      /* Generate page translation fault */
      error1("Page translation fault (address %08x)\n",address);
      return BAD_PHYS_ADDR;
    }
  }

    case 2:                     /* Section */
    return (level1d & 0xfff00000) | (address & 0x000fffff);

  default:                    /* Fault (0/3) */
    /* Generate section translation fault */
    error1("\
Section translation fault (address %08x) in TranslationWalkPure\n",
           address);
    return BAD_PHYS_ADDR;
  }
}


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*                                   Cache                                     *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */

#ifdef LRU_SUPPORT

static void LRUAccess(Memory *mem,ARMword addr,VirtLevel2 *vl2)
{
  CacheLine *cl;
  CacheBlock *cb;
  Cache *cache=&mem->cache;
  flag_word set,clear;
  unsigned int idx;
  
int dbg=0;

  cl=vl2->cache_line[(addr>>2) % LEVEL2SIZE];
  cb=cl->block;
  idx=cl->entry;

  set=cl->set; clear=cl->clear;

  cb->counter=(cb->counter | set) & clear;
}

#define LRUAccessRead(mem,addr,vl2) \
  if ((mem)->prop & Cache_LRURead_Prop) LRUAccess(mem,addr,vl2)
#define LRUAccessWrite(mem,addr,vl2) \
  if ((mem)->prop & Cache_LRUWrite_Prop) LRUAccess(mem,addr,vl2)

#else

#define LRUAccessRead(mem,addr,vl2) /* do nothing */
#define LRUAccessWrite(mem,addr,vl2) /* do nothing */

#endif

static unsigned int CacheVictim(Memory *mem,CacheBlock *victim_block)
{
  flag_word prop;
  ARMword entry=0;

  prop=mem->prop;

  switch (mem->cache.replace) {
  case CacheReplace_RNG:
  default:
    /* Default to any old R.N.G. */
    entry=rand()>>2;            /* >>2 cos Unix rand() is carp. */
    break;

  case CacheReplace_ARM6RNG: {
    unsigned32 seed;
    seed=mem->cache.work[0];
    /* ARM610 R.N.G. */
    entry=((seed<<8) | (mmuBITS(seed,12,20) ^ ((seed>>25) |
                                               mem->cache.work[1])));
    mem->cache.work[1]=((seed & (1<<24)) >> (24-7));
    mem->cache.work[0]=entry;
  }
    break;

  case CacheReplace_ARM7RNG: {
    unsigned32 seed;
    seed=mem->cache.work[0];
    entry=((((seed>>12) ^ (seed>>15)) & 3) | (seed<<2));
    mem->cache.work[0]=entry;
  }
    break;

#ifdef LRU_SUPPORT
  case CacheReplace_LRU: {
    /* there's a word containing bits, one plonk of bits per line. The
     * least recently used word has all these bits cleared. Find that
     * line... (Each "plonk" is n-1 bits, where n is the number of lines
     * in the block.)
     */
    unsigned int i;
    flag_word mask;
    unsigned int step=mem->cache.size-1;        /* n-1 */
    flag_word bits=victim_block->counter;

    if (step*step+step>(1<<FLAG_WORD_BITS)) {
      fprintf(stderr,"LRU code hits odd case....\n");
      return 0;
    }

    mask=(1<<step)-1; /* n-1 set bits */

    for (i=0;i<=step;i++) {
      if ((bits & mask)==0) {
        entry=i;
        break;
      }
      mask<<=step;
    }
  }
    break;
#endif

  case CacheReplace_GblRndRobin: {
    unsigned32 seed;
    seed=mem->cache.work[0];
    /* A global round robin counter - uses the 'seed' */
    entry=seed+1;
    mem->cache.work[0]=entry;
  }
    break;

  case CacheReplace_ARM8RNG:
    if (!mem->cache.lock_down.flag) {
      unsigned32 seed=mem->cache.work[0];
      unsigned32 cycles=1;      /* @@@@@@ */
      unsigned32 i;
      unsigned32 entry=mem->cache.work[1];
      unsigned32 words=mem->cache.size;
      unsigned32 base=mem->cache.lock_down.base;

      i=cycles-mem->cache.work[2];
      mem->cache.work[2]=cycles;

      i&=0xffff;        /* @@@ performance hack */
#if 0
      while (i>12) {
        static const char bits[] = { 0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4 };
        unsigned new=((seed>>9) ^ (seed>>6)) & 0xfff;
        entry+=bits[new & 0xf]+bits[(new>>4) & 0xf]+bits[(new>>8) & 0xf];
        seed=(seed<<12) | new;
        i-=12;
      }
#endif
      while (i--) {
        unsigned new=((seed>>16) ^ (seed>>13)) & 1;
        seed=(seed<<1) | new;
        entry+=new;
      }
      entry=((entry-base) % (words-base))+base;
      mem->cache.work[0]=seed;
      mem->cache.work[1]=entry;
    } else {
      entry=mem->cache.lock_down.base;
    }
    mem->cache.work[1]=entry;
    break;

  case CacheReplace_RoundRobin:
    entry=victim_block->counter++;
    break;
  }

  return entry & (mem->cache.size-1);
}

/* Clean a cache line - copy the data to the victim buffer, so that it
 * will be written out at the next FinishLineFetch() */
static VirtLevel1 *CleanLine(Memory *mem,CacheLine victim)
{
  ARMword words=mem->cache.words;
  VirtLevel1 *vl1;
  TFlags tf;
  ARMword victim_address=victim.address;

/*printf("vl2 %08x address %08x is dirty\n",victim.page,victim.address);*/
  memcpy(mem->cache.dirty,
         GETWORDin2(victim.page->page.t.word,victim_address),
         /*
           &victim.page->page.t.word[CACHEBLOCKin2(mem,victim.address) <<
           mem->cache.log_words],
           */
         words*sizeof(ARMword));

  /* @@@ Must update the victim.phys at this point, and possibly
   * generate a terminal exception */
  vl1=mem->svc_mode.level[LEVEL1inMEM(victim_address)];
  if (vl1==OutOfDate) {
    vl1=UpdateVL1(mem,victim_address,LEVEL1inMEM(victim_address));
    if (vl1==NULL) {
      FAULT(mem,0x2,0,victim_address);
      return NULL;
    }
  }
  tf=vl1->access[BLOCKin1(victim_address)];

  if (!(tf & TFvalid)) {        /* Entry not in TLB */
    vl1=TranslationWalk(mem,victim_address,acc_StoreWordS);
    if (vl1==NULL) {    /* Terminal Exception */
      FAULT(mem,0x2,0,victim_address);
      return NULL;
    }
  }
  victim.phys_addr=vl1->phys_addr[LEVEL2in1(victim_address)];

  mem->cache.victim=victim;

  return vl1;
}

/* StartLineFetch starts a line fetch from address. */
static VirtLevel2 *StartLineFetch(Memory *mem,
                                  ARMword address,
                                  ARMul_acc acc)
{
  ARMword entry;
  CacheLine victim;
  CacheBlock *victim_block;
  VirtLevel1 *vl1_usr=mem->raw_usr.level[LEVEL1inMEM(address)];
  VirtLevel1 *vl1_svc=mem->raw_svc.level[LEVEL1inMEM(address)];
  VirtLevel2 *vl2=vl1_usr->cache[LEVEL2in1(address)];
  ARMword phys_addr=vl1_usr->phys_addr[LEVEL2in1(address)];
  CacheLine *fetching;
  ARMword word_in_line;
  ARMword words=mem->cache.words;
  ARMword *write;
  unsigned int i, purge=0;
  
  word_in_line=(address & ((words<<2)-1))>>2;
  
  /* Clear address to a 16/32 byte boundary */
  address&=~((words<<2)-1); /* first word fetched !=> first word in line! */
  
  if (mem->cache.fetching_line)
    FinishLineFetch(mem,address,TRUE);
  else if (mem->wb.words)
    EmptyWriteBuffer(mem);

  victim_block=&mem->cache.block[Assoc(mem,address)];
  entry=CacheVictim(mem,victim_block);
  victim=victim_block->line[entry];
  
  ARMul_RaiseEvent(mem->state,
                   acc_OPC(acc) ? MMUEvent_ILineFetch
                   : MMUEvent_DLineFetch,address,victim.address);
  
  if ((mem->prop & Cache_WriteBack_Prop) &&
      mem->cache.victim.phys_addr==BAD_PHYS_ADDR &&
      ISDIRTY(mem,victim.address,victim.page) &&
      CleanLine(mem,victim)==NULL)
    return NULL;
  
  UNCACHE(mem,victim.address,victim.page);
  
  /* Undummy the level2v */
  if (vl2==DummyV2) {
    ARMword level2=LEVEL2in1(address)<<2;
    if (NewFail(vl2=vl1_usr->cache[level2>>2]=vl1_svc->cache[level2>>2],
                mem,VirtLevel2))
      return vl2;
    *vl2=*DummyV2;
    debug0("  Undummying a level2v\n");
    
    UpdateTFlags(mem,vl1_usr,vl1_svc,vl1_usr->access[level2],vl2,level2);
    level2++;
    UpdateTFlags(mem,vl1_usr,vl1_svc,vl1_usr->access[level2],vl2,level2);
    level2++;
    UpdateTFlags(mem,vl1_usr,vl1_svc,vl1_usr->access[level2],vl2,level2);
    level2++;
    UpdateTFlags(mem,vl1_usr,vl1_svc,vl1_usr->access[level2],vl2,level2);
  }
  
  /* Place new page in the cache table */
#ifdef LRU_SUPPORT
  victim_block->line[entry].page=victim.page=vl2;
  victim_block->line[entry].phys_addr=victim.phys_addr=phys_addr;
  victim_block->line[entry].address=victim.address;
#else
  victim.page=vl2;
  victim.phys_addr=phys_addr;
  victim.address=address;
  victim_block->line[entry]=victim;
#endif
  
#ifdef LRU_SUPPORT
  if (mem->cache.replace==CacheReplace_LRU) {
    unsigned int i;
    unsigned int base=CACHEBLOCKin2(mem,address)<<mem->cache.log_words;
    for (i=0;i<words;i++)
      vl2->cache_line[base+i]=&victim_block->line[entry];
  }
#endif
  
  fetching=&victim_block->line[entry];
  
  write=&(vl2->page.t.word[CACHEBLOCKin2(mem,address) <<
                           mem->cache.log_words]);
  
  debug1("StartLineFetch(%d)\n",wordinline);
  debug_timing(mem);
  
  phys_addr=PHYS_ADDR(phys_addr,address);

  FastCycle(mem);
  PhysAccess(mem,phys_addr,NULL,acc_Icycle);
  for (i=0;i<=word_in_line;i++,address+=4,phys_addr+=4) {
    if (purge) mem->abortSig=FALSE;
    PhysAccess(mem,phys_addr,&write[i],acc_LoadWordS);
    MARKCACHEword(mem,address,vl2);
    if (mem->abortSig) purge=1;
  }

  mem->cache.fetching_line=word_in_line+1;
  mem->cache.fetch_type=acc_OPC(acc) ? fetch_OPC : fetch_DATA;
  mem->cache.fetching=fetching;
  mem->cache.write=write;

  if (purge) {
    mem->cache.purge=1;         /* signal to purge at the end */
    if (mem->abortSig) {
      if (acc_nOPC(acc) && !ABORTING(mem)) {
        TFlags tf=mem->virt->level[LEVEL1inMEM(address)]->access[BLOCKin1(address)];
        FAULT(mem,(tf & TFsection) ? 0x4 : 0x6,TFdomain_get(tf),
              (address-4) & ~((words<<2)-1));
        SETABORTING(mem);
      }
      return NULL;
    }
  }

  return vl2;
}

/* Cache replacement stuff. Cache macros are in armmmuP.h
 * This is the slow version that checks for
 * (a) I/O pages and (b) dummy level2vs */
static VirtLevel2 *ReadCacheReplace(Memory *mem, ARMword address,
                                    ARMul_acc acc)
{
  FUNCTION("ReadCacheReplace");

  if (mem->cache.fetching_line==mem->cache.words ||
      mem->cache.fetching_line==0) { /* first word in line */
    return StartLineFetch(mem,address,acc);
  } else {
    /* continuing a line fetch */
    CacheLine *fetching=mem->cache.fetching;
    VirtLevel2 *vl2=fetching->page;
    unsigned int word=mem->cache.fetching_line++;
    ARMword phys_addr;
    ARMword fetch_addr;

    fetch_addr=fetching->address+(word<<2);

    MARKCACHEword(mem,fetch_addr,vl2);

    phys_addr=PHYS_ADDR(mem->cache.fetching->phys_addr,fetch_addr);

    PhysAccess(mem,phys_addr,
               &mem->cache.write[word],acc_LoadWordS);


    if (mem->abortSig) {
      if (acc_nOPC(acc) && !ABORTING(mem)) {
        TFlags tf=mem->virt->level[LEVEL1inMEM(address)]->access[BLOCKin1(address)];
        FAULT(mem,(tf & TFsection) ? 0x4 : 0x6,TFdomain_get(tf),
              fetching->address & ~((mem->cache.words<<2)-1));
        SETABORTING(mem);
      }
      mem->cache.purge=1;
      return NULL;
    }

    return vl2;
  }
}

#if 0
/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* The fast version is guaranteed to be called only with non-dummy vl2's */
/* and not with the rare I/O case. */
static VirtLevel2 *FastReadCacheReplace(Memory *mem, ARMword address,
                                        ARMul_acc acc,
                                        VirtLevel1 *vl1,VirtLevel2 *vl2)
{
  ARMword entry;
  CacheLine victim;
  CacheBlock *victim_block;
  ARMword offset=CACHEBLOCKin2(mem,address);
  PhysLevel2Ptr *pl2=vl1->physical[LEVEL2in1(address)];
  ARMword words=mem->cache.words;
  ARMword word_in_line;

  FUNCTION("FastReadCacheReplace");

  ARMul_RaiseEvent(mem->state,
                   acc_OPC(acc) ? MMUEvent_ILineFetch
                                : MMUEvent_DLineFetch,address,0);

  word_in_line=WORDinLINE(mem,address);
  /* Clear address to a 16/32 byte boundary */
  address &= ~((words<<2)-1);

  /* must finish the previous line fetch, since it may write out some
   * dirty data */
  if (mem->cache.fetching_line)
    FinishLineFetch(mem,address,TRUE);

  /* The processor accounts for the word offset by faking a number of gclk
   * edges to happen whilst the processor is waiting for the word to return.
   * This fools FinishLineFetch into finishing the line fetch early. */
  mem->clock.fclk+=mem->clock.fdiv*(mem->cache.replace_ticks-1);
  mem->clock.cycle+=(mem->cache.replace_ticks-1);

  /* @@@ should be configurable for different line-fetch strategies, e.g.
   * StrongARM's */
  mem->clock.delta_gclk=word_in_line ? mem->cache.words-word_in_line : 0;
  mem->cache.fetching_line=mem->cache.words; /* signal a (fast) line fetch */

  victim_block=&mem->cache.block[Assoc(mem,address)];
  entry=CacheVictim(mem,victim_block);
  victim=victim_block->line[entry];

#ifdef DEBUG
  debug3("  Cache ptr %08x, Read %08x, Write %08x\n",
         vl2,vl1->read[LEVEL2in1(address)],
         vl1->write[LEVEL2in1(address)]);

  if (ISCACHED(address,vl2))
    printf("Warning: Page is already cached! Page %08x Read %08x Write %08x (Fast)\n",
           vl2,vl1->read[BLOCKin1(address)],vl1->write[BLOCKin1(address)]);

  debug2("  cache entry %x of block %d\n",
         Entry(mem,newseed),Assoc(mem,address));

  if (vl2==DummyV2) printf("  Warning: DummyV2 passed in to FRCR\n");
#endif

#ifdef COUNT_CACHE_MISSES
  mem->CacheMiss[WORDinLINE(mem,address)]++;
#endif

  if ((mem->prop & Cache_WriteBack_Prop) &&
      ISDIRTY(mem,victim.address,victim.page) &&
      CleanLine(mem,victim)==NULL) return NULL;

  debug4("  Uncaching page %08x address %08x [%d][%d]\n",
         victim.page,victim.address,
         Assoc(mem,victim.address),entry);
  UNCACHE(mem,victim.address,victim.page);

  /* Cache the data directly */
  MARKCACHE(mem,address,vl2);
  memcpy(&vl2->page.t.word[offset<<mem->cache.log_words],
         &pl2->page->t.word[offset<<mem->cache.log_words],
         words*sizeof(ARMword));

  if (0 /*pl2->access.fn.time*/) {    /* may still have to account for access */
#if 0
    ns t;
    unsigned int i;
    void *handle=pl2->access.handle;
    ARMul_time *time_fn=pl2->access.fn.time;
    ARMword local_address=address;

    t=time_fn(handle,acc_Icycle,local_address);
    
    for (i=0;i<words;i++,local_address+=4) {
      t+=time_fn(handle,acc_LoadWordS,local_address);
    }
    mem->clock.mclk+=t;
#endif
  } else {
    mem->clock.mclk+=words+1;
  }

  debug4("  Caching page %08x address %08x [%d][%d]\n",
         vl2,address,Assoc(mem,address),entry);

  /* Add to the cache table */
  victim.page=vl2;
  victim.phys=pl2;
  victim.address=address;
#ifdef LRU_SUPPORT
  if (mem->cache.replace==CacheReplace_LRU) {
    victim.block=victim_block;
    victim.entry=entry;
    victim.set=mem->cache.lru_set[entry];
    victim.clear=mem->cache.lru_clear[entry];
  }
#endif
  victim_block->line[entry]=victim;
  
#ifdef LRU_SUPPORT
  if (mem->cache.replace==CacheReplace_LRU) {
    unsigned int i,base=offset<<mem->cache.log_words;
    for (i=0;i<words;i++)
      vl2->cache_line[base+i]=&victim_block->line[entry];
  }
#endif

  /* mark as the fetching line - this enables interlocks to work */
  mem->cache.fetching=&victim_block->line[entry];

#ifdef DEBUG
  /* if (MMU_debug) */ CheckCache(state,address);
#endif

  return vl2;
}
#endif                          /* FastReadCacheReplace */


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\
*                                                                             *
*                         External memory interface                           *
*                                                                             *
\* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */


/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* Function that resets the VM pointer after an abort */
static VirtMemory *ResetAbort(Memory *mem)
{
  SETVIRTUAL(mem,mem->priv_mode ? &mem->svc_mode : &mem->usr_mode);
  return mem->virt;
}

#define SORT_OUT_ABORTING \
  vl1=(vm=ResetAbort(state,mem))->level[LEVEL1inMEM(address)]


static int AbortRead(Memory *mem, ARMword address,
                     ARMword *data, ARMul_acc acc)
{
  VirtLevel1 *vl1=mem->virt->level[LEVEL1inMEM(address)];
  TFlags tf=vl1->access[BLOCKin1(address)];

  IGNORE(data);
  
  if (acc_nOPC(acc) && !ABORTING(mem)) {
    ACCESS_FAULT(tf,mem,address);
    SETABORTING(mem);
  }

  return -1;
}

static int CheckAlign(Memory *mem,ARMword address,
                      ARMword *data, ARMul_acc acc)
{
  if (!(mem->mmu.control & MMU_A)) {
    switch (acc_WIDTH(acc)) {
    case BITS_16:
      return MemAccess(mem,address & ~1,data,acc);
    case BITS_32: default:
      return MemAccess(mem,address & ~3,data,acc);
    }
  } else {
    error1("Alignment fault on word fetch at address %08x.\n",address);
    if (!ABORTING(mem)) {
      FAULT(mem,0x1,0,address);
      SETABORTING(mem);         /* @@@ believed to fix a fault */
    }
    FastCycle(mem);
    return -1;
  }
}

static int CheckAlign2(Memory *mem,ARMword address,
                       ARMword *data, ARMword *data2, ARMul_acc acc)
{
  if (!(mem->mmu.control & MMU_A)) {
    switch (acc_WIDTH(acc)) {
    case BITS_16:
      return MemAccess2(mem,address & ~1,data,data2,acc);
    case BITS_32: default:
      return MemAccess2(mem,address & ~3,data,data2,acc);
    }
  } else {
    error1("Alignment fault on word fetch at address %08x.\n",address);
    if (!ABORTING(mem)) {
      FAULT(mem,0x1,0,address);
      SETABORTING(mem);         /* @@@ believed to fix a fault */
    }
    FastCycle(mem);
    return -1;
  }
}

/* Macro for the physical page */
#define PL2 (vl1->phys_addr[LEVEL2in1(address)])
#define RETURN_WORD *data=w; return 1;
#define RETURN_ABORT *data=ARMul_ABORTWORD; return -1;

static int MemAccessPure(Memory *mem,
                         ARMword address,
                         ARMword *data,
                         ARMul_acc acc)
{
  if (acc_MREQ(acc)) {
    VirtMemory *vm;
    VirtLevel1 *vl1;
    VirtLevel2 *vl2;
    ARMword phys_addr;
    TFlags tf;

    vm=mem->virt;
    vl1=vm->level[LEVEL1inMEM(address)];

    if (vm==Aborting) return -1;
    if (vl1==OutOfDate) {
      vl1=UpdateVL1(mem,address,LEVEL1inMEM(address));
      if (vl1==NULL) return -1;
    }
    vl2=vl1->cache[LEVEL2in1(address)];

    if (ISCACHED(address,vl2)) {
      if (acc_READ(acc)) {
        switch (acc & WIDTH_MASK) {
        case BITS_32:
          *data=*GETWORDin2(vl2->page.t.word,address);
          break;
        case BITS_16:
          *data=*GETHALFin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
          break;
        case BITS_8:
          *data=*GETBYTEin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
          break;
        case BITS_64:
          /* pure 64-bit accesses not allowed? */
        default:
          /* bad access request */
          return -1;
        }
        return 1;
      } else {                  /* write to cache */
        switch (acc & WIDTH_MASK) {
        case BITS_32:
          *GETWORDin2(vl2->page.t.word,address)=*data;
          break;
        case BITS_16:
          *GETHALFin2(vl2->page.t.word,address,
                      HostEndian!=mem->bigendSig)=*data;
          break;
        case BITS_8:
          *GETBYTEin2(vl2->page.t.word,address,
                      HostEndian!=mem->bigendSig)=*data;
          break;
        }
      }
    }
      
    tf=vl1->access[BLOCKin1(address)];
    if (tf & TFvalid)
      phys_addr=PL2;
    else {
      phys_addr=TranslationWalkPure(mem,address);
      if (phys_addr==BAD_PHYS_ADDR) {
        return -1;
      }
    }
    
    phys_addr=PHYS_ADDR(phys_addr,address);

    PhysAccess(mem,phys_addr,data,acc);
  }

  return 1;
}


static int FetchV0NotFastAccess(Memory *mem,ARMword address,
                                ARMword *data,ARMword *data2,ARMul_acc acc,
                                VirtMemory *vm, VirtLevel1 *vl1,
                                VirtLevel2 *vl2)
{
  TFlags tf;
  ARMword phys_addr;

  SETFASTL2(mem,NotFastAccess,0,0);
  
  verbose("V0_outofdate");
  if (vm==Aborting) {
    if (acc_OPC(acc) || !acc_SEQ(acc)) {
      vl1=(vm=ResetAbort(mem))->level[LEVEL1inMEM(address)];
    } else {            /* acc_LoadWordN */
      /* *data=0; */
      FastCycle(mem);
      return -1;
    }
  }
  if (vl1==OutOfDate) {
    vl1=UpdateVL1(mem,address,LEVEL1inMEM(address));
    if (vl1==NULL) return -1;
  }
  
  tf=vl1->access[BLOCKin1(address)];

  if (!(tf & TFvalid)) {        /* TLB entry not found */
    if (acc_SPEC(acc)) return 0;
    vl1=TranslationWalk(mem,address,acc);
    if (vl1==NULL) return -1;
    tf=vl1->access[BLOCKin1(address)];
    debug1("  New %d\n",BLOCKin1(address)); ShowAccess(state,tf,FALSE);
  }
  
  if (!(tf & TFread)) {
    error1("Data abort on read of %08x.\n",address);
    /* CACHED_EXIT_TIMING; - increment gclk - done at exit */
    return AbortRead(mem,address,data,acc);
  }
  
  if (tf & TFrealcache) { /* Update the cache */
    int words=1;

    vl2=vl1->cache[LEVEL2in1(address)];
    if (!ISCACHED(address,vl2))  {
      if (acc_SPEC(acc)) return 0;
      vl2=ReadCacheReplace(mem,address,acc);
      if (vl2==NULL) return -1;
    } else {
      FastCycle(mem);
    }
    
    switch (acc & WIDTH_MASK) {
    case BITS_64:
      if (WORDinLINE(mem,address+4)) {
        ARMword w2=*GETWORDin2(vl2->page.t.word,address+4);
        if (w2 || ISCACHED(address+4,vl2)) {
          *data2=w2;
          words=2;
        }
      }
    case BITS_32:
      *data=*GETWORDin2(vl2->page.t.word,address);
      break;
    case BITS_16:
      *data=*GETHALFin2(vl2->page.t.word,address,
                        HostEndian!=mem->bigendSig);
      break;
    case BITS_8:
      *data=*GETBYTEin2(vl2->page.t.word,address,
                        HostEndian!=mem->bigendSig);
      break;
    }
    LRUAccessRead(mem,address,vl2);
    return words;
  }
  
  MARK(FetchV0_readfromphys);

  /* Read from physical memory */
  if (mem->wb.words) EmptyWriteBuffer(mem);

  phys_addr=PHYS_ADDR(PL2,address);
  if (!acc_SEQ(acc)) {
    FastCycle(mem);
    PhysAccess(mem,phys_addr,NULL,acc_Icycle);
    acc|=acc_seq;
  }
  PhysAccess(mem,phys_addr,data,acc);
  if (mem->prop & MMU_IdleCycles_Prop) mem->clock.next_mem_cycle=0;
  if (mem->abortSig) {
    if (acc_nOPC(acc)) {        /* can't have an unaccountable opc fetch */
      /* FSR/FAR not updated for prefetch aborts */
      if (tf & TFsection)
        FAULT(mem,0x8,TFdomain_get(tf),address);
      else
        FAULT(mem,0xa,TFdomain_get(tf),address);
      SETABORTING(mem);
      return -1;
    }
    error1("Bus error on read from %08x.\n",address);
    return AbortRead(mem,address,data,acc);
  }
  return 1;
}

/*
 * Function for dealing with a "locked" access
 */
static int Locked(Memory *mem,ARMword address,
                  ARMword *data,ARMul_acc acc,
                  VirtLevel1 *vl1)
{
  TFlags tf;
  ARMword phys_addr;

  if (vl1==OutOfDate) {
    vl1=UpdateVL1(mem,address,LEVEL1inMEM(address));
    if (vl1==NULL) return -1;
  }

  tf=vl1->access[BLOCKin1(address)];

  FinishLineFetch(mem,address,FALSE);
  EmptyWriteBuffer(mem);

  if (!(tf & TFvalid)) {
    vl1=TranslationWalk(mem,address,acc);
    if (vl1==NULL) return -1;
    tf=vl1->access[BLOCKin1(address)];
  }

  phys_addr=PHYS_ADDR(PL2,address);

  FastCycle(mem);

  if (acc_READ(acc)) {
    if (!(tf & TFread)) return AbortRead(mem,address,data,acc);
    /* Fetch data from external memory */
    PhysAccess(mem,phys_addr,NULL,acc_Icycle | acc_rlw);
    PhysAccess(mem,phys_addr,data,acc | acc_seq);
  } else if (!ABORTING(mem)) {
    unsigned32 prop=mem->prop;
    VirtLevel2 *vl2;

    vl2=vl1->cache[LEVEL2in1(address)];

    if (!(tf & TFwrite)) {
      ACCESS_FAULT(tf,mem,address);
      return -1;
    }
    if (ISCACHED(address,vl2)) {
      /* update value in cache */
      ARMword w=*data;
      if (acc_WIDTH(acc) == BITS_32) {
        *GETWORDin2(vl2->page.t.word,address)=w;
      } else {                  /* must be BITS_8 */
        *GETBYTEin2(vl2->page.t.word,address,
                    HostEndian!=mem->bigendSig)=w;
      }
      
      LRUAccessWrite(mem,address,vl2);

      if (prop & Cache_BlockInterlock_Prop) {
        flag_word interlock;
        interlock=1<<Assoc(mem,address);
        SETFASTL2(mem,NotFastAccess,0,interlock);
      } else {
        SETFASTL2(mem,NotFastAccess,0,0);
      }
    }
    if (prop & MMU_BufferSWP_Prop) {
      AddNonSEQToBuffer(mem,phys_addr,data,acc);
    } else {
      PhysAccess(mem,phys_addr,NULL,acc_Icycle | acc_rlw);
      PhysAccess(mem,phys_addr,data,acc | acc_seq);
    }
  }

  if (mem->abortSig) {
    if (!ABORTING(mem)) {
      if (tf & TFsection)
        FAULT(mem,0x8,TFdomain_get(tf),address);
      else
        FAULT(mem,0xa,TFdomain_get(tf),address);
      SETABORTING(mem);
    }
    return -1;
  }

  return 1;
}

static int WriteWordPhys(Memory *mem,ARMword address,ARMword *data,
                         ARMul_acc acc,ARMword phys_addr,TFlags tf)
{
  /* In a write-back cache we don't write the word out to physical
   * memory, unless the line isn't bufferable */

  phys_addr=PHYS_ADDR(phys_addr,address);

  if (tf & TFrealbuff) {
    if (acc_SEQ(acc)) {
      AddSEQToBuffer(mem,phys_addr,data,acc);
    } else {
      AddNonSEQToBuffer(mem,phys_addr,data,acc);
    }
    FastCycle(mem);
  } else {
    EmptyWriteBuffer(mem);
    if (!acc_SEQ(acc)) {
      FastCycle(mem);
      PhysAccess(mem,phys_addr,NULL,acc_Icycle);
      acc|=acc_seq;
    } else if (ABORTING(mem)) {
      return -1;
    }
    PhysAccess(mem,phys_addr,data,acc);
    mem->clock.next_mem_cycle=0;

    if (mem->abortSig) {
      ARMword control=mem->mmu.control;
      error1("Bus error on write to %08x.\n",address);
      if ((control & MMU_W) && (tf & TFbuffer))
        FAULT(mem,0x2,TFdomain_get(tf),address);
      else if (tf & TFsection)
        FAULT(mem,0x8,TFdomain_get(tf),address);
      else
        FAULT(mem,0xa,TFdomain_get(tf),address);
      SETABORTING(mem);
      return -1;
    }
  }

  return 1;
}

static int WriteV0(Memory *mem,ARMword address,ARMword *data,
                          ARMul_acc acc,VirtMemory *vm,VirtLevel1 *vl1)
{
  VirtLevel2 *vl2;
  TFlags tf;
  
  vl2=vl1->write[BLOCKin1(address)];
  tf=vl1->access[BLOCKin1(address)];

  if (mem->cache.fetching_line)
    FinishLineFetch(mem,address,TRUE);
  
  if (ISCACHED(address,vl2)) {
    ARMword w;
    flag_word prop;

    MARK(WriteV0_fastpath);
  write_word_in_cache:
    w=*data;
    MARK(WriteV0_updatecache);
    switch (acc & WIDTH_MASK) {
    case BITS_32:
      *GETWORDin2(vl2->page.t.word,address)=w;
      break;
    case BITS_16:
      *GETHALFin2(vl2->page.t.word,address,
                  HostEndian!=mem->bigendSig)=w;
      break;
    case BITS_8:
      *GETBYTEin2(vl2->page.t.word,address,
                  HostEndian!=mem->bigendSig)=w;
      break;
    }

    /* a write might lead to the cache being interlocked, or partially
     * interlocked on the next cycle */

    prop=mem->prop;
    if (prop & Cache_BlockInterlock_Prop) {
      flag_word interlock;
      interlock=1<<Assoc(mem,address);
      SETFASTL2(mem,NotFastAccess,0,interlock);
    } else {
      SETFASTL2(mem,NotFastAccess,0,0);
    }

    LRUAccessWrite(mem,address,vl2);

    /* We might have got here from !acc_ACCOUNT(acc) below. */
    if (tf & TFwriteback) {
/*printf("Marking vl2 %8x address %08x dirty data %08x\n",vl2,address,w);*/
      MARKDIRTY(address,vl2);   /* only write it to the cache */
      FastCycle(mem);
      return 1;
    }
  } else {                      /* not in the cache */
    SETFASTL2(mem,NotFastAccess,0,0);

    if (vl2==NotFastAccess) {
      MARK(WriteV0_notfastaccess);
      if (vm==Aborting) return -1;
      if (vl1==OutOfDate) {
        vl1=UpdateVL1(mem,address,LEVEL1inMEM(address));
        if (vl1==NULL) return -1;
        tf=vl1->access[BLOCKin1(address)]; /* update tf */
      }
      
      if (!(tf & TFvalid)) {        /* TLB entry not found */
        vl1=TranslationWalk(mem,address,acc);
        if (vl1==NULL) {
        abort_write:      
          SETABORTING(mem);
          return -1;
        }
        tf=vl1->access[BLOCKin1(address)];
        debug1("  New %d\n",BLOCKin1(address));
        ShowAccess(state,tf,FALSE);
      }
      
      if (!(tf & TFwrite)) {
        ACCESS_FAULT(tf,mem,address);
        error1("Data abort on write to %08x.\n",address);
        goto abort_write;
      }
            
      if (tf & TFupdate) {
        /* vl2 may have changed anywhere above... */
        vl2=vl1->cache[LEVEL2in1(address)];
        if (ISCACHED(address,vl2)) {
          goto write_word_in_cache;
        }
      }
    } else {                    /* fast access */
      MARK(WriteV0_fastaccess);
      tf=vl1->access[BLOCKin1(address)];
    }
  }
  
  return WriteWordPhys(mem,address,data,acc,PL2,tf);
}

static int MemAccess(void *handle,
                     ARMword address,
                     ARMword *data,
                     ARMul_acc acc)
{
  Memory *mem=(Memory *)handle;
  VirtMemory *vm;
  VirtLevel1 *vl1;

#ifdef VERIFY
  ARMword w2;
  w2=verify_MemAccess(&verify,address,data ? *data : 0,acc);
#  define VERIFY_WORD(X) if (*data!=w2) { \
  printf("ARMul_MemAccess(%08x,%08x)->%08x NOT %08x [%d]\n", \
         address,acc,*data,w2,X); }
#else
#  define VERIFY_WORD(X)
#endif

/*printf("%02x %08x: fclk %8d gclk %2d mclk %8d sync %8d\n",acc,address,
       mem->fclk,mem->delta_gclk,mem->mclk,mem->sync);*/

  /*
   * SuperFast path doesn't work with LRU, yet, since we do not have
   * the vl2 for the s.f.p. to update the LRU word.
   */
  if (acc==acc_LoadInstrS) {
    ARMword fast_addr=address & 0x03fc;
    if (fast_addr) {
#ifdef LRU_SUPPORT
      VirtLevel2 *vl2=mem->fast_l2;
      SmallLevel2 *l2_fast=vl2->fast;
#else
      SmallLevel2 *l2_fast=mem->fast_l2;
#endif
      ARMword w=( *((ARMword *)(((char *)(l2_fast->word))+fast_addr)) );
      if (w) {
        MARK(MemAccess_SuperFast);
        LRUAccessRead(mem,address,vl2);
        *data=w; VERIFY_WORD(1);
        FastCycle(mem);
        return 1;
      }
    }
  }

  if (acc_nACCOUNT(acc))
    return MemAccessPure(mem,address,data,acc);

  vm=mem->virt;
  vl1=vm->level[LEVEL1inMEM(address)];

  if (acc_MREQ(acc)) {
    if (acc_nOPC(acc)) {
      switch (acc_WIDTH(acc)) {
      case BITS_8:  break;
      case BITS_16: if (!(address & 1)) break; /* else fall through */
      case BITS_32: if (address & 3) return CheckAlign(mem,address,data,acc);
      }
    }

    if (acc_LOCK(acc)) {
      return Locked(mem,address,data,acc,vl1);
    }

    if (acc_READ(acc)) {
      ARMword w;
      VirtLevel2 *vl2;

      MARK(MemAccess_Read);
      vl2=vl1->read[BLOCKin1(address)];

      /* need some other condition to avoid this call */
      if (mem->cache.fetching_line) {
        if (!acc_SEQ(acc) || mem->cache.fetch_type==fetch_INTERNAL)
          FinishLineFetch(mem,address,TRUE);
      }
      
      switch (acc_WIDTH(acc)) {
      case BITS_32:
        w=*GETWORDin2(vl2->page.t.word,address);
        break;
      case BITS_16:
        w=*GETHALFin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
        break;
      case BITS_8:
        w=*GETBYTEin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
        break;
      default:
        /* bad access */
        w=0;
      }
      if (w || ISCACHED(address,vl2)) {
        if (acc_OPC(acc)) SETFASTL2(mem,vl2,address,0);
        else SETFASTL2(mem,NotFastAccess,0,0);
        LRUAccessRead(mem,address,vl2);
        *data=w; VERIFY_WORD(2);
        FastCycle(mem);
        return 1;
      }
      
#if 0
      if (vl2!=NotFastAccess) {
        if (acc_SPEC(acc)) return 0;
        vl2=FastReadCacheReplace(state,address,acc,vl1,vl2);
        goto read_word;         /* Try read again with new data */
      }
#endif


      return FetchV0NotFastAccess(mem,address,data,NULL,acc,
                                  vm,vl1,vl2);

    } else {                    /* write */
      MARK(MemAccess_Write);
      return WriteV0(mem,address,data,acc,vm,vl1);
    }      
  } else { /* I or C cycle */
    MARK(MemAccess_NonMemoryCycle);

    SETFASTL2(mem,NotFastAccess,0,0);

    if (acc_CYCLE(acc)==acc_typeC) {
      /* Ccycle - finish linefetch/flush writebuffer first */
      FinishLineFetch(mem,address,FALSE);
      EmptyWriteBuffer(mem);
    } else if (mem->cache.fetching_line) {
      /* fetch a word from memory */
      if (mem->cache.fetching_line==mem->cache.words)
        FinishLineFetch(mem,0,FALSE);
      else
        ReadCacheReplace(mem,0,0);
      mem->cache.fetch_type=fetch_INTERNAL;
    } else if (mem->mmu.control & MMU_M) {
      FastCycle(mem);
    } else {
      PhysAccess(mem,address,data,acc);
    }

    /* actually account for it, or what? */
  }

  debug1("Exiting with data=%08x\n",data ? *data : 0xdeadbeef);
  return 1;
}

static int MemAccess2(void *handle,
                      ARMword address,
                      ARMword *data,ARMword *data2,
                      ARMul_acc acc)
{
  Memory *mem=(Memory *)handle;
  VirtMemory *vm;
  VirtLevel1 *vl1;

/*printf("%02x %08x: fclk %8d gclk %2d mclk %8d sync %8d\n",acc,address,
       mem->fclk,mem->delta_gclk,mem->mclk,mem->sync);*/

  if (acc==acc_LoadInstrS2) {
    ARMword fast_addr=address & 0x03fc;
    if (fast_addr) {
#ifdef LRU_SUPPORT
      VirtLevel2 *vl2=FASTL2(mem);
      SmallLevel2 *l2_fast=vl2->fast;
#else
      SmallLevel2 *l2_fast=FASTL2(mem);
#endif
      ARMword *wp=((ARMword *)(((char *)(l2_fast->word))+fast_addr));
      ARMword w1=wp[0];
      if (w1) {
        MARK(superfast2);
        if (WORDinLINE(mem,address+4)) {
          ARMword w2=wp[1];
          if (w2) {
            *data2=w2;
            *data=w1;
            LRUAccessRead(mem,address,vl2);
            FastCycle(mem);
            return 2;
          }                     /* else fall to slow code. */
        } else {
          LRUAccessRead(mem,address,vl2);
          *data=w1;
          FastCycle(mem);
          return 1;
        }  
      }
    }
  }

  if (!acc_ACCOUNT(acc))
    return MemAccessPure(mem,address,data,acc);

  MARK(fastpath2);
  vm=mem->virt;
  vl1=vm->level[LEVEL1inMEM(address)];

  if (acc_MREQ(acc)) {

    if (acc_nOPC(acc)) {
      switch (acc_WIDTH(acc)) {
      case BITS_8:  break;
      case BITS_16: if (!(address & 1)) break; /* else fall through */
      case BITS_64:
      case BITS_32: if (address & 3) return CheckAlign2(mem,address,data,data2,acc);
      }
    }

    if (acc_READ(acc)) {
      ARMword w1;
      VirtLevel2 *vl2;
      int words=1;

      vl2=vl1->read[BLOCKin1(address)];

      if (mem->cache.fetching_line) {
        if (acc_SPEC(acc)) {
          if (mem->cache.fetching_line==mem->cache.words)
            FinishLineFetch(mem,address,TRUE);
          else {
            /* during a linefetch */
            ReadCacheReplace(mem,0,0);
            return 0;
          }
        } else if ((acc_OPC(acc) && mem->cache.fetch_type!=fetch_OPC)) {
          FinishLineFetch(mem,address,TRUE);
        } else if (!acc_SEQ(acc)) {
          FinishLineFetch(mem,address,TRUE);
        } else if (mem->cache.fetch_type==fetch_INTERNAL) {
          /*
           * If this is a seq instr fetch, and we're not doing an instr linefetch,
           * or this is a non-seq fetch,
           * or we've had an internal cycle,
           * then complete the linefetch before procedeing
           */
          FinishLineFetch(mem,address,TRUE);
        }
      }
      
      switch (acc & WIDTH_MASK) {
      case BITS_64:
        /* If at the end of a line, return only one word */
        if (WORDinLINE(mem,address+4)) {
          ARMword w2=*GETWORDin2(vl2->page.t.word,address+4);
          if (w2 || ISCACHED(address+4,vl2)) {
            *data2=w2;
            words=2;
          }
        }
        /* fall through to... */
      case BITS_32:
        w1=*GETWORDin2(vl2->page.t.word,address);
        break;
      case BITS_16:
        w1=*GETHALFin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
        break;
      case BITS_8:
        w1=*GETBYTEin2(vl2->page.t.word,address,HostEndian!=mem->bigendSig);
        break;
      default:
        /* bad access */
        w1=0;
      }

      if (w1 || ISCACHED(address,vl2)) {
        if (acc_OPC(acc)) SETFASTL2(mem,vl2,address,0);
        else SETFASTL2(mem,NotFastAccess,0,0);
        *data=w1;
        LRUAccessRead(mem,address,vl2);
        FastCycle(mem);
        return words;
      }
      
#if 0
      if (vl2!=NotFastAccess) {
        /* don't do a line fetch for speculative fetches */
        if (acc_SPEC(acc)) return 0;
        vl2=FastReadCacheReplace(state,address,acc,vl1,vl2);
        goto read_word;         /* Try read again with new data */
      }
#endif

      return FetchV0NotFastAccess(mem,address,data,data2,acc,
                                  vm,vl1,vl2);

    } else {                    /* write */
      return WriteV0(mem,address,data,acc,vm,vl1);
    }      
  } else { /* I or C cycle */
    MARK(non_memory_cycle2);

    SETFASTL2(mem,NotFastAccess,0,0);

    if (acc_CYCLE(acc)==acc_typeC) {
      /* Ccycle - finish linefetch/flush writebuffer first */
      FinishLineFetch(mem,address,FALSE);
      EmptyWriteBuffer(mem);
    } else if (mem->cache.fetching_line) {
      if (mem->cache.fetching_line==mem->cache.words)
        FinishLineFetch(mem,0,FALSE);
      else
        ReadCacheReplace(mem,0,0);
      /* actually account for it, or what? */
      mem->cache.fetch_type=fetch_INTERNAL;      
    } else if (mem->mmu.control & MMU_M) {
      FastCycle(mem);
    } else {
      PhysAccess(mem,address,data,acc);
    }
  }

  debug1("Exiting with data=%08x\n",data ? *data : 0xdeadbeef);
  return 1;
}

static unsigned long ReadClock(void *handle)
{
  Memory *mem=(Memory *)handle;
  ARMword clk=(mem->child.read_clock ?
               mem->child.read_clock(mem->child.handle) : 0);

  if (mem->prop & MMU_IdleCycles_Prop)
    return clk;
  else {
    double fclk=mem->NumFcycles*1000000.0;
    return clk+fclk/(double)mem->clock.conf_fclk;
  }
}

static void ResetClock(Memory *mem)
{
  if (mem->prop & MMU_IdleCycles_Prop)
    mem->clock.next_mem_cycle=0;
  else
    mem->clock.next_mem_cycle=1; /* non-zero */
  mem->clock.wb_cycle=0;
  mem->clock.control=0;

  mem->wb.words=mem->wb.addrs=0;
  mem->wb.bitfield=0;

  mem->cache.fetching_line=0;
}  

#if 0                           /* no longer used */
static ARMword hcf(ARMword a,ARMword b)
{
  while (a && b) if (a>b) a%=b; else b%=a;
  return a ? a : b;
}
#endif

static double range(ARMword value,char **mult)
{
  static char *multiplier[]={ "", "k", "M", "G" };
  double v=value;
  int i=0;

  while (v>=1000.0 && i<4) v/=1000.0,i++;

  *mult=multiplier[i];
  return v;
}

static unsigned PLLLockDetect(void *handle)
{
  Memory *mem=(Memory *)handle;

  mem->clock.control|=1<<4;     /* set PLL locked bit */
  mem->mmu.read[15]|=1<<4;

  return 0;
}

/* Set the memory/processor speeds */
static int SetClockSpeed(Memory *mem)
{
  ARMword fclk;
  static int called=0;

  fclk=mem->clock.conf_fclk;

  /* the clock is a function of the PLL. So we must decide what that       
   * clock is... fclk is REFCLK, MCLK is MCLK/PCLK. */
  switch (mem->clock.control & 0xd) { /* bits 0, 2, 3 */
  default:                      /* should not be any default cases */
    ARMul_ConsolePrint(mem->state,"MMU: MMUSetClockSpeed got to somewhere it\
 shouldn't.\n");
    break;
    /* all the D=0 cases */
  case 0:                       /* D=0 F0==0 F1==0 */
  case 4:                       /* D=0 F0==1 F1==0 */
  case 8:                       /* D=0 F0==0 F1==1 */
  case 12:                      /* D=0 F0==1 F1==1 */
    /* and the F0=0 F1=0 case */
  case 1:                       /* D=1 F0==0 F1==0 */
    /* bus clock is the fast clock source */
    if (!called) {
      char *ffac;
      double fclkd;
      fclkd=range(fclk,&ffac);
      ARMul_PrettyPrint(mem->state,", %.1f%sHz ref clock",fclkd,ffac);
    }
    if (mem->clock.conf_mclk)
      fclk=mem->clock.conf_mclk;
    break;
  case 5:                       /* D=1 F0==1 F1==0 */
    /* REFCLK (fclk) is the fast clock source */
    break;
  case 9:                       /* D=1 F0==0 F1==1 */
    /* Reserved - Do not use */
    ARMul_ConsolePrint(mem->state,
                       "MMU: Illegal PLL configuration - F1=1 F0=0.\n");
    ARMul_ConsolePrint(mem->state,
                       "     (assuming REFCLK is the fast clock source).\n");
    break;
  case 13:                      /* D=1 F0==1 F1==1 */
    /* PLL output is the fast clock source */
    /* scale refclk by 1, 2, 4 or 8 */
    if (!called) {
      char *ffac;
      double fclkd;
      fclkd=range(fclk,&ffac);
      ARMul_PrettyPrint(mem->state,", %.1f%sHz ref clock",fclkd,ffac);
    }
    fclk<<=mem->clock.refclkcfg;
    if (fclk<1e6 || fclk>10e6) {
      /* PLLCLKIn out of range */
      double fclkd;
      char *ffac;
      fclkd=range(fclk,&ffac);
      ARMul_ConsolePrint(mem->state,"\
MMU: REFCLK/%d results in PLLCLKIn being out of range. (%.1f%sHz)\n",
                         1<<mem->clock.refclkcfg,fclkd,ffac);
    }
    fclk*=mem->clock.pllcfg;
      fclk/=2;
    if (mem->clock.pllrange ? (fclk<22.5e6 || fclk>50e6)
        : (fclk<45e6 || fclk>100e6)) {
      double fclkd;
      char *ffac;
      fclkd=range(fclk,&ffac);
      ARMul_ConsolePrint(mem->state,"MMU: PLL output out of range (%.1f%sHz)\n",
                         fclkd,ffac);
    }
    break;
  }

  if (!(mem->prop & MMU_IdleCycles_Prop))
    mem->clock.fdiv=0;          /* prevent idle cycles from taking place */
  else
    mem->clock.fdiv=10000000000.0/fclk;

  if (mem->child.x.basic.get_cycle_length) {
    mem->clock.mdiv=mem->child.x.basic.get_cycle_length(mem->child.handle);
  } else {
    mem->clock.mdiv=1;
  }

  ResetClock(mem);

  if (!called) {
    char *ffac;
    double fclkd;
    fclkd=range(fclk,&ffac);
    ARMul_PrettyPrint(mem->state,", %.1f%sHz core clock",fclkd,ffac);
    called=1;
  }
  return 0;
}

/*
 * Return number of cycles used - simply call child memory model for now
 */
static const ARMul_Cycles *ReadCycles(void *handle)
{
  Memory *mem=(Memory *)handle;
  static ARMul_Cycles cycles;
  const ARMul_Cycles *p;

  if (mem->child.read_cycles==NULL) return NULL;
  
  p=mem->child.read_cycles(mem->child.handle);

  if (p==NULL) return NULL;

  cycles=*p;

  cycles.NumFcycles=mem->NumFcycles;

  cycles.Total=(cycles.NumScycles + cycles.NumNcycles + /* slow cycles */
                cycles.NumFcycles); /* fast cycles */

  return &cycles;
}


/*
 *
 * System co-processor model
 *
 */

/*
 * Kill a particular entry in the TLB
 */
static void KillThisTLBEntry(Memory *mem,unsigned n)
{
  TLBEntry kill=mem->tlb.buffer[n];
  unsigned j;

  FUNCTION("KillThisTLBEntry");

  /* Invalidate all the marked pages */
  for (j=kill.offset;j<kill.offset+kill.pagesize;j++) {
    kill.svc->access[j] = kill.usr->access[j] = 0;
    kill.svc->read[j]  = kill.usr->read[j]  = NotFastAccess;
    kill.svc->write[j] = kill.usr->write[j] = NotFastAccess;
  }

  kill.offset=0;
  kill.usr=DummyV1;
  kill.svc=DummyV1;
  kill.pagesize=0;
  kill.l1=kill.l2=0;
  mem->tlb.buffer[n]=kill;
}

/*
 * Miscellaneous CP15 ops - Cache
 */
static void InvalidateLine(Memory *mem,CacheLine *victim)
{
  /* Cache ops will hit locked-down words */
  UNCACHE(mem,victim->address,victim->page);
  victim->page=DummyV2;
  victim->phys_addr=BAD_PHYS_ADDR;
  victim->address=0;
}

static void InvalidateCache(Memory *mem)
{
  unsigned int i,j;
  unsigned int blocks,size;
  CacheBlock *cb=&mem->cache.block[0];
  unsigned int base;
  
  blocks=mem->cache.blocks;
  size=mem->cache.size;

  mem->mmu.state |= 1;          /* Set flushed bit */

  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** Invalidate cache **\n");

  base=(mem->cache.lock_down.base ? mem->cache.lock_down.flush : 0);

  for (i=base;i<blocks;i++,cb++) {
    CacheLine *cl=&cb->line[0];
    for (j=0;j<size;j++,cl++) InvalidateLine(mem,cl);
  }
}

#if 0                           /* not used */
static void PurgeCache(Memory *mem,ARMword address)
{
  int i,j;
  int blocks,size;
  CacheBlock *cb=&mem->cache.block[0];

  blocks=mem->cache.blocks;
  size=mem->cache.size;

  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** Purge cache **\n");

  for (i=0;i<blocks;i++,cb++) {
    CacheLine *cl=&cb->line[0];
    for (j=0;j<size;j++,cl++)
      if (mmuBITS((address ^ cl->address),mem->cache.log_words+2,32))
        InvalidateLine(mem,cl);
  }
}
#endif

#define IndexSeg(mem,value) \
  ((mem)->cache.block[(((unsigned32)(value))>>((mem)->cache.log_words+2)) & \
                      ((mem)->cache.blocks-1)] \
   .line[((unsigned32)(value))>>(32-(mem)->cache.log_size)])

static void BadCacheOp(Memory *mem,unsigned CRm,unsigned CpOp2)
{
  ARMul_State *state=mem->state;

  /* Unknown cache operation */
  ARMul_ConsolePrint(state,"MMU: at PC=0x%08x\n",ARMul_GetPC(state)-8);
  ARMul_ConsolePrint(state,"     Cache operation 0x%02x/0x%02x (",CRm,CpOp2);

  if (CRm & 0x8) ARMul_ConsolePrint(state,"Clean ");
  if (CRm & 0x4) ARMul_ConsolePrint(state,"Flush ");
  if (CRm & 0x1) ARMul_ConsolePrint(state,"I");
  if (CRm & 0x2) ARMul_ConsolePrint(state,"D");

  switch (CpOp2) {
  case 0: ARMul_ConsolePrint(state," Cache"); break;
  case 1: ARMul_ConsolePrint(state," Entry"); break;
  case 5: 
  case 2:
  case 3: ARMul_ConsolePrint(state," <undefined>"); break;
  case 4:
    if (CRm==0x5) ARMul_ConsolePrint(state," Prefetch");
    else if (CRm==0xa) ARMul_ConsolePrint(state," Buffer");
    else ARMul_ConsolePrint(state," <undefined>");
    break;
  case 6:
    if (CRm==0x5) ARMul_ConsolePrint(state," Target Cache");
    else ARMul_ConsolePrint(state," <undefined>");
    break;
  case 7:
    if (CRm==0x5) ARMul_ConsolePrint(state," Target Entry");
    else ARMul_ConsolePrint(state," <undefined>");
    break;
  }

  ARMul_ConsolePrint(state,") unsupported\n");
}

/* returns non-zero for an unsupported/invalid cache op */
static void CacheOp(Memory *mem,unsigned CRm,unsigned CpOp2,
                    ARMword value)
{
  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** Cache Op: **\n");

  switch (CRm) {
  default:
    break;

  case 7:
    switch (CpOp2) {
    case 0:
      InvalidateCache(mem);
      return;
    case 1:                     /* Invalidate ID entry */
      InvalidateLine(mem,&IndexSeg(mem,value));
      return;
    default:
      break;
    }
    break;

  case 11: /* @@@ Clean ID single entry */
  case 15: /* @@@ Clean and Invalidate ID entry */
    /* @@@ The format of these indexes is implementation defined. This is
     * the ARM8 code. */
    if ((mem->prop & Cache_WriteBack_Prop) && mem->cache.log_size!=-1) {
      CacheLine *victim=&IndexSeg(mem,value);

      if (mem->verbose_flag) {
        ARMul_ConsolePrint(mem->state,
                           "** Clean entry %08x (Block %02x, Line %02x - 0x%08x) - %s **\n",
                           value,
                           ((value>>(mem->cache.log_words+2)) &
                            (mem->cache.blocks-1)),
                           (value>>(32-mem->cache.log_size)),
                           victim->address,
                           ISDIRTY(mem,victim->address,victim->page) ?
                           "DIRTY" : "CLEAN");
      }
      if (ISDIRTY(mem,victim->address,victim->page) &&
          CleanLine(mem,*victim)) WriteOutVictim(mem);
      if (CRm==15) InvalidateLine(mem,victim);
      return;
    } 
  }

  BadCacheOp(mem,CRm,CpOp2);
}

/*
 * TLB Ops
 */
static void InvalidateTLB(Memory *mem)
{
  /* 
   * Flush TLB skips the "locked down" words
   */
  unsigned int i;
  unsigned int base;

  base=(mem->tlb.lock_down.base ? mem->tlb.lock_down.flush : 0);

  /*ARMul_ConsolePrint(mem->state,"TLB flush base %d\n",base);*/

  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** Flush TLB (base %d) **\n",base);

  for (i=base;i<mem->tlb.size;i++) /* Clear TLB entries to be zero */
    KillThisTLBEntry(mem,i);

  /*CP15Reg4(mem,3);*/
}  

static void PurgeTLB(Memory *mem,ARMword address)
{
  unsigned int i;
  VirtMemory *usr=&mem->usr_mode;
  VirtLevel1 *vl1_usr=usr->level[LEVEL1inMEM(address)];

  ARMword offset=BLOCKin1(address);
  
  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** Purge TLB address 0x%08x **\n",
                       address);

  /*
   * Purge TLB examines the "locked down" words
   */
  for (i=0;i<mem->tlb.size;i++) {
    ARMword tlb_offset=mem->tlb.buffer[i].offset;
    if (mem->tlb.buffer[i].usr==vl1_usr && /* Right level1 */
        tlb_offset<=offset &&              /* Good candidate */
        offset-tlb_offset<mem->tlb.buffer[i].pagesize) {
      /* Found entry */
      KillThisTLBEntry(mem,i);
      /* return ARMul_DONE; -- not necessarily the only entry... */
    }
  }
}  

static void BadTLBOp(Memory *mem,unsigned CRm,unsigned CpOp2)
{
  ARMul_State *state=mem->state;

  /* Unknown cache operation */
  ARMul_ConsolePrint(state,"MMU: at PC=0x%08x\n",ARMul_GetPC(state)-8);
  ARMul_ConsolePrint(state,"     Cache operation 0x%02x/0x%02x (",CRm,CpOp2);

  if (CRm & 0x8) ARMul_ConsolePrint(state,"<undefined> ");
  if (CRm & 0x4) ARMul_ConsolePrint(state,"Flush ");
  if (CRm & 0x1) ARMul_ConsolePrint(state,"I");
  if (CRm & 0x2) ARMul_ConsolePrint(state,"D");

  switch (CpOp2) {
  case 0: ARMul_ConsolePrint(state," TLB"); break;
  case 1: ARMul_ConsolePrint(state," Entry"); break;
  default: ARMul_ConsolePrint(state," <undefined>"); break;
  }

  ARMul_ConsolePrint(state,") unsupported\n");  
}

static void TLBOp(Memory *mem,unsigned CRm,unsigned CpOp2,ARMword value)
{
  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** TLB Op: **\n");

  switch (CRm) {
  case 7:
    switch (CpOp2) {
    case 0: InvalidateTLB(mem); return;
    case 1: PurgeTLB(mem,value); return;
    }
    break;
  }
  BadTLBOp(mem,CRm,CpOp2);
}

static void CP15Reg4(Memory *mem,ARMword value)
{
  switch (value) {
  case 0:
    ARMul_ConsolePrint(mem->state,"Writing to register 4 of ARMulator's MMU has the following actions:\n");
    ARMul_ConsolePrint(mem->state,"  0:  Display this help message.\n");
#ifdef VERBOSE_COUNT
    ARMul_ConsolePrint(mem->state,"  1:  Display memory access statistics.\n");
    ARMul_ConsolePrint(mem->state,"  2:  Reset counters for (6).\n");
#endif
    ARMul_ConsolePrint(mem->state,"  3:  Display TLB contents.\n");
    break;

#ifdef VERBOSE_COUNT
  case 1: {
    int loads=mem->Loads;
    int stores=mem->Stores;
    int total=loads+stores;
    int cache=0,i;
    
    for (i=0;i<mem->cache.words;i++) cache+=mem->CacheMiss[i];
      
    if (total==0) break;
#define PERCENT(X,T) (((X)*100.0)/(T))
    ARMul_ConsolePrint(mem->state,"\
Memory statistics:                 Number       Percentages\n\
                                           ( Global ) (  Local )\n");
    ARMul_ConsolePrint(mem->state,"\
  Total                        :%10d\n",total);
    ARMul_ConsolePrint(mem->state,"\
  Loads                        :%10d (%7.3f%%)\n",loads,PERCENT(loads,total));
    ARMul_ConsolePrint(mem->state,"\
  Stores                       :%10d (%7.3f%%)\n",stores,PERCENT(stores,total));
    ARMul_ConsolePrint(mem->state,"\
  Cache misses  (scaled)       :%10d (%7.3f%%)\n",
                     cache*mem->cache.words,PERCENT(cache*mem->cache.words,total));
    for (i=0;i<mem->cache.words;i++)
      ARMul_ConsolePrint(mem->state,"\
    Word %2d:                   :%10d (%7.3f%%) (%7.3f%%)\n",
                       i,mem->CacheMiss[i]*mem->cache.words,
                       PERCENT(mem->CacheMiss[i]*mem->cache.words,total),
                       PERCENT(mem->CacheMiss[i],cache));
    ARMul_ConsolePrint(mem->state,"\
  Translation walks (2 for page access, 1 for section)\n\
                               :%10d\n",mem->TranslationCount);
    ARMul_ConsolePrint(mem->state,"\n\
Processor statistics           :\n\
  Instructions                 :%10d\n\
  Internal (I) cycles          :%10d\n",state->NumInstrs,state->NumIcycles);
    ARMul_ConsolePrint(mem->state,"\n\
Time taken                     :%13.2fs\n",
                     (float)ARMul_ReadClock(mem->state)/1000000.0);
  }
    break;

  case 2: {
    int i;
      
    state->NumScycles=state->NumNcycles=mem->Loads=mem->Stores=0;
    for (i=0;i<mem->cache.words;i++) mem->CacheMiss[i]=0;
    mem->TranslationCount=0;
  }
    break;
#endif

  case 3: {
    TLBEntry *tlb;
    unsigned int i;
    ARMul_ConsolePrint(mem->state,"   # virtual  physical level1d  level2d   off size\n");
    for (i=0,tlb=mem->tlb.buffer;i<mem->tlb.size;i++,tlb++) {
      if (tlb->pagesize!=0) {
        if ((mem->prop & TLB_LockDown_Prop) &&
            i<mem->tlb.lock_down.base) {
          if (mem->tlb.lock_down.flag)
            ARMul_ConsolePrint(mem->state,"L");
          else
            ARMul_ConsolePrint(mem->state,"l");
        } else {
          ARMul_ConsolePrint(mem->state," ");
        }
        ARMul_ConsolePrint(mem->state," %2d %08x %08x %08x %08x %4d %4d\n",
                           i, tlb->virt, tlb->usr->phys_addr[tlb->offset],
                           tlb->l1,tlb->l2, tlb->offset, tlb->pagesize);
      }
    }
  }
    break;
    
  default:
    ARMul_ConsolePrint(mem->state,
                     "Write of %d to register 4 not understood.\n",
                     value);
    ARMul_ConsolePrint(mem->state,
                     "Use value '0' for a list of valid values.\n");
    
  }
}

/* MMU -> ARM register transfer */
static unsigned int MRC(void *handle,unsigned type,
                        ARMword instr,ARMword *value)
{
  Memory *mem=(Memory *)handle;
  unsigned reg=(unsigned)mmuBITS(instr,16,20);

  FUNCTION("MMU_MRCs");

  if (!mem->priv_mode) return ARMul_CANT;

  if (type==ARMul_INTERRUPT) return ARMul_DONE;
  if (mem->mmu.arch==3 && (reg>=mem->mmu.RegWords[0] ||
                           mem->mmu.RegWords[reg]==0)) return ARMul_CANT;
  if (reg)
    *value=mem->mmu.read[reg];
  else
    *value=mem->mmu.chip_id;
  return ARMul_DONE;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* As above, but for the RDI */
static unsigned CPRead(void *handle,unsigned reg,ARMword *value)
{
  Memory *mem=(Memory *)handle;
  ARMword v=mem->mmu.read[reg];
  FUNCTION("MMU_CPReads");
  
  if (mem->mmu.arch==3 && reg>=mem->mmu.RegWords[0]) return ARMul_CANT;
  switch (reg) {
  case 0: v=mem->mmu.chip_id; break;
  case 1: v=mem->mmu.control; break;
  case 2: v=mem->mmu.ttb;     break;
  case 3: {
    int i;
    for (i=v=0;i<16;i++)
      v|=mem->mmu.dac[i]<<(2*i);
  }
    break;
  }

  *value=v;

  return ARMul_DONE;
}

/* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * */
/* ARM -> MMU register transfer
 * Several have special cases, others are illegal. */

static const struct {
  ARMword flag;
  char *name;
} control_reg_bits[] = {
  MMU_M, "MMU",
  MMU_A, "Alignment fault",
  MMU_C, "Cache",
  MMU_W, "Write-buffer",
  MMU_P, "32-bit Program",
  MMU_D, "32-bit Data",
  MMU_L, "Late abort",
  MMU_B, "Big endian",
  MMU_S, "S bit",
  MMU_R, "R bit",
  MMU_Z, "Branch predict",
  0, NULL
  };

static void ControlRegisterWrite(Memory *mem,ARMword changes,ARMword value)
{
  int i;
  for (i=0;control_reg_bits[i].flag!=0;i++)
    if (changes & control_reg_bits[i].flag)
      ARMul_ConsolePrint(mem->state,
                         "** %s: %s **\n",
                         control_reg_bits[i].name,
                         (control_reg_bits[i].flag & value) ? "Enable" : "Disable");
}

static unsigned AssignRegister(Memory *mem,unsigned reg,
                               unsigned CRm,unsigned CpOp2,
                               ARMword value)
{
  VirtMemory *usr=&mem->usr_mode,*svc=&mem->svc_mode;
  
  FUNCTION("AssignRegister");
  
#ifdef TRACKMMUREGS
  mem->mmu.write[reg]=value;
#endif

  if (mem->verbose_flag)
    ARMul_ConsolePrint(mem->state,"** CP15 assign to register %d **\n",reg);
  
  switch (reg) {
  case 0:                     /* Ignore writes */
    if (mem->verbose_flag)
      ARMul_ConsolePrint(mem->state,"** Write to MMU non-register **\n");

    return ARMul_DONE;
    
  case 1: {                   /* Control register */
    ARMword changes;
    value=(value | mem->mmu.control_hi) & ~mem->mmu.control_lo;
    changes=value^mem->mmu.control;

    if (mem->verbose_flag)
      ARMul_ConsolePrint(mem->state,"** Write to MMU control register **\n");

    mem->mmu.control=value;
    if (mem->mmu.arch==4) mem->mmu.read[1]=value;

    if (changes & MMU_M) {    /* MMU enable has changed */
      if (value & MMU_M) {    /* M going high */
        int i;
        for (i=0;i<MEMSIZE;i++) {
          if (mem->raw_usr.level[i]!=usr->level[i] &&
              usr->level[i]!=OutOfDate &&
              usr->level[i]!=DummyV1) { /* Flat memory block */
            free(usr->level[i]);
            usr->level[i]=OutOfDate;
            debug1("    Freeing USR mode flat memory block %d.\n",i);
          }
          if (mem->raw_svc.level[i]!=svc->level[i] &&
              svc->level[i]!=OutOfDate &&
              svc->level[i]!=DummyV1) { /* Flat memory block */
            free(svc->level[i]);
            svc->level[i]=OutOfDate;
            debug1("    Freeing SVC mode flat memory block %d.\n",i);
          }
        }
      } else {                  /* M going low */
        unsigned int i;
        /* Check that the Cache will be disabled */
        if (value & MMU_C)
          ARMul_ConsolePrint(mem->state,
                             "MMU: Warning: MMU disabled while IDC still enabled.\n");
        mem->mmu.state |= 2;    /* Set "needs flush" flag */
        for (i=0;i<MEMSIZE;i++)
          usr->level[i]=svc->level[i]=OutOfDate;
        debug0("    Flush TLB\n");
        for (i=0;i<mem->tlb.size;i++)   /* Clear TLB entries to be zero */
          KillThisTLBEntry(mem,i);
      }
    } else if (changes & (MMU_RS | MMU_C | MMU_W)) {
      /* MMU enable is stable */
      if (value & MMU_M) {      /* S/C{/W} changes while M is stable high */
        int i;
        for (i=0;i<MEMSIZE;i++)
          usr->level[i]=svc->level[i]=OutOfDate;
      }
    }
    if (changes & MMU_C) {      /* Cache disabled/enabled */
      if (value & MMU_C) {      /* Cache enabled */
        if (mem->mmu.state==2)
          ARMul_ConsolePrint(mem->state,
                           "MMU: Warning: MMU has been reenabled, but the cache has not been flushed.\n");
        mem->mmu.state &= 2;    /* Clear flushed bit */
      } else {                  /* Cache disabled */
        mem->mmu.state &= 1;    /* Clear needflush bit */
      }
    }

    ARMul_SetConfig(mem->state,changes,value); /* inform ARMulator of new signals */
    mem->bigendSig=((value & MMU_B)!=0);
    
    if (mem->verbose_flag)
      ControlRegisterWrite(mem,changes,value);
  }
    return ARMul_DONE;
    
  case 2:                       /* Translation table base */
    mem->mmu.ttb=value & 0xffffc000;
    if (mem->mmu.arch==4) mem->mmu.read[2]=mem->mmu.ttb;
    return ARMul_DONE;
    
  case 3: {                   /* Domain access control */
    int i;
    if (mem->verbose_flag)
      ARMul_ConsolePrint(mem->state,
                         "** Write 0x%08x to DAC register **\n",value);
    if (mem->mmu.arch==4) mem->mmu.read[3]=value;
    for (i=0;i<16;i++,value>>=2)
      mem->mmu.dac[i]=(unsigned char)(value & 0x3);
    if (mem->mmu.control & MMU_M)
      for (i=0;i<MEMSIZE;i++)   /* OutOfDate everything */
        usr->level[i]=svc->level[i]=OutOfDate;
  }
    return ARMul_DONE;
    
  case 4:                       /* Used for debugging */
    CP15Reg4(mem,value);
    return ARMul_DONE;
    
  case 5:                       /* Flush the TLB / FSR */
    if (mem->mmu.arch==4) mem->mmu.read[5]=value;
    else InvalidateTLB(mem);
    return ARMul_DONE;
    
  case 6:                       /* Purge address / FAR */
    if (mem->mmu.arch==4) mem->mmu.read[6]=value;
    else PurgeTLB(mem,value);
    return ARMul_DONE;
    
  case 7:                       /* Flush cache / Cache operation*/
    if (mem->mmu.arch==4) {
      CacheOp(mem,CRm,CpOp2,value);
    } else {
      InvalidateCache(mem);
    }
    return ARMul_DONE;
    
  case 8:
    if (mem->mmu.arch==4) {
      TLBOp(mem,CRm,CpOp2,value);
      return ARMul_DONE;
    }
    break;

  case 9:
    if (mem->prop & Cache_LockDown_Prop) {
      mem->mmu.read[9]=value & ((1<<31) | (mem->cache.size-1));
      mem->cache.lock_down.flag=value & (1<<31);
      mem->cache.lock_down.base=value & (mem->cache.size-1);
      if (!(value & (1<<31)) &&
          !(mem->cache.lock_down.valid & (1<<value))) {
        ARMul_ConsolePrint(mem->state,"\
MMU: Illegal value (0x%08x) written to CP15 R9.\n",value);
      }
      if (mem->prop & Cache_LockDownFlush_Prop)
        mem->cache.lock_down.flush=mem->cache.lock_down.base;
      return ARMul_DONE;
    }
    break;

  case 10:
    if (mem->prop & TLB_LockDown_Prop) {
      mem->mmu.read[10]=value=value & ((1<<31) | (mem->tlb.size-1));
      /* @@@ need to make this test configurable - 0 or 4 for ARM8 */
      if (!(value & (1<<31)) &&
          !(mem->tlb.lock_down.valid & (1<<value))) {
        ARMul_ConsolePrint(mem->state,"\
MMU: Illegal value (0x%08x) written to CP15 R10.\n",value);
      }
      mem->tlb.lock_down.flag=value & (1<<31);
      mem->tlb.lock_down.base=mem->tlb.nexttodie=value & (mem->tlb.size-1);
      if (mem->prop & TLB_LockDownFlush_Prop)
        mem->tlb.lock_down.flush=mem->tlb.lock_down.base;
      return ARMul_DONE;
    }
    break;
    
#ifdef BENCHMARKING
#if 0
  case 12:
    ARMul_SetMemoryType(mem,0,0,value);
    return ARMul_DONE;
#endif
  case 13:
    mem->clock.conf_fclk=value;
    SetClockSpeed(mem);
    return ARMul_DONE;
  case 14: 
    mem->clock.conf_mclk=value;
    SetClockSpeed(mem);
    return ARMul_DONE;
#endif  

  case 15: /* ARM810 clock and test configuration */
    if ((mem->prop & MMU_PLLClock_Prop) ||
        !(mem->prop & MMU_ExternalSNA_Prop)) {
      /* check for setting L bit high */
      if (value & (1<<4)) {     /* L bit sent high */
        value&=~(1<<4);         /* on reads will come back zero until set */
        /* generate a random number of cycles to come back in */
        /* centre around 1000 */
        ARMul_ScheduleEvent(mem->state,(rand()%1000)+(rand()%1000),PLLLockDetect,mem);
      }
      /* Before we change the PLL we need to zero the clock. This is
       * because the clock value relies on the old value */
      /* ZeroClock(mem); */
      mem->mmu.read[15]=value & 0xf; /* only bottom four bits */
      mem->clock.control=value;
      SetClockSpeed(mem);
        
      return ARMul_DONE;
    }
    break;
  }
  
  if (mem->mmu.arch==4 && !(mem->prop & MMU_Undefined_Prop)) {
    ARMul_ConsolePrint(mem->state,"MMU: Warning: write to undefined MMU register\
 at PC=0x%08x",ARMul_GetPC(mem->state));
    return ARMul_DONE;
  } else {
    debug1("  Not a valid register %d\n",reg);
    return ARMul_CANT;
  }
}

/* Same as above, but takes reg as part of an instruction */
static unsigned MCR(void *handle,unsigned type,ARMword instr,ARMword v)
{
  Memory *mem=(Memory *)handle;

  FUNCTION("MMU_MCRs");
  
  return (mem->priv_mode ?
          (type==ARMul_INTERRUPT) ? ARMul_DONE :
          AssignRegister(mem,
                         (unsigned)mmuBITS(instr,16,20), /* CRn */
                         (unsigned)mmuBITS(instr,0,4), /* CRm */
                         (unsigned)mmuBITS(instr,5,8), /* CpOp2 */
                         v) :
          ARMul_CANT);
}

/* Same as above, but takes a ptr to the value (for the RDI) */
static unsigned CPWrite(void *handle,unsigned reg,ARMword const *value)
{
  FUNCTION("MMU_CPWrites");

  return AssignRegister((Memory *)handle,reg,0,0,*value);
}

/*
 * Deal with a change in mode
 */
static void TransChangeHandler(void *handle,unsigned oldt,unsigned newt)
{
  Memory *mem=(Memory *)handle;

  IGNORE(oldt);

  SETVIRTUAL(mem,newt ? &mem->svc_mode : &mem->usr_mode);
  mem->priv_mode=newt;
  mem->abortSig=FALSE;

  debug2("Change trans %d to %d\n",oldt,newt);
}

/*
 * Function called on an ARM8 after when the core reports a vector
 * exception
 */

static void CoreException(void *handle,ARMword address,ARMword penc)
{
  FAULT((Memory *)handle,penc,0,address);
}

/*
 * Function called when the ARM resets
 */

static void InterruptHandler(void *handle,unsigned int which)
{
  Memory *mem=(Memory *)handle;

  if (which & ARMul_InterruptUpcallReset) { /* we only care about reset */
    
    AssignRegister(mem,1,0,0,0);        /* reset control reg */
    AssignRegister(mem,2,0,0,0);        /* reset TTB */
    AssignRegister(mem,3,0,0,0);        /* reset domain access control */
    
    mem->mmu.read[5]=0;
    mem->mmu.read[6]=0;         /* reset FSAR */
    
    if (mem->prop & Cache_LockDown_Prop)
      AssignRegister(mem,9,0,0,0); /* reset cache lockdown */
    
    if (mem->prop & TLB_LockDown_Prop)
      AssignRegister(mem,10,0,0,0); /* reset tlb lockdown */
    
    if (mem->prop & MMU_PLLClock_Prop) 
      AssignRegister(mem,15,0,0,0); /* reset clock switching */
    
    /* Flush the TLB */
    InvalidateTLB(mem);
    
    /* Flush the cache */
    InvalidateCache(mem);

    ResetClock(mem);
  }
}

/*
 * Initialise the MMU
 */

/*
 * Function to tell the debugger about us.
 */

static int RDI_info(void *handle, unsigned type,
                    ARMword *arg1, ARMword *arg2)
{
  Memory *mem=(Memory *)handle;
  if (type==RDIInfo_MMU) {
    *arg1=mem->mmu.chip_id; IGNORE(arg2);
    return RDIError_NoError;
  } else if (type==(RDIInfo_MMU | RDIInfo_CapabilityRequest)) {
    return RDIError_NoError;
  }
  return RDIError_UnimplementedMessage;
}

static ARMul_Error CPInit(ARMul_State *state,
                          unsigned num,
                          ARMul_CPInterface *interf,
                          toolconf config,
                          void *handle)
{
  Memory *mem=(Memory *)handle;
  MMU *mmu=&mem->mmu;
  int i;
  char *option,*x;
  int arch;

  FUNCTION("MMU_CPInits");

  if (num!=15) {
    return ARMul_RaiseError(state,ARMulErr_CoProNumber,ModelName,15);
  }

  option=(void *)ToolConf_Lookup(config,"ARCHITECTURE");
  arch=option ? strtol(option,&x,0) : 3;

  for (i=1;i<16;i++) mmu->read[i]=0;

  ARMul_InstallTransChangeHandler(state,TransChangeHandler,handle);
  ARMul_InstallInterruptHandler(state,InterruptHandler,handle);

  for (i=1;i<=8;i++) mmu->RegWords[i]=1;
  for (;i<=16;i++) mmu->RegWords[i]=0;

  if (arch==3) {
    mmu->RegWords[0]=8;
  } else {
    mmu->RegWords[0]=9;
    mmu->RegWords[9]=1;
  }

  if (mem->prop & Cache_LockDown_Prop) {
    mmu->RegWords[0]=10;
    mmu->RegWords[10]=1;
  }

  if (mem->prop & TLB_LockDown_Prop) {
    mmu->RegWords[0]=11;
    mmu->RegWords[11]=1;
  }

  if ((mem->prop & MMU_PLLClock_Prop) ||
      !(mem->prop & MMU_ExternalSNA_Prop)) {
    mmu->RegWords[0]=16;
    mmu->RegWords[16]=1;
  }

  interf->mrc=MRC;
  interf->mcr=MCR;
  interf->read=CPRead;
  interf->write=CPWrite;
  interf->reg_words=mmu->RegWords;

  ARMul_PrettyPrint(state,", MMU");
  ARMul_InstallUnkRDIInfoHandler(state,RDI_info,mem);

  interf->handle=handle;

  return ARMulErr_NoError;
}

/*
 * Co-processor bus.
 */

static unsigned CPBusLDC(void *handle,unsigned type,ARMword instr,
                         ARMword value)
{
  Memory *mem=(Memory *)handle;
  if (mem->cp.flag & (1<<mmuBITS(instr,8,11)))
    FastCycle(mem);
  return mem->cp.bus.ldc(mem->cp.bus.handle,type,instr,value);
}

static unsigned CPBusSTC(void *handle,unsigned type,ARMword instr,
                         ARMword *value)
{
  Memory *mem=(Memory *)handle;
  if (mem->cp.flag & (1<<mmuBITS(instr,8,11)))
    FastCycle(mem);
  return mem->cp.bus.stc(mem->cp.bus.handle,type,instr,value);
}

static unsigned CPBusMCR(void *handle,unsigned type,ARMword instr,
                         ARMword value)
{
  Memory *mem=(Memory *)handle;
  if (mem->cp.flag & (1<<mmuBITS(instr,8,11)))
    FastCycle(mem);
  return mem->cp.bus.mcr(mem->cp.bus.handle,type,instr,value);
}

static unsigned CPBusMRC(void *handle,unsigned type,ARMword instr,
                         ARMword *value)
{
  Memory *mem=(Memory *)handle;
  if (mem->cp.flag & (1<<mmuBITS(instr,8,11)))
    FastCycle(mem);
  return mem->cp.bus.mrc(mem->cp.bus.handle,type,instr,value);
}

static unsigned CPBusCDP(void *handle,unsigned type,ARMword instr)
{
  Memory *mem=(Memory *)handle;
  if (mem->cp.flag & (1<<mmuBITS(instr,8,11)))
    FastCycle(mem);
  return mem->cp.bus.cdp(mem->cp.bus.handle,type,instr);
}

static ARMul_Error CPBusInit(ARMul_State *state,unsigned num,
                             ARMul_CPInterface *interf,
                             toolconf config,void *sibling)
{
  char *option;
  Memory *mem=(Memory *)sibling;

  option=(void *)ToolConf_Lookup(config,"EXTERNALCOPROBUS");

  assert(num==16);

  if (ToolConf_AddFlag(option,0,1,0)) { /* default to FALSE */
    /* has a co-processor bus. add an interface which takes a cycle
     * to re-broadcast the co-processor instruction
     */
    interf->ldc=CPBusLDC;
    interf->stc=CPBusSTC;
    interf->mcr=CPBusMCR;
    interf->mrc=CPBusMRC;
    interf->cdp=CPBusCDP;

    /* Attach any internal co-processors */
    mem->cp.flag=~ARMul_CoProInit(state,config);

    if (mem->cp.flag==0)
      return ARMulErr_InitFailCop; /* failed - error already raised */

    interf->handle=(void *)mem;

    /* attach the normal co-processor bus */
    return mem->cp.init(state,num,&mem->cp.bus,
                        mem->cp.config,mem->cp.sibling);
  } else {
    /* no coprocessor interface. */
    if (ARMul_CoProInit(state,NULL)==~0)
      return ARMulErr_InitFailCop; /* error already raised */

    /* attach the normal co-processor bus */
    return mem->cp.init(state,num,interf,mem->cp.config,mem->cp.sibling);
  }
}
