/* Title:    lexer.c
 * Purpose:  lexical analysis of an application description
 * Author:   IDJ
 * History:  05-Apr-90: IDJ: created
 *           19-Mar-91: IDJ: added "prefix_by" keyword
 *
 *           Re-release
 *           04-Nov-91: IDJ: bug-fix to DDE-0846 to allow tokens of any length
 *
 */


#include <string.h>
#include <stdio.h>
#include <stdlib.h>
#include <ctype.h>
#include <stdarg.h>

#include "global.h"
#include "types.h"
#include "FrontEnd.h"
#include "lexer.h"
#include "parser.h"
#include "bool.h"
#include "FEinterr.h"
#include "FEmem.h"


/* error messages */
#define lerr_internal       "FrontEnd internal error (lexer): %s"
#define lerr_nonterm_string "non-terminated string value"


extern char *lexer_tokenstrings[] = 
     {
        "any",                   /* keywords */
        "buffer_size",
        "by",
        "command_is",
        "dbox_end",
        "dbox_start",
        "decreases",
        "defaults",
        "deselections_end",
        "deselections_start",
        "deselects",
        "display_dft_is", 
        "drag_to",
        "excludes",
        "exclusions_end",
        "exclusions_start",
        "extends",
        "fileoutput_end",
        "fileoutput_start",
        "filetype",
        "followed_by",
        "from",
        "has_auto_run",
        "has_auto_save",
        "has_extended_cmdline",
        "has_summary_window",
        "has_text_window",
        "icn",
        "iconbar",
        "icons_end",
        "icons_start",
        "imports_end",
        "imports_start",
        "increases",
        "inserts",
        "k",
        "leafname",
        "make_defaults",
        "make_excludes",
        "make_order_is",
        "maps_to",
        "max",
        "menu",
        "menu_end",
        "menu_start",
        "metaoptions_end",
        "metaoptions_start",
        "min",
        "name",
        "not_saved",
        "number",
        "off",
        "on",
        "order_is",
        "output",
        "output_dft_is",
        "output_dft_string",
        "output_option_is",
        "prefix_by",
        "produces_no_output",
        "produces_output",
        "separator_is",
        "spaces",
        "string",
        "sub_menu",
        "summary",
        "text",
        "to",
        "tool_details_end",
        "tool_details_start",
        "toolflags",
        "version",
        "wild_card_is",
        "wimpslot",
        "string value",          /* literals */
        "integer value",
        "boolean value",
        "eof",
        ";",
        "(",
        ")",
        ",",
        ".",
        "^",
        "keyword"
   };

extern int line_number = 1;


static int lexer__next_char(void)
{
   return fgetc(fp);
}

static int lexer__keywd_lookup(char *s)
{
   int i = 0;

   while (i < NKEYWORDS)
   {
      if (!strcmp(s, lexer_tokenstrings[i])) return i;
      else i++;
   }

   return s_unknown;
}


static BOOL lexer__token_starter(int ch)
{
   return (ch == '"'   ||
           ch == '('   ||
           ch == ')'   ||
           ch == ';'   ||
           ch == ','   ||
           ch == '.'   ||
           ch == '^'   ||
           ch == '&'   ||
           isalpha(ch) ||
           isdigit(ch) 
          );
}


static void lexer__error(char *s, ...)
{
   va_list a;
   va_start(a, s);
   printf("FrontEnd: line %d: ", line_number);
   vprintf(s, a);
   printf("\n");
   va_end(a);
   exit(-1);
}


static int lexer__hexval(int c)
{
   return(isdigit(c) ? (c) - '0' :
          islower(c) ? (c) - 'a' + 10 :
          isupper(c) ? (c) - 'A' + 10 :
          -1);
}


/* exported functions */

/* if tokens are more complex this will need rewriting */
/* for the moment, this simplistic approach to lexing is good enough */

#if VARIABLE_LENGTH_TOKENS

#define TOKEN_BLOCK_SIZE 64

static void lexer__ensure_space(lexer_token *t, unsigned int size)
{
   if (t->lexeme == 0)
   {
      t->lexeme = FEmem_alloc(size);
      t->lexeme_size = size;
   }
   else
   {
      while (size > t->lexeme_size)
      {
         t->lexeme = FEmem_realloc(t->lexeme, t->lexeme_size+TOKEN_BLOCK_SIZE);
         t->lexeme_size +=TOKEN_BLOCK_SIZE;
      }
   }
}

extern void lexer_copy_token(lexer_token *dst, lexer_token *src)
{
   dst->number = src->number;
   dst->value.integer = src->value.integer;

   if (src->lexeme != 0)
   {
      if (dst->lexeme_size < src->lexeme_size) lexer__ensure_space(dst, src->lexeme_size);
      memcpy(dst->lexeme, src->lexeme, src->lexeme_size);
   }
}

extern void lexer_next_token(lexer_token *token)
{
   int ch, pos=0;

   /* --- ensure initial space for lexeme --- */
   lexer__ensure_space(token, TOKEN_BLOCK_SIZE);

   /* --- skip spaces and blank lines --- */
   ch = lexer__next_char();
   while (TRUE)
   {
      if (ch == '#') 
         do {ch = lexer__next_char(); } while (ch != '\n' && ch != EOF);
      if (ch == EOF) {token->number = s_eof; return;}
      if (ch == '\n') line_number++;
      if (!isspace(ch) && lexer__token_starter(ch)) break;
      ch = lexer__next_char();
   }

   /* --- first char gives type of symbol --- */
   switch (ch)
   {
      case '"':  /* string literal */
        ch = lexer__next_char();
        while (ch != '"' && ch != '\n' && ch != EOF)
        {
           lexer__ensure_space(token, pos+1);
           token->lexeme[pos++] = ch;
           ch = lexer__next_char();
        }
        if (ch == '\n' || ch == EOF)
        {
           if (ch == '\n') line_number++;
           lexer__error(lerr_nonterm_string);
        }
        else
           token->number = s_string_value;
        token->lexeme[pos] = 0;
        break;

      case '(':
        token->number = s_bra;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case ')':
        token->number = s_ket;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case ',':
        token->number = s_comma;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case '.':
        token->number = s_dot;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case '^':
        token->number = s_hat;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case ';':
        token->number = s_semicolon;
        token->lexeme[pos++] = ch; token->lexeme[pos] = 0;
        break;

      case '&':
        ch = lexer__next_char();
        token->value.integer = 0;
        while (isxdigit(ch))
        {
           lexer__ensure_space(token, pos+1);
           token->lexeme[pos++] = ch;
           token->value.integer = (token->value.integer<<4) + lexer__hexval(ch);
           ch = lexer__next_char();
        }
        ungetc(ch, fp);
        token->number = s_number_value;
        token->lexeme[pos] = 0;
        break;

      default:  /* maybe keywd, number or crap */
        if (isdigit(ch))   /* a number */
        {
           do 
           {
              lexer__ensure_space(token, pos+1);
              token->lexeme[pos++] = ch;
              ch = lexer__next_char();
           } while (isdigit(ch));
           ungetc(ch, fp);
           token->number = s_number_value;
           token->lexeme[pos] = 0;
           token->value.integer = atoi(token->lexeme);
        }
        else if (isalpha(ch))  /* a keyword? */
        {
           do
           {
              lexer__ensure_space(token, pos+1);
              token->lexeme[pos++] = ch;
              ch = lexer__next_char();
           } while (isalpha(ch) || ch == '_');
           ungetc(ch, fp);
           token->lexeme[pos] = 0;
           token->number = lexer__keywd_lookup(token->lexeme); 
        }
        else
          lexer__error(lerr_internal, "unexpected non-token char");
        break;
   }
}

#else

extern lexer_token lexer_next_token(void)
{
   lexer_token token;
   int ch, pos=0;

   /* --- skip spaces and blank lines --- */
   ch = lexer__next_char();
   while (TRUE)
   {
      if (ch == '#') 
         do {ch = lexer__next_char(); } while (ch != '\n' && ch != EOF);
      if (ch == EOF) {token.number = s_eof; return token;}
      if (ch == '\n') line_number++;
      if (!isspace(ch) && lexer__token_starter(ch)) break;
      ch = lexer__next_char();
   }

   /* --- first char gives type of symbol --- */
   switch (ch)
   {
      case '"':  /* string literal */
        ch = lexer__next_char();
        while (ch != '"' && ch != '\n' && ch != EOF)
        {
           token.lexeme[pos++] = ch;
           ch = lexer__next_char();
        }
        if (ch == '\n' || ch == EOF)
        {
           if (ch == '\n') line_number++;
           lexer__error(lerr_nonterm_string);
        }
        else
           token.number = s_string_value;
        token.lexeme[pos] = 0;
        break;

      case '(':
        token.number = s_bra;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case ')':
        token.number = s_ket;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case ',':
        token.number = s_comma;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case '.':
        token.number = s_dot;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case '^':
        token.number = s_hat;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case ';':
        token.number = s_semicolon;
        token.lexeme[pos++] = ch; token.lexeme[pos] = 0;
        break;

      case '&':
        ch = lexer__next_char();
        token.value.integer = 0;
        while (isxdigit(ch))
        {
           token.lexeme[pos++] = ch;
           token.value.integer = (token.value.integer<<4) + lexer__hexval(ch);
           ch = lexer__next_char();
        }
        ungetc(ch, fp);
        token.number = s_number_value;
        token.lexeme[pos] = 0;
        break;

      default:  /* maybe keywd, number or crap */
        if (isdigit(ch))   /* a number */
        {
           do 
           {
              token.lexeme[pos++] = ch;
              ch = lexer__next_char();
           } while (isdigit(ch));
           ungetc(ch, fp);
           token.number = s_number_value;
           token.lexeme[pos] = 0;
           token.value.integer = atoi(token.lexeme);
        }
        else if (isalpha(ch))  /* a keyword? */
        {
           do
           {
              token.lexeme[pos++] = ch;
              ch = lexer__next_char();
           } while (isalpha(ch) || ch == '_');
           ungetc(ch, fp);
           token.lexeme[pos] = 0;
           token.number = lexer__keywd_lookup(token.lexeme); 
        }
        else
          lexer__error(lerr_internal, "unexpected non-token char");
        break;
   }

   return token;
}

#endif
