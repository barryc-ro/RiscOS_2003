
New caching strategy
--------------------

Cache directory only holds directories 00-76. Each of which holds the
cache files.

Cache arrays are allocated a directory full at a time (ie 77 files) with
their pointers stored in a master array.

The file names are not used, each files entry number is its filename ie
00-76.

Otherwise things work much as they do at the moment.

----------------------------------

If cacheFS is in use we need to know when the file is removed so we can 
reuse the slot. Otherwise our cache tables will build up until we've used
77*77 files (or other limit) and there is still no guarantee that we will
remove the items from our cache list that have actually gone from the 
cache.

Luckily cachefs issues the file modified UpCalls (well it would have to 
for the Filer to work!) so we can trap them and look for file deletes
on files starting <Wimp$ScrapDir>.STBWeb.

One way to handle it would be to have a module that just filled up with
matching file names. And a poll call that would return these to the 
controlling application. It could even use cachefs to store the list of
files - but maybe not.

 So an appliation would register an interest in 
   a type of modification
   a file prefix
 or a list of these.
 
and would be returned a handle. It would then call a Poll entry with
this handle and get the filenames that had changed.

In STBWeb's case it could be simpler in that all the files will be 
numerically identified and so the module could just store the numbers
rather than the filenames.

Given the frequency of STBWeb's wimp polling then it is probable that
there wouldn't be many filenames at one time so there wouldn't be too
much overhead anyway. Still some thought as to how to store the data would
be good. A linked list od filenames would be simple but not necessarily
most effective.

So a spec might go something like

Module FileWatch

SWI FileWatch_RegisterInterest
  R0 = flags
  R1 = upcall reason, lowest
  R2 = upcall reason, highest
  R3 = file prefix
Exit
  R0 = handle

SWI FileWatch_DeRegisterInterest
  R0 = flags
  R1 = handle

SWI FileWatch_Poll
  R0 = flags
  R1 = handle
  R2 = buffer
  R3 = buffer size
Exit
  R2,R3 updated
  R4 = number of files left

Future enhancements might be things like setting Wimp Poll Words when files
are changed

----------------------------------

Another way to handle files in cachefs would be to do away with the cache
array totally and store files under their URL's (suitable munged to be
legal and still unique). 

The main thing to watch out for here is that URLs are case sensitive in
the path section. Luckily most characters in a path name by far are
lower case so if we escape upper case then thre shouldn't be too much of
an overhead. 

I will also have to escape all fileswitch reversed characters. 

I will also reverse the use of / and . to make viewing the cache easier
(there shouldn't be any otehr side effects).

The use of the cache functions might have to change to support this behavious
however (due to URL relocation).


FileSwitch reserved characters
------------------------------

 0-31,127   control

 @ $ % & \  special directories
 * #        wildcards
 : ^ .      path elements
 " < sp     generally awkward

URL reserved characters
-----------------------

 :          scheme term
 /          dir sep
 #          fragment id
 ?          query sep
 =          in query info
 ; sp

A URL can be converted to a canonical form, all non RISC OS characters
escaped. This shouldn't be displayed but only used to access the file
in cachefs to avoid having to keep a copy of the URL.

All deletion code would be removed.

cache_keep() would just read file info so that cachefs would note it
as having been used recently.

scrapfile_name() will return a unique scrap name (as at present perhaps)

cache_insert() will rename it with it's URL.

----------------------------------

typedef struct {
    char *url;
    unsigned int hash;

    char index;
    char flags;
    char keep_count;

    unsigned int last_used;
    int size;			/* Kept in K, rounded UP */
} _cache_item;

scrapfile_name() will search through the array until it finds an unused
slot (url=0) and return that name.

// internal to cache() functions

double cache_cost(_cache_item *item, unsigned int t)
  how deletable is this file?

int cache_index(char *url)
  given a url find the cache index, return -1 if not present
  not used outside cache()

os_error *cache_remove_file(int i)
  given an index remove from the cache and delete (if ours)

// external functions

char *cache_lookup(char *url)
  given a url find the filename (and mark it as used)

void cache_remove(char *url)
  given a url remove from the cache and delete (if ours)

void cache_make_room(int size)
  delete unrecently used until below size limit

void cache_insert(char *url, char *file, cache_flags flags)
  create a new cache entry, removing anything if necessary

void cache_dump(void)
  dump out list for persistent use. This might have to be done
  on every access and so should be held in separate files for each
  directory.

void cache_keep(char *url)
  locate file and increment keep count

void cache_unkeep(char *url)
  locate file and decrement keep count

void cache_not_ours(char *file)
  locate file and clear OURS flag
  ie we don't take resposibility for deleting it (in which case why do we
  keep a reference to it at all?).

char *scrapfile_name()

--------------------

