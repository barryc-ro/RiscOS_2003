;
; Copyright(c) 1994 Acorn Computers Ltd., Cambridge, England
;
; Assembler function to enable podule irqs
;

	GET	Hdr:ListOpts
	GET	Hdr:Macros
	GET	Hdr:System
	GET	Hdr:EnvNumbers
	GET	Hdr:ModHand
        GET     Hdr:APCS.<APCS>

	EXPORT	escape_seen
	EXPORT	user_mode_donothing
	EXPORT	splet
	EXPORT	splimp
	EXPORT	splnet
	EXPORT	splx
	EXPORT	splhi
	EXPORT	ensure_irqs_on
	EXPORT	restore_irqs
	EXPORT	splrestore
	EXPORT  in_cksum_hdr
	EXPORT	get_t0_count

	^	0

	AREA	poduleirqs, PIC, CODE, REL, READONLY

	ALIGN

; This routine returns 1 if escape condition set, else 0
escape_seen
        FunctionEntry
	SWI	XOS_ReadEscapeState
	MOVCS	r0, #1
	MOVCC	r0, #0

; I don't think it's up to us to acknowledge the escape condition
; It's the callee's problem
	[ {TRUE}
        Return
	|
	STMFD r13!,{r0}
	MOV r0, #126			; OS_Byte 126 = Acknowledge escape condition
	SWI XOS_Byte

        Return "r0"
	]

; os_error *usermode_donothing();
user_mode_donothing ROUT

        FunctionEntry

	; Now execute a SWI in user mode to trigger callbacks
        WritePSRc 0, r0                 ; IRQs on, user mode
	MOV r0, #0
	MOV r1, #1
	SWI XOS_Byte			; Read OS version
	SWI XOS_EnterOS			; Back to SVC mode

        Return

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; splhi etc:
;
; Disable IRQs). Once IRQs are disabled, we cannot/must not be reentered.
;
; Returns a value indicating the state of interrupts prior to calling here.
;

splhi
splet
splnet
splimp
        [ {CONFIG}=26
	AND	r0, lr, # I_bit
	ORRS	pc, lr, # I_bit
        |
        MRS     a1, CPSR
        ORR     a2, a1, #I32_bit
        MSR     CPSR_c, a2
        AND     a1, a1, #I32_bit
        MOV     pc, lr
        ]


;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; ensure_irqs_on:
;
; Ensure that interrupts are enabled. Returns a value that, when passed
; to restore_irqs, will restore the state prior to enabling interrupts.
;

ensure_irqs_on
        [ {CONFIG}=26
	AND	r0, lr, # I_bit
	BICS	pc, lr, # I_bit
        |
        MRS     a1, CPSR
        BIC     a2, a1, #I32_bit
        MSR     CPSR_c, a2
        AND     a1, a1, #I32_bit
        MOV     pc, lr
        ]

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; restore_irqs etc:
;
; Restore interrupts to the state they were in prior to a call to
; splhi, using the value returned by splhi.
;

restore_irqs
splrestore
splx
        [ {CONFIG}=26
	BIC	lr, lr, # I_bit
	ORRS	pc, lr, r0
        |
        MRS     a2, CPSR
        BIC     a2, a2, #I32_bit
        ORR     a2, a2, a1
        MSR     CPSR_c, a2
        MOV     pc, lr
        ]

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; get_t0_count
;
; Read the current value in Timer 0.
;

get_t0_count
        [ {CONFIG}=26
        MOV     r12,lr
        MOV     r3,#IOC
; Shut off interrupts (briefly) to ensure an atomic read of these
; silly hardware registers.
        TEQP    pc,#I_bit :OR: SVC_mode
        STRB    r3,[r3,#Timer0LR]
        LDRB    r1,[r3,#Timer0CL]
        LDRB    r0,[r3,#Timer0CH]
        ORR     r0,r1,r0,LSL #8
        MOVS    pc,r12                  ; Will restore mode and interrupt status
        |
        MOV     r3,#IOC
; Shut off interrupts (briefly) to ensure an atomic read of these
; silly hardware registers.
        MRS     r2,CPSR
        ORR     r0,r2,#I32_bit
        MSR     CPSR_c,r0
        STRB    r3,[r3,#Timer0LR]
        LDRB    r1,[r3,#Timer0CL]
        LDRB    r0,[r3,#Timer0CH]
        MSR     CPSR_c,r2
        ORR     r0,r1,r0,LSL #8
        MOV     pc,lr
        ]



;
; Hyper-fast simple-case IP header checksum
;

in_cksum_hdr
	; Load 20 bytes of IP header
	LDMIA	a1,{a1-a4,ip}

	; Calculate 1's-complement sum of the 5 32-bit words.
	ADDS	a1,a1,a2
	ADCS	a1,a1,a3
	ADCS	a1,a1,a4
	ADCS	a1,a1,ip
	ADC	a1,a1,#0

        ; Fold two 16-bit words together - top half will
        ; contain the 1's complement sum
        ADD     a1,a1,a1,ROR #16

        ; Take the 1's-complement of the result
        MVN     a1,a1

        ; And shift it down to the bottom
        MOV     a1,a1,LSR #16

        Return  ,LinkNotStacked

	^	0
m_next	#	4
m_list	#	4
m_off	#	4
m_len	#	4

	[ {TRUE}

	EXPORT	in_cksum

;
; This routine is engineered to be rapid on cached ARMs.
; See RFC1072 for the 1's-complement arithmetic tricks used.
;
; The routine is engineered with the following points in mind:
;    Arithmetic operations, including constant shifts, take 1 tick
;    Arithmetic operations with register shifts take 2 ticks
;    Unexecuted instructions take 1 tick
;    Branches take 3 ticks
;    An LDM of n registers is significantly faster than n LDRs
;
; The amount to "unroll" the loop is an issue.  On an ARM710,
; doing 64 bytes at a time appears to be significantly (11-12%) faster
; on average than doing 32 bytes at a time.  The trade-off
; between reducing the number of branches and utilising burst-reads,
; and the filling of the instruction cache, will differ from processor
; to processor.  This sort of slight tweaking is probably trivial
; compared to the 8 times speedup over the bytewise in_cksum routine
; present in Internet 4.08...
;
; The mind boggles at a "processor-tuned" variation of the standard
; BSD in_cksum routine that manages to be under half the speed.
;
; In speed tests, trying 16-byte blocks after 64-byte blocks does not
; noticeably affect the speed. This probably means that it will actually
; increase the speed in real use, when this routine is called less
; often, as it makes the routine smaller, hence disrupting the cache less.
;
; On entry:
;      a1 -> first mbuf
;      a2 -> length to checksum
;
; Throughout routine:
;      a1 = current mbuf
;      a2 = length remaining to checksum
;      v1 = data ptr
;      v2 = length remaining of mbuf
;      v3 = total rotate of checksum
;      ip = checksum
;
;      a3-a4,v4-v6,sl,fp,lr = general work registers
;
;    In final 64 bytes:
;      a3 = number of bits present in final word (0-31)
;
	ROUT
in_cksum
        FunctionEntry "v1-v6,sl,fp"

	; Start off checksum and rotate
	MOV	v3, #0
	MOV	ip, #0

99	LDR	v1,[a1,#m_off]
	; v2 = length of mbuf
	LDR	v2,[a1,#m_len]

	; v1 = ptr to data
	ADD	v1,a1,v1

	; if mlen > len, mlen = len
	CMPS	v2,a2
	MOVHI	v2,a2

	; len -= mlen
	SUB	a2,a2,v2

	ANDS	a3,v1,#3
	BLNE	fiddly

	; If we have 64 bytes, do it fast (utilising burst
	; reads)
	SUBS	v2,v2,#64
	BMI	%F97
0	LDMIA	v1!,{a3,a4,v4,v5,v6,sl,fp,lr}
	ADDS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADCS	ip,ip,v6
	ADCS	ip,ip,sl
	ADCS	ip,ip,fp
	ADCS	ip,ip,lr
	LDMIA	v1!,{a3,a4,v4,v5,v6,sl,fp,lr}
	ADCS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADCS	ip,ip,v6
	ADCS	ip,ip,sl
	ADCS	ip,ip,fp
	ADCS	ip,ip,lr
	ADC	ip,ip,#0

	SUBS	v2,v2,#64
	BGE	%B0

	; If we have 16 bytes, do it fast (utilising burst
	; reads)
97	ADDS	v2,v2,#64-16
	BMI	%F1
98	LDMIA	v1!,{a3,a4,v4,v5}
	ADDS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADC	ip,ip,#0

	SUBS	v2,v2,#16
	BGE	%B98

	; Right, down to < 16 bytes.
	; However we get here, C is clear

	; Do we have an "odd" number?
1	ANDS	a3,v2,#3       ; Doesn't alter C
	BEQ	%F2

	; Yes we do. Bugger.

	; a3 is no of bytes present in incomplete word
	; Get lr to point to end word
	SUB	lr,v2,a3
	ADD	lr,lr,#16
	; Load word containing end-point. This will give us a3 bits
	; that need to be ignored (high-bits).
	LDR	a4,[v1,lr]

	; set a3 to no of bits present in incomplete word
	MOV	a3,a3,LSL #3
	; set lr to number of bits missing in incomplete word
	RSB	lr,a3,#32
	; clear bits to be ignored
	MOV	a4,a4,LSL lr
	; add incomplete word to checksum
	ADDS	ip,ip,a4,LSR lr
	; reduce amount left to read so the following code
	; will only sum remaining whole words
	BIC	v2,v2,#3

	; Now we continue. Note that as we reach label 2, a3 will
	; be set to the number of extra bits beyond the complete
	; words in the mbuf.

	; Branch as appropriate to sum remaining 0-3 words
	; Note that state of C as we reach this point is significant;
	; if we didn't go through the incomplete word malarky, C
	; must be clear, otherwise we take C from previous ADDS
	; (although this will of course be clear also).
	;
	; Can't really loop here as any sort of end-of-loop test
	; will corrupt the C flag.
2	SUB	pc,pc,v2,LSL #1
	NOP
	NOP			  ; Can't get here (honest!)
	NOP
	LDR	a4,[v1],#4	  ; 12
	ADCS	ip,ip,a4
	LDR	a4,[v1],#4        ; 8
	ADCS	ip,ip,a4
	LDR	a4,[v1]           ; 4
	ADCS	ip,ip,a4
	ADC	ip,ip,#0          ; 0

	; Have we finished?
	TEQS	a2,#0
	BEQ	%F03

	; Now then, now then, now then. If this mbuf did not have
	; a complete number of words, the next one will have "rotated
	; words". Eg in 3 mbufs of 5 bytes:
	;
	; [(A B C D) (A)] -> [(B C D A) (B)] -> [(C D A B) (C)]
	;
	; to cope with this, rotate the checksum so far to match
	; the rotation state of the next mbuf (eg rotate it one byte
	; left in the above example), and keep track of the total
	; rotations done in v3, so we can unwind at the end.
	;
	MOV	ip,ip,ROR a3
	SUB	v3,v3,a3

	; Back to the top for the next mbuf!
	LDR	a1,[a1,#m_next]
	B	%B99

3	MOV	ip,ip,ROR v3

        ; Fold two 16-bit words together - top half will
        ; contain the 1's complement sum
        ADD     a1,ip,ip,ROR #16

        ; Take the 1's-complement of the result
        MVN     a1,a1

        ; Shift it down to the bottom
        MOV     a1,a1,LSR #16

	; And... relax.
        Return  "v1-v6,sl,fp"

	; This is very rare, so separate it off down here
	; can't be bothered to optimise
	; a3 is number of missing bytes
fiddly
	; Check if out of data
	TEQS	v2,#0
	MOVEQ	pc,lr

	; Load byte
11	LDRB	a4,[v1],#1
	; Add to checksum
	ADDS	ip,ip,a4
	ADC	ip,ip,#0
	; Rotate checksum
	MOV	ip,ip,ROR #8
	SUB	v3,v3,#8
	; Reduce counter
	SUBS	v2,v2,#1
	MOVEQ	pc,lr
	TSTS	v1,#3
	BNE	%B11
	MOV	pc,lr

	]

	END



; EOF poduleirq.s
