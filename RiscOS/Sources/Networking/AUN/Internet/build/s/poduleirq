;
; Copyright(c) 1994 Acorn Computers Ltd., Cambridge, England
;
; Assembler function to enable podule irqs
;

	GET	Hdr:ListOpts
	GET	Hdr:Macros
	GET	Hdr:System
	GET	Hdr:EnvNumbers
	GET	Hdr:ModHand

	GBLL	DeferCallbacks
DeferCallbacks SETL	{FALSE}

	EXPORT	escape_seen
	EXPORT	user_mode_donothing
	EXPORT	splet
	EXPORT	splimp
	EXPORT	splimp2
	EXPORT	splnet
	EXPORT	splx
	EXPORT	splhi
	EXPORT	splhi2
	EXPORT	ensure_irqs_on
	EXPORT	restore_irqs
	EXPORT	splrestore
	EXPORT  in_cksum_hdr

	^	0

	AREA	poduleirqs, PIC, CODE, REL, READONLY

	ALIGN

; This routine returns 1 if escape condition set, else 0
escape_seen
	STMFD	sp!,{lr}
	SWI	XOS_ReadEscapeState
	MOVCS	r0, #1
	MOVCC	r0, #0

; I don't think it's up to us to acknowledge the escape condition
; It's the callee's problem
	[ {TRUE}
	LDMFD	sp!,{pc}^
	|
	STMFD r13!,{r0}
	MOV r0, #126			; OS_Byte 126 = Acknowledge escape condition
	SWI XOS_Byte

	LDMFD r13!,{r0,pc}^
	]

	[ DeferCallbacks

; This callback handler simple defers the callback until later
; Note that this may be entered in IRQ or SVC mode
defer_callback
	MOV	r8, pc			; Save current status/mode
	ORR	r8, r8, #SVC_Mode	; Derive SVC-mode version of it
	TEQP	r8, #0			; Enter SVC mode
	NOP
	SWI	XOS_SetCallBack		; Defer callback
	MOV	r14, r12		; Register block
	LDMIA	r14, {r0-r14}^		; Loads USR r13,r14
	NOP				; NOOP after accessing user
					; registers before accessing banked
					; register.
	LDR	r14, [r14, #15*4]	; Loads user PC into SVC r14
	MOVS	pc, r14			; Drop back to USR mode

	]


; os_error *usermode_donothing();
user_mode_donothing ROUT

	STMFD r13!,{lr}
	[ DeferCallbacks
	SUB sp, sp, #&40		; Make space on stack for reg dump

	; Update callback handler atomically in case an event occurs
	; between reading the old handler and writing the new handler
	;
        ; Callback handler needs defering so that escape code doesn't blow
        ; away the program which called this SWI before this SWI returns.
	MOV r0, #CallBackHandler
	ADR r1, defer_callback
	MOV r2, sp			; R12 in defer_callback = reg ptr
	MOV r3, sp			; Reg save area on stack
	SWI XOS_ChangeEnvironment
	STMVCFD r13!,{r1-r3}		; Save old handler
	MOVVC r3,#1
	MOVVS r3,#0
	]

	; Now execute a SWI in user mode to trigger callbacks
	TEQP pc, #0			; To user mode
	MOV r0, #0
	MOV r1, #1
	SWI XOS_Byte			; Read OS version
	SWI XOS_EnterOS			; Back to SVC mode

	[ DeferCallbacks
	CMP r3,#0
	; Restore old callback handler
	MOVNE r0, #CallBackHandler
	LDMNEFD r13!,{r1-r3}
	SWINE XOS_ChangeEnvironment

	ADD sp, sp, #&40
	]
	LDMFD r13!,{pc}^

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; splhi etc:
;
; Disable IRQs). Once IRQs are disabled, we cannot/must not be reentered.
;
; Returns a value indicating the state of interrupts prior to calling here.
;

splhi
splet
splnet
splimp
	AND	r0, lr, # I_bit
splhi2
splimp2
	ORRS	pc, lr, # I_bit

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; ensure_irqs_on:
;
; Ensure that interrupts are enabled. Returns a value that, when passed
; to restore_irqs, will restore the state prior to enabling interrupts.
;

ensure_irqs_on
	AND	r0, lr, # I_bit
	BICS	pc, lr, # I_bit

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
;
; restore_irqs etc:
;
; Restore interrupts to the state they were in prior to a call to
; splhi, using the value returned by splhi.
;

restore_irqs
splrestore
splx
	BIC	lr, lr, # I_bit
	ORRS	pc, lr, r0

;
; Hyper-fast simple-case IP header checksum
;

in_cksum_hdr
	; Load 20 bytes of IP header
	LDMIA	a1,{a1-a4,ip}

	; Calculate 1's-complement sum of the 5 32-bit words.
	ADDS	a1,a1,a2
	ADCS	a1,a1,a3
	ADCS	a1,a1,a4
	ADCS	a1,a1,ip
	ADC	a1,a1,#0

	; Fold two 16-bit words together
	; May be left with 16-bit carry
	ADDS	a1,a1,a1,LSL #16

	; See below for the explanation of this bit
	MVN	a2,#0
	RSC	a1,a2,a1,LSR #16
	EOR	a1,a1,a2,LSR #16
	MOVS	pc,lr

	^	0
m_next	#	4
m_list	#	4
m_off	#	4
m_len	#	4

	[ {TRUE}

	EXPORT	in_cksum

;
; This routine is engineered to be rapid on cached ARMs.
; See RFC1072 for the 1's-complement arithmetic tricks used.
;
; The routine is engineered with the following points in mind:
;    Arithmetic operations, including constant shifts, take 1 tick
;    Arithmetic operations with register shifts take 2 ticks
;    Unexecuted instructions take 1 tick
;    Branches take 3 ticks
;    An LDM of n registers is significantly faster than n LDRs
;
; The amount to "unroll" the loop is an issue.  On an ARM710,
; doing 64 bytes at a time appears to be significantly (11-12%) faster
; on average than doing 32 bytes at a time.  The trade-off
; between reducing the number of branches and utilising burst-reads,
; and the filling of the instruction cache, will differ from processor
; to processor.  This sort of slight tweaking is probably trivial
; compared to the 8 times speedup over the bytewise in_cksum routine
; present in Internet 4.08...
;
; The mind boggles at a "processor-tuned" variation of the standard
; BSD in_cksum routine that manages to be under half the speed.
;
; In speed tests, trying 16-byte blocks after 64-byte blocks does not
; noticeably affect the speed. This probably means that it will actually
; increase the speed in real use, when this routine is called less
; often, as it makes the routine smaller, hence disrupting the cache less.
;
; On entry:
;      a1 -> first mbuf
;      a2 -> length to checksum
;
; Throughout routine:
;      a1 = current mbuf
;      a2 = length remaining to checksum
;      v1 = data ptr
;      v2 = length remaining of mbuf
;      v3 = total rotate of checksum
;      ip = checksum
;
;      a3-a4,v4-v6,sl,fp,lr = general work registers
;
;    In final 64 bytes:
;      a3 = number of bits present in final word (0-31)
;
	ROUT
in_cksum
	STMFD	sp!,{v1-v6,sl,fp,lr}

	; Start off checksum and rotate
	MOV	v3, #0
	MOV	ip, #0

	; v1 = ptr to data
99	LDR	v1,[a1,#m_off]
	ADD	v1,a1,v1

	; v2 = length of mbuf
	LDR	v2,[a1,#m_len]

	; if mlen > len, mlen = len
	CMPS	v2,a2
	MOVHI	v2,a2

	; len -= mlen
	SUB	a2,a2,v2

	ANDS	a3,v1,#3
	BLNE	fiddly

	; If we have 64 bytes, do it fast (utilising burst
	; reads)
	SUBS	v2,v2,#64
	BMI	%F97
0	LDMIA	v1!,{a3,a4,v4,v5,v6,sl,fp,lr}
	ADDS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADCS	ip,ip,v6
	ADCS	ip,ip,sl
	ADCS	ip,ip,fp
	ADCS	ip,ip,lr
	LDMIA	v1!,{a3,a4,v4,v5,v6,sl,fp,lr}
	ADCS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADCS	ip,ip,v6
	ADCS	ip,ip,sl
	ADCS	ip,ip,fp
	ADCS	ip,ip,lr
	ADC	ip,ip,#0

	SUBS	v2,v2,#64
	BGE	%B0

	; If we have 16 bytes, do it fast (utilising burst
	; reads)
97	ADDS	v2,v2,#64-16
	BMI	%F1
98	LDMIA	v1!,{a3,a4,v4,v5}
	ADDS	ip,ip,a3
	ADCS	ip,ip,a4
	ADCS	ip,ip,v4
	ADCS	ip,ip,v5
	ADC	ip,ip,#0

	SUBS	v2,v2,#16
	BGE	%B98

	; Right, down to < 16 bytes.
	; However we get here, C is clear

	; Do we have an "odd" number?
1	ANDS	a3,v2,#3       ; Doesn't alter C
	BEQ	%F2

	; Yes we do. Bugger.

	; a3 is no of bytes present in incomplete word
	; Get lr to point to end word
	SUB	lr,v2,a3
	ADD	lr,lr,#16
	; Load word containing end-point. This will give us a3 bits
	; that need to be ignored (high-bits).
	LDR	a4,[v1,lr]

	; set a3 to no of bits present in incomplete word
	MOV	a3,a3,LSL #3
	; set lr to number of bits missing in incomplete word
	RSB	lr,a3,#32
	; clear bits to be ignored
	MOV	a4,a4,LSL lr
	; add incomplete word to checksum
	ADDS	ip,ip,a4,LSR lr
	; reduce amount left to read so the following code
	; will only sum remaining whole words
	BIC	v2,v2,#3

	; Now we continue. Note that as we reach label 2, a3 will
	; be set to the number of extra bits beyond the complete
	; words in the mbuf.

	; Branch as appropriate to sum remaining 0-7 words
	; Note that state of C as we reach this point is significant;
	; if we didn't go through the incomplete word malarky, C
	; must be clear, otherwise we take C from previous ADDS
	; (although this will of course be clear also).
	;
	; Can't really loop here as any sort of end-of-loop test
	; will corrupt the C flag.
2	SUB	pc,pc,v2,LSL #1
	NOP
	NOP			  ; Can't get here (honest!)
	NOP
	LDR	a4,[v1],#4	  ; 12
	ADCS	ip,ip,a4
	LDR	a4,[v1],#4        ; 8
	ADCS	ip,ip,a4
	LDR	a4,[v1]           ; 4
	ADCS	ip,ip,a4
	ADC	ip,ip,#0          ; 0

	; Have we finished?
	TEQS	a2,#0
	BEQ	%F03

	; Now then, now then, now then. If this mbuf did not have
	; a complete number of words, the next one will have "rotated
	; words". Eg in 3 mbufs of 5 bytes:
	;
	; [(A B C D) (A)] -> [(B C D A) (B)] -> [(C D A B) (C)]
	;
	; to cope with this, rotate the checksum so far to match
	; the rotation state of the next mbuf (eg rotate it one byte
	; left in the above example), and keep track of the total
	; rotations done in v3, so we can unwind at the end.
	;
	MOV	ip,ip,ROR a3
	SUB	v3,v3,a3

	; Back to the top for the next mbuf!
	LDR	a1,[a1,#m_next]
	B	%B99

3	MOV	ip,ip,ROR v3

	; Fold two 16-bit words together
	; May be left with 16-bit carry
	ADDS	a1,ip,ip,LSL #16

	; Useful constant...
	MVN	a2,#0

	; This means a1=(a1>>16)+C, would you believe it.
	; The things we do to save a single instruction :-)
	RSC	a1,a2,a1,LSR #16

	; Take the 1's-complement of the (16-bit) result
	EOR	a1,a1,a2,LSR #16

	; And... relax.
	LDMFD   sp!,{v1-v6,sl,fp,pc}^

	; This is very rare, so separate it off down here
	; can't be bothered to optimise
	; a3 is number of missing bytes
fiddly
	; Check if out of data
	TEQS	v2,#0
	MOVEQ	pc,lr

	; Load byte
11	LDRB	a4,[v1],#1
	; Add to checksum
	ADDS	ip,ip,a4
	ADC	ip,ip,#0
	; Rotate checksum
	MOV	ip,ip,ROR #8
	SUB	v3,v3,#8
	; Reduce counter
	SUBS	v2,v2,#1
	MOVEQ	pc,lr
	TSTS	v1,#3
	BNE	%B11
	MOV	pc,lr

	]

	END


; EOF poduleirq.s
