.TH MNORBMET 8 "8 March 1996" "Oracle Media Net"
.SH NAME
mnorbmet - Oracle Media Net Metric Damon
.SH SYNOPSIS
.nf
mnorbmet [-x][-d][-p host:pid[:aff]][-y yortref][-D][-P][-q][-c][-m][-s]
.SH DESCRIPTION
mnorbmet collects metric data from active implementations and
distributes it to the yd daemons running in the system.  It runs two
asynchonous loops.  One gets and the other distributes metric data.
Only one mnorbmet is needed in a system.
.P
The first loop queries the implementation repository (ydim) to
identify processes containing active implementaitons.  It then asks
each of these for their metric data.  When data is received, it may be
queued to be sent to all the known mnorbsrv(8) ORB daemons for them to
use in their routing decisions.  The loop pauses before starting
again, so as not to consume the entire CPU.
.P
The second loop is started only if the -d option is specified.  It
queries the runtime to identify all the destination yds.  As new ones
are noticed, they are sent all current metric data.  The loops pauses
before each iteration to avoid consuming the CPU.
.P
The mnorbmet also provides the object interfaces, defined in mnorbmetidl.idl.
.SH OPTIONS
.TP
-x
Turn on tracing to level 5.
.TP
-p host:pid[:aff]
Client mode - Query the daemon and return the collected metrics for the
specified process, if known.
.TP
-y yortref
Client mode - Quety the daemon and return the collected metrics for
the runtime specified with the string form of an object reference, pehaps
obtained from mnorbls -a
.TP
-D
Trace only the distribution loop.
.TP
-P
Trace only the polling loop.
.TP
-q
Client mode - shut down server.
.TP
-c
Client mode - query the server for statistics about polling operations.
.TP
-m
Client mode - query the server and dump out all the collected metrics.
.TP
-s
be a server (default).
.SH ENVIRONMENT
.TP
OMN_ADDR
The physical address of the address server to use.
.SH RESOURCES
.TP
ydmtd.trace-level
Determine the extent of tracing; default 0, also set with -x and -t arguments.
.TP
ydmtd.chunksize
How many entries to work with in operations that can block data; default 50.
.TP
ydmtd.poll-idle-ms
Milliseconds to pause between poll loops.  Default 10000 (10s).  Less
delay increases the acruacy of the metrics used by the mnorbsrv(8) router,
but consumes more cpu.
.TP
ydmtd.ttl-ms
Time-to-live for metrics.  If they haven't been sent to the yds again 
in this interval, they will be sent again.  Default 30000 (30s).
.TP
ydmtd.max-polls
Maximum number of poll requests to have outstanding at any one time.  This
limits the bandwidth draing the daemon will impose on the system, at
the possible expense of polling loop latency.  Default 8.
.TP
ydmtd.reap-ms
Time to remove metrics that have not been updated.  If metrics from a yort have not been updated by a poll in this interval, they are removed and the
yort is considered dead.  It is removed from the implementation repository
as well, and no further requests will be made to it either from the mnorbmet or
routed from the yd.  Default is 1800000 (3 minutes).
.TP
ydmtd.timeout-ms
Time to wait for a poll request or a metric send before decrementing
the "lives" counter for target.  Once the "lives" have expired, the entity is 
considered dead.  If the target is a yort, mnorbmet deletes it from the implementation repository; if it's a yd destination, it stops trying to send it updated
metric information.  Default is 30000 (30s).
.TP
ydmtd.lives
Number of timeouts to a target mnorbmet will tolerate before declaring it dead.
Default is 6.
.TP
ydmtd.dest-check-ms
Time between checks for new yd destinations.  Default is 30000 (30s). 
.SH BUGS
There is currently no limit on the number of i/o operations that may
be outstanding.  This will probably not work well when there are 1,000
yorts to poll, as there will be 1,000 requests to get metrics
outstanding at the same time.
.SH SEE ALSO
ydls(1), ydspps(1), mnorbsrv(8), ydc(8), mnorbmetc(8), ydmtls(8).
