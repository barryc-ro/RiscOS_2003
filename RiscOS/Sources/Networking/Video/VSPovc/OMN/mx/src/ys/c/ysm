/* Copyright (c) 1994, 1995 by Oracle Corporation.  All Rights Reserved.
 *
 * ysm.c - OMX Memory Manager
 */

#ifndef SYSI_ORACLE
#include <sysi.h>
#endif
#ifndef YS_ORACLE
#include <ys.h>
#endif
#ifndef YSMSC_ORACLE
#include <ysmsc.h>
#endif
#ifndef YSI_ORACLE
#include <ysi.h>
#endif
#ifndef YSMI_ORACLE
#include <ysmi.h>
#endif

/*
 * Identifier Declarations
 */
externdef ysidDecl(YS_EX_OUTMEM) = "ys::outmem";
static    ysidDecl(YS_EX_REFREE) = "ys::refree";

externdef ysmtagDecl(YSMHP_TAG) = "ysmhp";
externdef ysmtagDecl(YSMEOB_TAG) = "(end of buffer)";
externdef ysmtagDecl(YSMFREE_TAG) = "(freed block)";

/*
 * ysmCreate - create a global heap
 */
ysmhp *ysmCreate(ysmaf af, ysmrf rf, ysmff ff, ysbv *bv, sword nbv)
{
  ysmhp   *hp;
  sb4      sz, init;
  ysmahdr *ahdr;
  ysmfhdr *prevptr, *fhdr;
  ub1     *buf;

  /* check parameters */
  if ((af || rf || ff) && (!(af && rf && ff) || (bv || nbv)))
    yseThrow(YS_EX_BADPARAM);

  if ((bv || nbv) && !(bv && nbv > 0))
    yseThrow(YS_EX_BADPARAM);

  if (af)
    {
      /* create function-based heap */
      if (!(ahdr = (ysmahdr *) (*af)(sizeof(ysmahdr) + sizeof(ysmhp))))
	yseThrow(YS_EX_FAILURE);

      ahdr->sz = -((sb4) (sizeof(ysmahdr) + sizeof(ysmhp)));
      ahdr->tag = YSMHP_TAG;
      hp = (ysmhp *) (ahdr + 1);

      hp->roveptr = (ysmfhdr *) 0;
      hp->limit = 0;
      hp->inuse = hp->maxusg = 0;
      hp->bv = bv, hp->nbv = nbv;
    }
  else
    {
      /* create fixed-size heap */
      sz = (sb4) ysTruncVal(bv->len, SYSM_STRICT_ALIGN);
      sz = (sz - 2 * sizeof(ysmahdr) - sizeof(ysmhp));
      if (sz < (sb4) YSM_MIN_SIZE)
	yseThrow(YS_EX_BADPARAM);

      /* allocate heap descriptor */
      ahdr = (ysmahdr *) (bv->buf + sz);
      ahdr->sz = -((sb4) (sizeof(ysmahdr) + sizeof(ysmhp)));
      ahdr->tag = YSMHP_TAG;
      hp = (ysmhp *) (ahdr + 1);

      /* initialize heap descriptor */
      hp->limit = 0;
      hp->maxusg = hp->inuse = -ahdr->sz;
      hp->bv = bv, hp->nbv = nbv;

      /* initialize free chain and prepare for scan */
      prevptr = hp->roveptr = (ysmfhdr *) bv->buf;
      init = sizeof(ysmhp) + sizeof(ysmahdr);

      do
	{
	  /* compute size of buffer */
	  sz = (sb4) ysTruncVal(bv->len, SYSM_STRICT_ALIGN);
	  sz = (sz - sizeof(ysmahdr));
	  buf = bv->buf;

	  if (sz < YSM_MIN_SIZE || (0x7fffffff - hp->limit) < sz)
	    yseThrow(YS_EX_BADPARAM);

	  hp->limit += sz;

	  /* place empty allocated marker at the end of the buffer */
	  ahdr = (ysmahdr *) (buf + sz);
	  ahdr->sz = -1;
	  ahdr->tag = YSMEOB_TAG;

	  /* create free block and link into free chain */
	  fhdr = (ysmfhdr *) buf;
	  fhdr->sz = sz - init;
	  fhdr->prev = prevptr;
	  prevptr->next = fhdr;

	  /* skip to next buffer element */
	  if (--nbv)
	    prevptr = fhdr, init = 0, bv++;
	} while (nbv);

      /* complete circular chain */
      hp->roveptr->prev = fhdr;
      fhdr->next = hp->roveptr;
    }

  /* initialize common heap fields */
  hp->bhvr = YSM_THROW;
  hp->afcnt = 0;
  hp->af = af, hp->rf = rf, hp->ff = ff;

  return hp;
}

/*
 * ysmDestroy - destroy a global heap
 */
void ysmDestroy(ysmhp *hp)
{
  ysmahdr *ahdr;

  if (hp->ff)
    {
      ahdr = ((ysmahdr *) hp) - 1;
      (*hp->ff)((dvoid *) ahdr);
    }
}

/*
 * ysmAlloc - allocate memory
 */
dvoid *ysmAlloc(ysmhp *hp, size_t len, CONST char *tag)
{
  sb4      sz;
  ysmfhdr *ptr, *nextptr;
  ysmahdr *ahdr;
  dvoid   *buf;

  /* check parameters */
  ysmCheck((dvoid *) hp, YSMHP_TAG);

  /* attempt the allocation */
  sz = (sb4) len;
  if (sz < 0 || (hp->limit && (sz > hp->limit - hp->inuse)))
    ptr = (ysmfhdr *) 0;
  else if (hp->af)
    {
      /* use the allocation callback if one is defined */
      sz += sizeof(ysmahdr);
      ptr = (ysmfhdr *) (*hp->af)((size_t) sz);
    }
  else
    {
      /* adjust the allocation size to ensure that we have room for our
       * free block header, and align the size to the platform's strictest
       * alignment
       */
      if (sz < (sizeof(ysmfhdr) - sizeof(ysmahdr)))
	sz = YSM_MIN_SIZE;
      else
	sz = ysRoundVal(sz + sizeof(ysmahdr), SYSM_STRICT_ALIGN);

      /* scan our free list, starting from our roving pointer.  continue
       * until the first block large enough to meet the allocation request
       * is found.  during the scan, coalesce adjacent free blocks before
       * checking the size of the block.
       */
      ptr = hp->roveptr;
      for (;;)
	{
	  nextptr = (ysmfhdr *) (((ub1 *) ptr) + ptr->sz);
	  if (nextptr->sz > 0)
	    {
	      /* coalesce the adjacent free blocks */
	      ptr->sz += nextptr->sz;
	      nextptr->prev->next = nextptr->next;
	      nextptr->next->prev = nextptr->prev;
	      if (hp->roveptr == nextptr)
		hp->roveptr = ptr;
	    }
	  else if (ptr->sz < sz)
	    {
	      /* skip this block; it's too small.  if we cycled, then fail. */
	      ptr = ptr->next;
	      if (ptr == hp->roveptr)
		{
		  ptr = (ysmfhdr *) 0;
		  buf = (dvoid *) 0;
		  break;
		}
	    }
	  else
	    {
	      /* found a valid block.  if we are close enough to a perfect
	       * fit, remove the block from the free list.  otherwise,
	       * allocate the user's block from the end of this block (so
	       * that we don't have to adjust pointers for our free list).
	       */
	      if (ptr->sz - sz < YSM_MIN_SIZE)
		{
		  if (ptr->next == ptr)
		    {
		      /* this is about to remove the very last free block in
		       * the heap.  the code cannot deal with an empty free
		       * block chain, so convert this to an allocation
		       * failure.
		       */
		      ptr = (ysmfhdr *) 0;
		    }
		  else
		    {
		      ptr->prev->next = ptr->next;
		      ptr->next->prev = ptr->prev;
		      hp->roveptr = ptr->next;
		      sz = ptr->sz;
		    }
		}
	      else
		{
		  ptr->sz -= sz;
		  hp->roveptr = ptr;

		  ptr = (ysmfhdr *) (((ub1 *) ptr) + ptr->sz);
		}
	      break;
	    }
	}
    }

  if (ptr)
    {
      /* if the allocation was successful, the block is now allocated.
       * convert the header by storing a negative size.  accumulate
       * statistics.
       */
      ahdr = (ysmahdr *) ptr;
      ahdr->sz = -sz;
      ahdr->tag = tag;

      hp->inuse += sz;
      if (hp->inuse > hp->maxusg)
	hp->maxusg = hp->inuse;

      buf = (dvoid *) (ahdr + 1);
    }
  else
    {
      /* the allocation failed, track the error. */
      if (hp == ysmGlbHeap())
	ysePanic(YS_EX_OUTMEM);

      hp->afcnt++;
      buf = (dvoid *) 0;
    }

  /* observe the allocation failure behavior if necessary */
  if (!buf && hp->bhvr == YSM_THROW)
    yseThrowObj(YS_EX_OUTMEM, hp);

  return buf;
}

/*
 * ysmRealloc - reallocate memory
 */
dvoid *ysmRealloc(ysmhp *hp, dvoid *buf, size_t len)
{
  ysmahdr *ahdr;
  sb4      oldsz, sz, diff;
  ysmfhdr *ptr;
  sword    oldbhvr;
  dvoid   *oldbuf;

  /* check parameters */
  ysmCheck((dvoid *) hp, YSMHP_TAG);
  if (!buf)
    return ysmAlloc(hp, len, "NULL PTR REALLOC");

  /* attempt the reallocation */
  ahdr = ((ysmahdr *) buf) - 1;
  oldsz = -ahdr->sz - sizeof(ysmahdr);
  sz = (sb4) len;
  diff = sz - oldsz;

  if (sz < 0 || (hp->limit && (diff > hp->limit - hp->inuse)))
    ahdr = (ysmahdr *) 0, buf = (dvoid *) 0;
  else if (hp->rf)
    {
      /* use the reallocation callback if one is defined */
      sz += sizeof(ysmahdr);
      ahdr = (ysmahdr *) (*hp->rf)((dvoid *) ahdr, (size_t) sz);
      if (!ahdr)
	buf = (dvoid *) 0;
    }
  else if (sz <= oldsz)
    {
      /* truncate block */
      if (sz < (sizeof(ysmfhdr) - sizeof(ysmahdr)))
	sz = YSM_MIN_SIZE;
      else
	sz = ysRoundVal(sz + sizeof(ysmahdr), SYSM_STRICT_ALIGN);

      /* create a new free block following this one */
      ptr = (ysmfhdr *) (((ub1 *) ahdr) + sz);
      ptr->next = hp->roveptr;
      ptr->prev = hp->roveptr->prev;
      ptr->next->prev = ptr;
      ptr->prev->next = ptr;
    }
  else
    {
      /* expand the block; this should technically check the following
       * blocks and coalesce free ones because if we can find a large
       * enough block, then we won't have to move this one.  But if
       * that fails we still have to fall back on our basic allocate/
       * copy/free sequence.  So just do this right away for now.
       */
      oldbhvr = hp->bhvr;
      hp->bhvr = YSM_RETURN;
      oldbuf = buf;
      buf = ysmAlloc(hp, len, ahdr->tag);
      hp->bhvr = oldbhvr;
      ahdr = (ysmahdr *) 0;

      if (buf)
	{
	  DISCARD memcpy(buf, oldbuf, len);
	  ysmFree(hp, oldbuf);
	}
    }

  if (ahdr)
    {
      /* if the allocation was successful, the block is allocated.  convert
       * the header by storing a negative size.  accumulate statistics.
       */
      ahdr->sz = -sz;
      hp->inuse += (sz - oldsz);
      if (hp->inuse > hp->maxusg)
	hp->maxusg = hp->inuse;

      buf = (dvoid *) (ahdr + 1);
    }
  else if (!buf)
    {
      /* the allocation failed, track the error. */
      hp->afcnt++;
    }

  /* observe the allocation failure behavior if necessary */
  if (!buf && hp->bhvr == YSM_THROW)
    yseThrowObj(YS_EX_OUTMEM, hp);

  return buf;
}

/*
 * ysmFree - free memory
 */
void ysmFree(ysmhp *hp, dvoid *buf)
{
  sb4      sz;
  ysmfhdr *ptr;
  ysmahdr *ahdr;

  /* check parameters */
  ysmCheck((dvoid *) hp, YSMHP_TAG);

  if (!buf)
    return;

  /* retrieve the size and accumulate statistics */
  ahdr = ((ysmahdr *) buf) - 1;
  if (ahdr->tag == YSMFREE_TAG)
    ysePanic(YS_EX_REFREE);
  sz = -ahdr->sz;
  hp->inuse -= sz;

  /* free the buffer */
  if (hp->ff)
    {
      /* invalide the tag and use the free callback if one is defined */
      ahdr->tag = YSMFREE_TAG;
      (*hp->ff)((dvoid *) ahdr);
    }
  else
    {
      /* convert the header by storing a positive size */
      ptr = (ysmfhdr *) ahdr;
      ptr->sz = sz;

      /* insert the block into the free chain, immediately preceding the
       * roving pointer
       */
      ptr->next = hp->roveptr;
      ptr->prev = hp->roveptr->prev;
      ptr->next->prev = ptr;
      ptr->prev->next = ptr;
    }
}

/*
 * ysmGetSize - get size of allocated block
 */
size_t ysmGetSize(dvoid *buf)
{
  ysmahdr *ahdr;

  if(!buf)
    return (size_t) 0;

  ahdr = (ysmahdr *) (((ub1 *) buf) - sizeof(ysmahdr));
  return (size_t) ((-ahdr->sz) - sizeof(ysmahdr));
}

/*
 * ysmSetBehavior - set behavior on heap
 */
sword ysmSetBehavior(ysmhp *hp, sword bhvr)
{
  sword  old;

  ysmCheck((dvoid *) hp, YSMHP_TAG);

  /* do not allow the global heap behavior to be changed */
  if (hp == ysmGlbHeap())
    yseThrow(YS_EX_BADPARAM);

  /* change the behavior */
  old = hp->bhvr;
  hp->bhvr = bhvr;
  return old;
}

/*
 * ysSetLimit - set the heap limit
 */
sb4 ysmSetLimit(ysmhp *hp, sb4 limit)
{
  sword i;
  sb4   total;

  if (hp->af)
    hp->limit = (limit ? max(limit, hp->inuse) : 0);
  else
    {
      for (i = 0, total = 0; i < hp->nbv; i++)
	total += (sb4) hp->bv[i].len;

      if (!limit)
	limit = total;

      hp->limit = max(min(limit, total), hp->inuse);
    }

  return hp->limit;
}

/*
 * ysmGetStats - get current statistics
 */
void ysmGetStats(ysmhp *hp, sb4 *limit, sb4 *curusage, sb4 *maxusage,
		sb4 *afcnt)
{
  ysmCheck((dvoid *) hp, YSMHP_TAG);
  *limit = hp->limit;
  *curusage = hp->inuse;
  *maxusage = hp->maxusg;
  *afcnt = hp->afcnt;
}

/*
 * ysmAlterTag - alter a tag
 */
void ysmAlterTag(dvoid *ptr, CONST char *newtag)
{
  ysmahdr *ahdr;

  if (!ptr)
    ysePanic(YS_EX_BADMAGIC);

  ahdr = (ysmahdr *) (((ub1 *) ptr) - sizeof(ysmahdr));
  ahdr->tag = newtag;
}

/*
 * ysmFGlbFree - free from global heap
 */
void ysmFGlbFree(dvoid *ptr)
{
  ysmFree(ysmGlbHeap(), ptr);
}
