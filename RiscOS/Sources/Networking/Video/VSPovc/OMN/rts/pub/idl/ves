#ifndef VES_ORACLE
#define VES_ORACLE

// ves.idl
// Copyright (C)1996,1997 Oracle Corporation
// 
// This CORBA interface definition specifies the data types that are used
// for the Video Encoding Standard Application Programming Interface
// (VESAPI). VESAPI is a method of loading encoded content (audio and/or
// video) onto a video server (usually in realtime but not necessarily)
// which includes metadata that the server can later use to provide
// VCR-style functionality to clients.
//
// The actual CORBA methods used for the Oracle Video Server can be found
// in vesm.idl. The C language client API is defined in vesw.h; it makes
// heavy use of the data types defined in this file.
//
// The C header file ves.h is generated from this file. Many of the C
// mappings for the IDL structures are included here for ease of
// reference when working with vesw.h, though you will need to consult
// ves.h for the full mapping. In sequences, you want to set both _maximum
// and _length to the number of items (not the number of bytes, unless you
// happen to have a sequence of chars) that _buffer points to. See the
// demo programs for some usage examples.
// 
// 13-Aug-97 dweaver  Public debut
//

module ves
{
  // The vendor field is used for the encoder to identify itself to the
  // server. Typically, the server only uses this information as a
  // signature so it can identify the source encoder in case there are
  // any problems. A suggested format for this string is:
  //   productName:versionNumber:dateCompiled
  // for example,
  //   MegaTronics Mpeg-O-Rama II:1.0:97-07-22
  // which may give the server a chance to parse this string if it ever
  // really needs to.
  typedef string<256> vendor;  // C mapping: char* ves_vendor

  // There is an implicit assumption that there is a default video track and
  // a default audio track in the encoded stream. These fields specify the
  // appropriate codec for each of those tracks. Typically, this information
  // could be used to determine whether or not a specific client will be
  // able to decode the video stream or not.  We recommend using the Video
  // for Windows or QuickTime four character format codes. It is important
  // to recognize that these codes aren't actually strings, but rather
  // sequences of bytes, since some codecs use nulls as part of their code.
  //
  // Sample video strings
  //    MPEG        ISO/IEC 11172 video (MPEG-1)
  //    MPG2        ISO/IEC 13818-2 video (MPEG-2)
  //    CVID        Radius Cinepak
  //    UCOD        Iterated Systems ClearVideo
  //    IV41        Intel Indeo V4.1
  //    0x04006931  Motion Pixels
  //
  // Audio isn't quite as nice, at least on the Windows side. For WAVE
  // audio formats, use WAVE followed by the two byte codec code. For
  // example, Microsoft's ADPCM codec would be 0x574156450002.
  //
  // Note: The video server isn't expected to be aware of this information;
  //       it is concerned only with the format defined by ves::format, below.
  //
  // C mapping: struct ves_vidCmp { ub4 _maximum; ub4 _length; ub1* _buffer; }
  typedef sequence<octet, 20> vidCmp;    // video codec
  // C mapping: struct ves_audCmp { ub4 _maximum; ub4 _length; ub1* _buffer; }
  typedef sequence<octet, 20> audCmp;    // audio codec

  // Video server format. This information is used by a video server to
  // figure out how to generate legal play points from the content. This
  // is typically a function of a transport wrap or container format.
  //
  // This list can grow as servers add support for features specific
  // to certain container formats. Adding a new format here implies adding
  // format specific structures for headers and tags, as well; otherwise,
  // raw key frame (RKF) is the catch-all default format.
  //
  enum format   // C mapping: typedef ub4 ves_format
  {             // C mapping of elements is ves_formatFoo
    formatInvalid,      // CORBA IDL enums always start at 0, a value we avoid
    formatMpeg1SS,      // Mpeg1 audio and video in Mpeg1 system stream
    formatMpeg2Trans,   // Mpeg1/2 audio and video in Mpeg2 transport wrap
    formatRKF           // Raw key frame format, often Oracle Streaming Format
  };

  // The time structure pulls double duty in this interface: it is used both
  // to specify a duration for the feed and for the timestamps that go into
  // the tags.
  enum timeType // C mapping: typedef ub4 ves_timeType
  {             // C mapping of elements is ves_timeTypeFoo
    timeTypeInvalid,
    timeTypeSMPTE,      // HH:MM:SS:FF time format
    timeTypeMillisecs,  // milliseconds
    timeTypeMpegSCR,    // In practice, any 33-bit, 90kHz MPEG time type
    timeTypeMpegPCR,    // 42 bit, 27MHz resolution MPEG-2 clock
    timeTypeBytes       // Only valid for durations (and discouraged there)
  };

  struct SMPTE  // C mapping: struct ves_SMPTE
  {
    unsigned long   hour;
    octet           minute;
    octet           second;
    unsigned short  frame;
  };

  // C mapping for timeType:
  // struct ves_time {
  //   ves_time     _d;        // discriminator of union
  //   union {
  //     sysb8      ves_timeInvalid;
  //     ves_SMPTE  ves_timeSMPTE;
  //     sysb8      ves_timeMs;
  //   [ et cetera ]
  //   }            _u;
  // }
  // sample usage looks something like:
  //   dst->_d = ves_timeTypeMillisecs;
  //   sysb8ext(&dst->_u.ves_timeMs, (ub4)2000);  // set dst to 2 seconds
  union time switch (timeType)
  {
    case timeTypeInvalid:   long long  ves_timeInvalid;
    case timeTypeSMPTE:     SMPTE      ves_timeSMPTE;
    case timeTypeMillisecs: long long  ves_timeMs;
    case timeTypeMpegSCR:   long long  ves_timeSCR;
    case timeTypeMpegPCR:   long long  ves_timePCR;
    case timeTypeBytes:     long long  ves_timeBytes;
  };

  //------------------------------------------------------------------------
  // 
  //          Header structures
  //
  //  Header structures specify global information about the entire feed.
  //  This means that they aren't allowed to change once a feed has begun.
  //  The server will rely on this data when it streams content to the
  //  client.
  // 
  //------------------------------------------------------------------------
  // The following format specific structures provide detail for the ves::hdr
  // struct which follows.
  struct m1sHdr  // C mapping: struct ves_m1sHdr
  {
    // This is the sequence header in the video elementary stream, including
    // the start code (0x000001b3).
    // The sequence header may not change during the course of the feed.
    sequence<octet, 4096> seqHdr;
  };
  struct m2tHdr  // C mapping: struct ves_m2tHdr
  {
    unsigned short  videoPid;   // PID carrying default video elementary stream
    unsigned short  audioPid;   // PID carrying default audio elementary stream
    unsigned short  clockPid;   // PID that carries the program clock reference
    octet           videoStream;  // video elementary stream identifier
    // Entire contents of the PAT, which may not change during the feed.
    sequence<octet, 4096> pat;
    // Entire contents of the PMT, which may not change during the feed.
    sequence<octet, 4096> pmt;
    // The sequence header includes the start code (0x000001b3); like the
    // PAT and the PMT, it may not change during the course of the feed.
    sequence<octet, 4096> seqHdr;
  };
  struct rkfHdr  // C mapping: struct ves_rkfHdr
  {
    // Init data is the bytestream that needs to be transmitted before play
    // begins at a key frame (aka blind seek).
    sequence<octet> initData;
  };

  struct hdr     // C mapping: struct ves_hdr
  {
    vendor         vend;
    format         fmt;
    vidCmp         vid;
    audCmp         aud;

    // The following information helps the client set up its display windows
    unsigned short heightInPixels;
    unsigned short widthInPixels;
    // The pixel aspect ratio is ht*10000/wd of an INDIVIDUAL pixel,
    // e.g. 10000 (ten thousand) for square pixels.
    long           pelAspectRatio;
    // frame rate in frames per second * 1000, e.g. 29970 -> 29.97 fps
    unsigned long  frameRate;

    // C mapping for ves_hdr_hdrCompData:
    // struct ves_hdr_hdrCompData {
    //   ves_format     _d;      // the discriminator for the union
    //   union {
    //     ves_m1sHdr   m1s;
    //     ves_m2tHdr   m2t;
    //     ves_rkfHdr   rkf;
    //   } _u;                   // the data portion of the union
    // };
    // so you end up with things that look like:
    // myHdr->compData._u.rkf.initData._maximum =
    //   myHdr->compData._u.rkf.initData._length = 20;
    union hdrCompData switch (format)
    {
      case formatMpeg1SS:     m1sHdr  m1s;
      case formatMpeg2Trans:  m2tHdr  m2t;
      case formatRKF:         rkfHdr  rkf;
    }              compData;
  };

  //------------------------------------------------------------------------
  // 
  //          Tag structures and data types
  //
  //  Tags describe access points to the content stream. Usually, this
  //  corresponds to a single frame from the video. It is not necessary
  //  (and is probably not a good idea) to tag every frame. The idea
  //  is to have enough granularity for "accurate enough" seeks and "smooth
  //  enough" visual fast forward and rewind. The ideal rate for this varies
  //  depending on the application, but a number between one tag every two
  //  seconds and two tags every second is usually pretty good. For MPEG,
  //  this is often equivalent to tagging every I-frame. In combo audio/video
  //  streams, no "audio frames" should ever be tagged.
  //
  //  In an audio-only stream, a concept such as "frames" doesn't truly
  //  exist. However, it is possible to think of a group of audio samples
  //  as a frame and treat it that way.
  //
  //------------------------------------------------------------------------
  enum frame   // C mapping: ub4 ves_frame
  {
    frameInvalid,
    frameMpegI,      // MPEG I, P and B frames, unsurprisingly...
    frameMpegP,
    frameMpegB,
    frameRawKey,     // A random access point. Video can be legally played
                     // from this point at any time if it is preceded by the
                     // the init data.
    frameRawBias,    // A conditional access point; it can only be used if
                     // the previous key frame was sent. Note that intermediate
                     // bias frames _may_ have been dropped, so these frames
                     // need to be decodable based only on the last key frame.
    frameRawAudio    // An audio-only random access point. Typically only
                     // used in audio-only programs.
  };

  // The following format specific structures provide detail for the ves::tag
  // struct which follows.
  struct m1sTag // C-mapping: struct ves_m1sTag
  {
    // The videoStreamCode is the stream_id found in the system header
    // for this video frame; this byte is always "1110 xxxx" to indicate
    // an ISO 11172-2 video stream. See section 2.4.4.2 of the MPEG-1
    // systems spec, ISO/IEC 11172-1.
    octet          videoStreamCode;
  };
  struct m2tTag // C-mapping: struct ves_m2tTag
  {
    //----------------------------------------------------------------------
    // In packet descriptions below, 47 is the sync byte, Px bytes include
    // the transport error indicator, payload unit start indicator, transport
    // priority and PID. Cx bytes include the transport scrambling control,
    // adaptation field control and continuity counter (taken from section
    // 2.4.3.2 of the MPEG-2 spec, ISO/IEC 13818-1: 1994(E))
    //
    //
    // These letters represent the MPEG-2 transport packets that hold a
    // particular picture:
    //
    //   A B.....B C
    //
    // Packet A contains the first 00 of the picture start code for the frame.
    // The LEADING ZEROS field is the number of bytes leading up to that 00
    // in the trasport packet payload. For instance, if the packet was
    //
    //   A:  47 P1 P2 C1 00 00 01 00 (picture header continues...)
    //
    // the number of "leading zeros" would be zero.
    // On the other hand, if the start code was split between two transport
    // packets, the number of "leading zeros" could be as high as 183, e.g.
    //
    //   A:  47 P1 P2 C1 ... 00
    //   B:  47 P3 P4 C2 00 01 00 (picture header continues...)
    //
    // The BYTE OFFSET is the offset of the picture start code from the
    // beginning of the stream. This number is zero-based; for instance,
    // if A was the 101st packet in the stream, and the picture start code
    // was the first thing in that packets' payload, the "byte offset"
    // would be:
    //
    //   100 * 188 + 4 = 18804.
    //
    // The CONTINUITY COUNTER is the last four bits of the C1 byte in packet A.
    //
    // Similar to "leading zeros", TRAILING ZEROS is the number of bytes in
    // packet C after the last byte of the picture data.
    //
    // NULL PACKETS is the number of B packets that have the null pid (1FFF).
    //
    // NON VIDEO PACKETS is the number of B packets that have any PID other
    // than the video PID (i.e., the PID in packets A and C). This includes
    // the "null packets".
    //
    // For HEADER PES LENGTH, we need to add a few more transport packets to
    // the discussion in front of packet A. Packet H contains a program
    // elementary stream header for the PES packet which A is a part of:
    //
    //   H [J|K] ... [J|K] A B....B C
    //
    // Before we go any further, section 2.4.3.7 of the spec under
    // "PES_packet_length" states:
    //
    //     ... A value of 0 indicates that the PES packet length is neither
    //     specified nor bounded and is allowed only in PES packets whose
    //     payload is a video elementary stream contained in Transport Stream
    //     packets.
    //
    // Zero is a completely acceptable value for "header PES length", assuming
    // that you record a zero for the PES packet length of all of your video
    // elementary streams. However, if you record a non-zero value in the
    // PES_packet_length for video elementary streams, the "header PES length"
    // field is calculable and must be accurate.
    //
    // Packet H has the same PID as A. J packets are other packets with the
    // same PID as A and H; K packets are anything else. "header PES length"
    // is the number of bytes left in the PES_packet after the "byte offset",
    // (including the video start code). In a parser, the PES_packet_length
    // is decremented until the next video start code is found; you might
    // accomplish much the same thing by subtracting 
    //
    //   (bytes in H after PES_packet_len
    //    + no. of J packets * 184
    //    + "leading zeros")
    //
    // from the PES_packet_len.
    //----------------------------------------------------------------------
    octet          continuityCounter;
    unsigned long  leadingZeros;       // byte count to first video in frame
    unsigned long  trailingZeros;      // bytes from last video to frame end
    unsigned short headerPesLength;    // byte count
    unsigned short trailerPesLength;   // byte count
    unsigned short nonVideoPackets;    // packet count
    unsigned short nullPackets;        // packet count
  };
  struct rkfTag // C-mapping: struct ves_rkfTag
  {
    octet          nothing;          // IDL doesn't tolerate empty structs
  };

  struct tag    // C-mapping: struct ves_tag; Note that bytestamp is a sysb8.
  {
    frame          frameType;
    // Typically we use the presentation time to identify the frame. However,
    // as long as you're precise in relation to the tag frequency and accurate
    // to plus or minus a couple seconds, you can use whatever, so long as
    // your application doesn't have additional synchronization requirements.
    time           timestamp;
    // The bytestamp is relative to the first byte that was sent to the
    // server (that byte being byte zero).
    long long      byteOffset;
    // Number of bytes from the bytestamp to the last byte of video in
    // the frame. Has a somewhat format-specific meaning.
    unsigned long  videoByteLength;
    // C mapping for ves_tag_tagCompData (see ves_hdr_hdrCompData for usage):
    // struct ves_tag_tagCompData {
    //   ves_format _d;
    //   union {
    //     ves_feed_m1sTag m1s;
    //     ves_feed_m2tTag m2t;
    //     ves_feed_rkfTag rkf;
    //   } _u;
    // };
    union tagCompData switch (format)
    {
      case formatMpeg1SS:    m1sTag  m1s;
      case formatMpeg2Trans: m2tTag  m2t;
      case formatRKF:        rkfTag  rkf;
    }              compData;
  };

  // An array of tags. C mapping:
  // struct ves_tagList { ub4 _maximum; ub4 _length;
  //                       struct ves_tag* _buffer; }
  typedef sequence<tag, 65536> tagList;

}; // module ves

#endif // !VES_ORACLE
