<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
   <TITLE>Frequently Asked Questions about MPEG Audio Layer-3</TITLE>
   <META NAME="GENERATOR" CONTENT="Mozilla/3.0Gold (Win95; I) [Netscape]">
</HEAD>
<BODY>

<P><A NAME="news0"></A></P>

<H2>Frequently Asked Questions about MPEG Audio Layer-3, Fraunhofer-IIS,
and all the rest...</H2>

<H2>Version 2.83</H2>

<H3><A HREF="#news1"><IMG SRC="new.gif" BORDER=0 HEIGHT=63 WIDTH=61 ALIGN=LEFT></A>
To find the latest changes, just follow this clickable sign ! </H3>

<P>This text will be continously upgraded: step by step, more answers and
more information will be included. Yes, we definitely know that there are
a lot more questions to answer! But we cannot do that all at once. So,
some parts may remain &quot;under construction&quot; for a while, and other
parts may be modified due to new results of our research work or new applications.
You find the latest release at</P>

<CENTER><P><A HREF="http://www.iis.fhg.de/departs/amm/layer3/sw/">http://www.iis.fhg.de/departs/amm/layer3/sw/</A>
or<BR>
<A HREF="ftp://ftp.fhg.de/pub/layer3/l3faq.html">ftp://ftp.fhg.de/pub/layer3/l3faq.html</A></P></CENTER>

<H3>Table of Contents</H3>

<UL>
<LI><A HREF="#intro">Introduction - or: What is &quot;MPEG Audio Layer-3&quot;?</A></LI>

<LI><A HREF="#applications">Applications - or: Layer-3, what is it good
for?</A></LI>

<LI><A HREF="#aboutMPEG">Overview about the ISO-MPEG Standard - or: What
is MPEG all about?</A></LI>

<LI><A HREF="#aboutLayers">Some Basics about MPEG Audio - or: What about
Layer-1, Layer-2, Layer-3?</A></LI>

<LI><A HREF="#aboutLayer3">Advanced Features of Layer-3 - or: Why does
Layer-3 perform so well?</A></LI>

<LI><A HREF="#aboutCoding">Basics of Perceptual Audio Coding - or: What
is the trick?</A></LI>

<LI><A HREF="#references">References - or: Where to find more information?</A></LI>

<LI><A HREF="#aboutFraunhofer">About us - or: What is going on at our Fraunhofer
Institute?</A></LI>
</UL>

<P><A NAME="intro"></A></P>

<H3>Introduction - or: What is &quot;MPEG Audio Layer-3&quot;?</H3>

<P>Today, efficient coding techniques are a must for cost-effective processing
of digital audio and video data by computers. Data reduction of moving
pictures and sound is a key technology for any application with limited
transmission or storage capacity. In the recent years, a lot of progress
has been achieved. While there (still) exist several proprietary formats
for audio and video coding, the ISO/IEC standardisation body has released
an international standard (&quot;MPEG&quot;) for powerful audio and video
coding tools (see: <A HREF="#aboutMPEG">Overview about the ISO-MPEG Standard
- or: What is MPEG all about?</A>).</P>

<P><B>Without data reduction</B>, digital audio signals typically consist
of 16 bit samples recorded at a sampling rate more than twice the actual
audio bandwidth (e.g. 44.1 kHz for Compact Disks). So you end up with more
than <B>1400 kbit</B> to represent just <B>one second of stereo music in
CD quality</B>. By using MPEG audio coding, you may shrink down the original
sound data from a CD by a factor of 12, without losing sound quality. Factors
of 24 and even more still maintain a sound quality that is significantly
better than what you get by just reducing the sampling rate and the resolution
of your samples. Basically, this is realized by &quot;perceptual coding&quot;
techniques addressing the perception of sound waves by the human ear (see:
<A HREF="#aboutCoding">Basics of Perceptual Audio Coding - or: What is
the trick?</A>).</P>

<P>Using MPEG audio, one may achieve a typical data reduction of</P>

<CENTER><TABLE BORDER=1 >
<TR>
<TD>
<DIV ALIGN=right><P><B>1:4</B></P></DIV>
</TD>

<TD>by <B>Layer 1</B> (corresponds with 384 kbps for a stereo signal),</TD>
</TR>

<TR>
<TD>
<DIV ALIGN=right><P><B>1:6...1:8</B></P></DIV>
</TD>

<TD>by <B>Layer 2</B> (corresponds with 256..192 kbps for a stereo signal),</TD>
</TR>

<TR>
<TD><B>1:10...1:12</B></TD>

<TD>by <B>Layer 3</B> (corresponds with 128..112 kbps for a stereo signal),</TD>
</TR>
</TABLE></CENTER>

<P>still maintaining the original CD sound quality.</P>

<P>By exploiting stereo effects and by limiting the audio bandwidth, the
coding schemes may achieve an acceptable sound quality at even lower bitrates.
Layer-3 is the most powerful member of the MPEG audio coding family. For
a given sound quality level, it requires the lowest bitrate - or for a
given bitrate, it achieves the highest sound quality (see: <A HREF="#aboutLayer3">Advanced
Features of Layer-3 - or: Why does Layer-3 perform so well?</A>).</P>

<P>Some typical performance data of <B>Layer-3</B> are:</P>

<CENTER><TABLE BORDER=1 >
<TR>
<TD><B>sound quality</B></TD>

<TD><B>bandwidth </B></TD>

<TD><B>mode </B></TD>

<TD><B>bitrate</B></TD>

<TD><B>reduction ratio</B></TD>
</TR>

<TR>
<TD>&quot;telephone sound&quot;</TD>

<TD>2.5 kHz</TD>

<TD>mono</TD>

<TD>8 kbps (*)</TD>

<TD>96:1</TD>
</TR>

<TR>
<TD>&quot;better than shortwave&quot;</TD>

<TD>4.5 kHz</TD>

<TD>mono</TD>

<TD>16 kbps</TD>

<TD>48:1</TD>
</TR>

<TR>
<TD>&quot;better than AM radio&quot;</TD>

<TD>7.5 kHz</TD>

<TD>mono</TD>

<TD>32 kbps</TD>

<TD>24:1</TD>
</TR>

<TR>
<TD>&quot;similar to FM radio&quot;</TD>

<TD>11 kHz</TD>

<TD>stero</TD>

<TD>56...64 kbps</TD>

<TD>26...24:1</TD>
</TR>

<TR>
<TD>&quot;near-CD&quot;</TD>

<TD>15 kHz</TD>

<TD>stereo</TD>

<TD>96 kbps</TD>

<TD>16:1</TD>
</TR>

<TR>
<TD>&quot;CD&quot;</TD>

<TD>&gt;15 kHz</TD>

<TD>stereo</TD>

<TD>112..128kbps</TD>

<TD>14..12:1</TD>
</TR>
</TABLE></CENTER>

<PRE>*: Fraunhofer uses a non-ISO extension of Layer-3 for enhanced performance (&quot;MPEG 2.5&quot;)
</PRE>

<P>All in all, Layer-3 is the key for numerous low-bitrate, high-quality
sound applications (see: <A HREF="#applications">Applications - or: Layer-3,
what is it good for?</A>).</P>

<P><A NAME="applications"></A></P>

<H3>Applications - or: Layer-3, what is it good for?</H3>

<P>A key technology like Layer-3 is useful for a pretty large spectrum
of applications - practically almost any system with a limited channel
capacity may benefit from it. The following chapters identify some main
areas and list some companies that are actively exploiting the Layer-3
technology. For product-related information, please contact these <A HREF="#addresses">companies
</A>directly.</P>

<H4>Music Links via ISDN</H4>

<P>Digital telephone networks (ISDN = Integrated Services Digital Network)
offer reliable dial-up links with two 64 kbps data channels per basic rate
adapter; other regional networks (in North-America) use 56 kbps data links.
Transmission fees are often rather similar or identical to the traditional
analog phone lines - those allow to transmit up to 28.8 kbps (V.34 modem)
or even 32 kbps (&quot;V.34+&quot;).</P>

<P>Using Layer-3, a low-cost narrowband ISDN connection allows to transmit
CD-quality sound. Audio professionals, like broadcasting stations and sound
studios, benefit from the &quot;music-by-phone&quot; application in various
ways. They save money, as they only pay transmission fees for the actual
time of usage (not 24 h a day in case of a leased phone line) and for a
rather small data channel (one ISDN phone connector for a stereo music
link). Radio stations increase the attractiveness of their programs, as
reporters transmit high-quality takes (e.g. an interview) or live news
without annoying &quot;telephone sound&quot;. And new applications become
possible, e.g. a &quot;virtual studio&quot;, where remote artists may play
along some preproduced material, without actually travelling to the studio.</P>

<P>Examples:</P>

<UL>
<LI>In 1992, Radio FFN, a private broadcasting station in Niedersachsen,
Germany, replaced its leased phone lines with ISDN and Layer-3 codecs,
to transmit 8 local programs 20 min per day to the central broadcasting
studio. This move saved them transmission fees of more than 300.000 US$
per year.</LI>

<LI>As one of the first real-world trials, all private radio stations of
Germany very successfully used Layer-3 codecs during the Winter Olympic
Games in Albertville (France) as reporter links between the various sporting
events and their central studio in Meribel.</LI>

<LI>At the International Music Festival 92 in Bergen, Arne Nordheim composed
a piece of music, where an organ in the church of Trondheim played along
with the symphony orchestra in Bergen; the sound of the organ was transmitted
via ISDN and a Layer-3 codec.</LI>
</UL>

<P>Since 1992, various manufacturers are providing equipment (&quot;codecs&quot;)
for professional audio applications: <A HREF="#AVT">AVT</A>, <A HREF="#Broadcast Electronics">Broadcast
Electronics</A>, <A HREF="#CCS">CCS</A>, <A HREF="#Dialog 4">Dialog 4</A>,
<A HREF="#Telos">Telos</A>.</P>

<H4>Digital Satellite Broadcasting</H4>

<P>Pioneered by <A HREF="#WorldSpace">WorldSpace</A>, a worldwide satellite
digital audio broadcasting system is under construction. Its name is &quot;WorldStar&quot;,
and it will use three geostationary orbit satellites called &quot;AfriStar
1&quot; (21 East), &quot;CaribStar 1&quot; (95 West), and &quot;AsiaStar
1&quot; (105 East), with AfriStar 1 being launched in mid-1998. The other
satellites will follow until mid-1999. Each satellite is equipped with
three downlink spot beams that are pointed so as to cover populations that
provide the greatest radio listener base. Each downlink uses TDM (time
division multiplexing) to carry 96 prime rate channels (16 kbps each).
The prime rate channels are combined to carry broadcast channels ranging
from 16 kbps to 128 kbps; the broadcast channels are coded using MPEG Layer-3.
The prime rate channels may even be dynamically allocated to meet the demands
of the broadcast service (e.g. 4 channels combined for 1 hour to allow
FM quality stereo (64 kbps) for the transmission of a concert with classic
music, followed by 1 hour with 4 separate news channels (16 kbps) in 4
different native tongues).</P>

<P>WorldSpace is offering channels on its three satellites for lease to
international and national broadcasters. Channel reservation agreements
already have been signed with a number of major broadcasters, including
Voice of America, Radio Nederland, the Kenya Broadcasting Corporation,
the national broadcasting authority of Ghana, the national broadcasting
authority of Zimbabwe, New Sky Media of Korea, and RCN of Columbia. Nearly
1 billion $ in private financing has been raised to cover acquisition of
the satellites and for most of the operational costs through full system
implementation in 1999. France&acute;s Alcatel Espace is the spacecraft
prime contractor and supplies the telecommunications payload.</P>

<P>The radio receivers will be designed for maximum convenience of use
at a minimum cost. Low cost receiver will use a small compact patch antenna,
will require practically no pointing, and will tune automatically to selected
channels. Higher end receivers are also envisioned. In a press release
from 5. June 96 (Montreux, Switzerland), WorldSpace declared that it has
awarded production contracts for two million receiver chips; the contracts
were issued to SGS-Thomson and ITT Intermetall, authorizing each company
for an initial production of one million receiver chip-sets.</P>

<P><A HREF="#ITT Intermetall">ITT Intermetall</A> has already gained Layer-3
knowhow by using its mask-programmed DSP technology to develop a single-chip
Layer-3 decoder named &quot;MAS 3503 C&quot;. This chip supports only MPEG-1
Layer-3.</P>

<H4>Audio-on-Demand</H4>

<P>The Internet is a world-wide packet-switched network of computers linked
together by various types of data communications systems. Professional
Internet providers usually access the network through rather high bit-rate
links (e.g., primary rate ISDN with 2 Mbps or ATM with up to 2 Gbps). However,
the average consumer uses low cost, low bit-rate connections (e.g., basic
rate ISDN with 64 kbps or phone line modems with 28.8 or 14.4 kbps). The
actual transmission rate depends on the current user load and the infrastructure
of the part of the Internet in use. From a client&acute;s point of view,
it may unpredictably vary between zero and the maximum bit-rate of its
network modem, with an average bit-rate somewhere in between.</P>

<P>Without audio coding, downloading uncompressed high-quality audio files
from a remote Internet server would result in unfavourably long transmission
times. For example, with an average transmission rate of 28.8 kbaud (optimistic
guess), a single 3-min stereo track from a CD (31.7 Mbyte) would require
a download time of more than 2 hours. Therefore, audio on the Internet
calls for an audio coding scheme that maintains sound quality as far as
possible and allows real-time decoding on a large number of computer platforms
without special add-on hardware. Layer-3 fits very well into this scenario
- real-time players (like <A HREF="#WinPlay3">WinPlay3</A>) are available.
Intranets present an interesting special case, as they usually provide
sufficient bitrate to allow a number of real-time audio links. Furthermore,
our experiments indicate that using the http protocol, a real-time connection
with 56 (112) kbps is possible with one (two) ISDN phone line(s).</P>

<P>If content providers are willing to add audio data onto their Internet
servers, they have to consider carefully the copyright aspects of the music
industry (e.g., artists, producers, record companies). They must not violate
these rights by their actions! In the framework of a European project called
<A HREF="#MODE">MODE</A> (for &quot;Music-on-Demand&quot;), we developed
a flexible protection scheme called <A HREF="#MMP">MMP</A> (for &quot;MultiMedia
protection protocol&quot;) that effectively addresses this issue. Furthermore,
MMP allows to distribute real-time players &quot;virtually free&quot;.</P>

<P>Audio servers may be used plainly for promotional purposes. E.g., museums
may increase the attractiveness of their WWW pages by adding some sound
files, or mail-order services may add sound excerpts to their server to
increase their CD sales numbers. <A HREF="#Opticom">Opticom</A>, a spin-off
from <A HREF="#Fraunhofer-IIS">Fraunhofer</A>, offers system solutions
for this type of application. In spring 1996 (CeBit Hannover), they successfully
demonstrated an &quot;audio-on-demand&quot; application via T-Online together
with the <A HREF="#Deutsche Telekom">Deutsche Telekom</A> and a broadcasting
station, the Suedwestfunk Baden-Baden. </P>

<P>Another music sales systems has been developed by <A HREF="#Cerberus Sound &">Cerberus
Sound &amp; Vision.</A> The company uses a personalized real-time Layer-3
player and a proprietary encryption scheme to sell sound files via the
Internet on a &quot;per song&quot; base. Music servers and mirror sites
are currently located in London, New York, Tokyo and Rio; Melbourne and
Berlin will follow soon.</P>

<P>&quot;Audio-on-the-Internet&quot; is currently a very popular topic.
It does not only comprise audio file transfers with download times as low
as possible, but also streaming audio applications, like &quot;Internet
Radio&quot;. As Layer-3 offers a sound quality &quot;better than shortwave&quot;
at a bitrate of 16 kbps (and, with some modifications, may even be useful
at 8 kbps), various companies currently work on this Internet subject -
e.g., <A HREF="#Opticom">Opticom </A>or <A HREF="#Telos">Telos</A>. </P>

<P>In a partnership with Apple, Telos introduced in September 96 the <A HREF="#AudioActive">Audioactive
</A>technology to support &quot;Internet Radio&quot; applications with
a live audio input processed by a Layer-3 NetCoder Hardware.</P>

<P><A NAME="news1"></A><A HREF="#news2"><IMG SRC="new.gif" ALT="NEW !" BORDER=0 HEIGHT=63 WIDTH=61 ALIGN=LEFT></A>
In December 96, <A HREF="#Microsoft">Microsoft </A>announced to support
MPEG Layer-3 as part of their NetShow multimedia server technology.</P>

<P>As first multimedia authoring tools, &quot;Director Multimedia Studio
2&quot; and &quot;SoundEdit 16&quot; (from <A HREF="#Macromedia">Macromedia</A>)
use Layer-3 to generate compressed sound files for the &quot;shockwave&quot;
format.</P>

<P>Layer-3 encoders and decoders are not only available as studio equipment,
but also as ISA-bus PC boards from <A HREF="#Dialog 4">Dialog 4</A>, along
with application software, or as low-cost (decoder only) PC boards from
<A HREF="#NSM">NSM</A>; recording and playback tools are also available
from <A HREF="#Proton">Proton Data</A>, along with a special decoder module
(called &quot;CenLay3&quot;) that allows to playback Layer-3 files via
the parallel printer port. Proton Data has also developed a &quot;cutting
tool&quot; that allows to manipulate audio data at Layer-3 level.</P>

<P>In addition, a file-oriented Layer-3 encoder and decoder (called &quot;L3ENC&quot;
and &quot;L3DEC&quot;) is available as shareware for various platforms.
Registration is processed by <A HREF="#Opticom">Opticom</A>. Please note
that even for registered users, the use of the shareware is limited to
&quot;personal edition&quot; purposes.</P>

<H4>Real-time Layer-3 players</H4>

<P><A NAME="WinPlay3"></A></P>

<H5>WinPlay3</H5>

<P>&quot;WinPlay3&quot; allows the decoding simply by software on any Pentium
PC in real time. A 80486 class CPU with a built-in floating-point-unit
will also allow some limited operation. For the availability of supported
modes, please refer to the following performance matrix:</P>

<CENTER><TABLE BORDER=1 >
<TR>
<TD></TD>

<TD><B>Pentium </B></TD>

<TD><B>486DX4-133 </B></TD>

<TD><B>486DX2-66 </B></TD>

<TD><B>486DX-50 </B></TD>

<TD><B>486DX-33</B> </TD>
</TR>

<TR ALIGN=CENTER>
<TD ALIGN=LEFT>MPEG-1 stereo</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>-</TD>

<TD>-</TD>

<TD>-</TD>
</TR>

<TR ALIGN=CENTER>
<TD>MPEG-1 downmix* </TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>-</TD>

<TD>-</TD>
</TR>

<TR ALIGN=CENTER>
<TD ALIGN=LEFT>MPEG-1 mono</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>-</TD>
</TR>

<TR ALIGN=CENTER>
<TD ALIGN=LEFT>MPEG-2 stereo</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>-</TD>
</TR>

<TR ALIGN=CENTER>
<TD ALIGN=LEFT>MPEG-2 downmix</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>
</TR>

<TR ALIGN=CENTER>
<TD ALIGN=LEFT>MPEG-2 mono</TD>

<TD>
<CENTER><P>ok</P></CENTER>
</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>

<TD>ok</TD>
</TR>
</TABLE></CENTER>

<PRE>*downmix: the original stereo signal will be played back as a mono signal
&quot;MPEG-1&quot; = &quot;MPEG-1 Layer-3&quot;, i.e. sample rates 32, 44.1 or 48 kHz
&quot;MPEG-2&quot; = &quot;MPEG-2 Layer-3&quot;, i.e. sample rates 16, 22.05 or 24 kHz
</PRE>

<P>On a Pentium-90, WinPlay3 consumes less than 30 % of the CPU power to
decode Layer-3 stereo @ 44.1 kHz, or around 5 % of the CPU power to decode
Layer-3 mono @ 16 kHz.<BR>
At least, a 8-bit stereo sound card is required. For full quality audio,
a 16-bit card is recommended. The card&acute;s MCI driver should support
sampling frequencies from 8 kHz to 48 kHz.<BR>
A standard VGA graphics card is required.<BR>
As WinPlay3 buffers up to 4 seconds of sound data due to the limitations
of the Microsoft Windows multitasking architecture, around 1 MByte free
physical memory must be available.<BR>
WinPlay3 runs with the following operating systems: Microsoft Windows 3.1/3.11
(in extended 386 mode), Windows 95 und Windows NT (long file names not
yet supported).<BR>
WinPlay3 supports file play back of *.mp3 files and direct play from an
URL via HTTP. WinPlay3 can simply be integrated as an helper application
in common browsers, for example Netscape or Mosaic.<BR>
WinPlay3 is available at <A HREF="http://www.iis.fhg.de/departs/amm/layer3/winplay3/">http://www.iis.fhg.de/departs/amm/layer3/winplay3/</A>.
The unregistered player is limited to a reproduction time of 20 sec, i.e.
it will playback each plain Layer-3 file only for this time. If you want
to use your player without limitation, you have to register your player
with <A HREF="#Opticom">Opticom</A>.</P>

<P><A NAME="MMP"></A></P>

<H5>MMP</H5>

<P>As many applications require a player that is &quot;free&quot; for the
user, the latest versions of WinPlay3 (starting with version 2.0) also
support the new &quot;MMP&quot; (&quot;MultiMedia protection protocol&quot;)
format.</P>

<P>MMP is a very flexible data format that may support the following functions:</P>

<UL>
<LI>&quot;unlocking&quot; of the 20 sec playback time limitation</LI>

<LI>&quot;copyright protection&quot; by applying encryption methods to
(part of) the data</LI>

<LI>&quot;title associated data&quot; (e.g. ISRC code, user data)</LI>

<LI>&quot;expiry date&quot; to allow only a limited use</LI>
</UL>

<P>More detailed information is available at <A HREF="http://www.iis.fhg.de/departs/amm/layer3/mmp/">http://www.iis.fhg.de/departs/amm/layer3/mmp/</A>.</P>

<P>In a typical &quot;audio-on-demand&quot; application, the content provider
may &quot;on-the-fly&quot; convert its plain Layer-3 data into MMP data,
by using a &quot;MMP tagger&quot; software (available at <A HREF="#Opticom">Opticom</A>).
The client may use its unregistered player to playback these files without
limitation - the player is &quot;virtually free&quot;. The client need
not pay fees - this issue now may be covered at the server side.</P>

<H5>MPEG Layer 3 Player</H5>

<P>For Mac OS users, a real-time player called &quot;MPEG Layer 3 Player&quot;
with a similar look and feel (and similar features) like &quot;WinPlay3&quot;
will be released very soon. This new player will (finally!) replace the
much simpler (and somewhat buggy) pre-version 0.99 beta that has been available
from <A HREF="http://www.iis.fhg.de/departs/amm/layer3/macplay3/">http://www.iis.fhg.de/departs/amm/layer3/macplay3/</A>.</P>

<H4>Layer-3 Sound on CD-ROMs</H4>

<P>CD-ROMs (and hard disks) have become most popular to store &quot;multimedia&quot;
data. Even with the advent of the new DVD standard, memory capacity will
remain a precious resource for many applications. For uncompressed stereo
signals from a CD, more than 10 MByte are necessary to store one minute
of music. Using Layer-3, less than 1 MByte is enough for the same playing
time. And significantly less memory is necessary, if some limitations in
performance are acceptable. As CD-ROM readers (and pretty soon, writers
too) have already gained a significant market share, typical applications
focus today on storing compressed sound files on CD-ROMs, introducing more
or better sound tracks into the product. Real application examples are
video games, music catalogues or encyclopedias with sound excerpts (e.g.,
&quot;MusicFinder&quot; by <A HREF="#Sygna">Sygna</A>), or talking books
for blind people.</P>

<P><A NAME="news2"></A><A HREF="#news0"><IMG SRC="new.gif" ALT="NEW !!!" BORDER=0 HEIGHT=63 WIDTH=61 ALIGN=LEFT></A>
Since fall 96, <A HREF="#Bertelsmann Publishing">Bertelsmann </A>is selling
their new CD-ROM encyclopedia &quot;Discovery 97&quot; providing information
to around 100.000 key words, with rich multimedia information (e.g. more
than 2400 coloured photos and images, 41 interactive maps, more than 30
minutes of movie clips, 27 slide shows) including 150 minutes of sound
tracks coded with MPEG Layer-3.</P>

<H4>Layer-3 Sound on Silicon</H4>

<P>Up to now, solid-state memories (RAMs, Flash-ROMs) are only used as
audio storage devices in special (niche) applications, as the costs per
byte are much higher than with other types of media (magneto-optical disks
or magnetic tapes). Speech announcement systems for mass transit vehicles
(e.g., busses, subways or trains) are an example for such special applications,
as the rough environment requires to use ROM based memories. Since 1993,
<A HREF="#Meister">Meister Electronic</A> manufactures speech announcement
systems with Layer-3, significantly reducing the precious memory capacity
and, at the same time, significantly improving the sound quality (compared
with their older 64 kbps PCM &quot;phone sound&quot;).</P>

<P>Today, PC-Cards with Flash-ROMs are available, offering a memory capacity
up to 100 MByte and more, but at prohibitive high costs for a consumer
application. Here, further advances in memory and card technology may trigger
a new interesting market segment of &quot;audio-chip-card&quot;-applications.
At a press conference in August 95 in Munich, <A HREF="#Siemens">Siemens</A>
Germany announced the advent of a new cost-effective ROM technology called
the &quot;ROS chip&quot; (ROS = Record-on-Silicon). The first generation
of ROS chips will be in production in 1997, with a storage capacity of
64 Mbit; a next generation with 256 Mbit as well as a one-time user programmable
version will follow. The ROS chips will be embedded in the new &quot;MultiMedia-Card&quot;
from Siemens, a cost-effective card media that will store data, text, graphics,
images and sound. Siemens has already demonstrated a battery-powered audio
player using a prototype &quot;Audio-Card&quot; containing sound tracks
coded with MPEG-Layer-3.</P>

<H3>General Questions and Answers</H3>

<UL>
<LI><B>Q:</B> O.K., Layer-3 is obviously a key to many applications. Where
are its limitations?</LI>

<LI><B>A:</B> Well, Layer-3 is a perceptual audio coding scheme, exploiting
the properties of the human ear, and trying to maintain the original sound
quality as far as possible.<BR>
In contrast, a dedicated speech codec exploits the properties of the human
vocal tract, trying to maintain the intelligibility of the voice signals
as far as possible. Advanced speech coding schemes (e.g., CS-ACELP [LD-CELP]
as standardised by ITU as G.723.1 [G.728]) achieve a useful voice reproduction
at bitrates as low as 5.3 [16] kbps, with a codec delay below 40 [1] ms.
At such very low bitrates, they behave superior to Layer-3 for pure voice
signals, and they offer the low delay that is necessary for full- duplex
voice communications.<BR>
In the framework of MPEG-4, scalable audio coding schemes are devised that
combine speech coding and perceptual audio coding.</LI>

<LI><B>Q:</B> You mentioned the codec delay. May I have some figures?</LI>

<LI><B>A:</B> Well, the standard gives some figures of the theoretical
minimum delay:<BR>
Layer-1: 19 ms (&lt;50 ms)<BR>
Layer-2: 35 ms (100 ms)<BR>
Layer-3: 59 ms (150 ms)<BR>
Practical values are significantly above that. As they depend on the implementation,
precise figures are hard to give. So the numbers in brackets are just rough
thumb values - real codecs may show even higher values. So yes, there are
certain applications that may suffer from such a delay (like feedback links
for remote reporter units). For many other applications (like the ones
mentioned above), delay is of minor interest.</LI>
</UL>

<P><A NAME="aboutMPEG"></A></P>

<H3>Overview about the ISO-MPEG Standard - or: What is MPEG all about?</H3>

<UL>
<LI><B>Q:</B> What is &quot;MPEG&quot;?</LI>

<LI><B>A:</B> MPEG is the &quot;Moving Picture Experts Group&quot;, working
under the joint direction of the International Standards Organization (ISO)
and the International Electro-Technical Commission (IEC). This group works
on standards for the coding of moving pictures and audio. <A HREF="#MPEG">MPEG
</A>has created its own homepage, providing information on the what, where,
when and how of the standards.</LI>

<LI><B>Q:</B> What is MPEG-1, -2, and so on?</LI>

<LI><B>A:</B> MPEG approaches the growing need for multimedia standards
step-by-step. Today, three main &quot;steps&quot; are defined (MPEG-1,
MPEG-2, MPEG-4).</LI>

<UL>
<LI>MPEG-1: &quot;Coding of Moving Pictures and Associated Audio for Digital
Storage Media at up to about 1.5 Mbit/s&quot;</LI>

<LI>MPEG-2: &quot;Generic Coding of Moving Pictures and Associated Audio
Information&quot;</LI>

<LI>MPEG-3: originally planned mainly for HDTV applications; later on,
it was merged into MPEG-2</LI>

<LI>MPEG-4: &quot;Coding of Audio-Visual Objects&quot;</LI>
</UL>

<LI><B>Q:</B> Are MPEG-3 and Layer-3 the same thing?</LI>

<LI><B>A:</B> No! Layer-3 is a powerful audio coding scheme which certainly
is part of the MPEG standard. Layer-3 is defined within the audio part
of both existing international standards, MPEG-1 and MPEG-2. So please
do not mix audio layers and MPEG standards!</LI>

<LI><B>Q:</B> What is the status of MPEG-1?</LI>

<LI><B>A:</B> Work on MPEG-1 is finished. The first three parts are standardized
since 1992. MPEG-1 consists of five parts:</LI>

<UL>
<LI>IS-11172-1 (&quot;System&quot;) describes synchronization and multiplexing
of video and audio signals.</LI>

<LI>IS-11172-2 (&quot;Video&quot;) describes compression of video signals,
focussing on progressive scan video (and mainly aiming at &quot;Video-on-CD&quot;
applications).</LI>

<LI>IS-11172-3 (&quot;Audio&quot;) describes a generic audio coding family,
with three hierarchically compatible members (called &quot;Layer-1&quot;,
&quot;Layer-2&quot; and &quot;Layer-3&quot;).</LI>

<LI>IS-11172-4 (&quot;Compliance Testing&quot;) describes procedures for
determining the characteristics of coded bitstreams and the decoding process
and for testing compliance with the requirements stated in the other parts.</LI>

<LI>DTR-11172-5 (&quot;Software Simulation&quot;) is a technical report
about a full software implementation of the first three parts of MPEG-1.</LI>
</UL>

<LI><B>Q:</B> What is the status of MPEG-2?</LI>

<LI><B>A:</B> MPEG-2 currently consists of nine parts. The first three
parts are standardized since 1994, with some amendments included later
on. Other parts are at different levels of completion.</LI>

<UL>
<LI>IS-13818-1 (&quot;System&quot;) describes synchronization and multiplexing
of video and audio signals; it is also standardised by ITU-T as H.222.</LI>

<LI>IS-13818-2 (&quot;Video&quot;) describes a generic video coding tool
set, supporting interlaced scan; it is also standardised by ITU-T as H.262.</LI>

<LI>IS-13818-3 (&quot;Audio&quot;) describes a backward compatible extension
of MPEG-1 for multichannel audio coding (&quot;surround sound&quot;, &quot;multilingual
sound&quot;) and a non-backward compatible extension to lower sample rates,
to support sound applications with limited audio bandwidth requirements.</LI>

<LI>IS-13818-4 (&quot;Conformance Testing&quot;) describes procedures for
determining the characteristics of coded bitstreams and the decoding process
and for testing compliance with the requirements stated in the other parts.</LI>

<LI>DTR-13818-5 (&quot;Software Simulation&quot;) is a technical report
about a full software implementation of the first three parts of MPEG-2.</LI>

<LI>IS-13818-6 (&quot;System Extensions - Digital Storage Media Command
and Control (DSM-CC))&quot; describes a set of protocols for client-server
applications</LI>

<LI>CD-13818-7 (&quot;Audio, Non-Backwards-Compatible (NBC) - Coding&quot;)
describes an improved audio coding scheme for mono- and stereophonic signals
as well as for multichannel sound</LI>

<LI>13818-8 (&quot;Video, extension to 10-bit input samples&quot;) has
been withdrawn, due to insufficient interest.</LI>

<LI>IS-13818-9 (&quot;Real-Time Interface Specification for Low-Jitter
Applications&quot;) defines timing constraints on the real-time delivery
of MPEG-2 transport bitstreams.</LI>

<LI>WD-13818-10 (&quot;Conformance Extensions - DSM-CC&quot;) describes
the addendum to IS 13818-4 for DSM-CC</LI>
</UL>

<LI><B>Q:</B> &quot;NBC audio&quot;?&quot; What is the motivation for this
working group? What are the results?</LI>

<LI><B>A:</B> Well, during the work for multichannel audio coding (IS-13818-3),
it turned out that backwards compatible (BC) schemes suffer from the matrixing
process. Matrixing is required to allow a MPEG-1 decoder to playback all
surround channels via its two stereophonic channels. Unfortunately, some
of the introduced quantisation noise may become audible after dematrixing.
All in all, during an ISO listening test in spring 1994, BC multichannel
coding performed poorer, compared to non-ISO coding schemes (e.g., Dolby&acute;s
AC-3). So the NBC working group currently develops a new audio coding scheme.
NBC audio achieves a significant better performance, not only for multichannel
surround sound, but even for monophonic signals (here targeting &quot;true
transparency&quot; at 64 kbps). In spring 1996, ISO performed a listening
test for 5-channel surround sound, and NBC audio using a total bit-rate
of 320 kbps scored better than Layer-2 BC at a bit-rate of 640 kbps. NBC
audio will also become one of the MPEG-4 audio coding algorithms.</LI>

<LI><B>Q:</B> How do I get the MPEG documents?</LI>

<LI><B>A:</B> Well, you may contact <A HREF="#ISO Central">ISO</A>, or
you order it from your national standards body. E.g., in Germany, please
contact <A HREF="#DIN">DIN</A>.</LI>

<LI><B>Q:</B> Is some public C source available?</LI>

<LI><B>A:</B> Well, there is &quot;public C source&quot; available on various
sites, e.g. at <A HREF="ftp://ftp.fhg.de/pub/layer3/">ftp://ftp.fhg.de/pub/layer3/</A>
or at <A HREF="ftp://ftp.tnt.uni-hannover.de/pub/MPEG/audio/mpeg2/public_software/">ftp://ftp.tnt.uni-hannover.de/pub/MPEG/audio/mpeg2/public_software/</A>
. This code has been written mainly for explanation purposes, so do not
expect too much performance.</LI>
</UL>

<P><A NAME="aboutLayers"></A></P>

<H3>Some Basics about MPEG Audio - or: What about Layer-1, Layer-2, Layer-3?</H3>

<UL>
<LI><B>Q:</B> Talking about MPEG audio, I always hear &quot;Layer 1, 2
and 3&quot;. What does it mean?</LI>

<LI><B>A:</B> MPEG describes the compression of audio signals using high
performance perceptual coding schemes. It specifies a family of three audio
coding schemes, simply called Layer-1, Layer-2, and Layer-3. From Layer-1
to Layer-3, encoder complexity and performance (sound quality per bitrate)
are increasing.<BR>
The three codecs are compatible in a hierarchical way, i.e. a Layer-N decoder
may be able to decode bitstream data encoded in Layer-N and all Layers
below N (e.g., a Layer-3 decoder may accept Layer-1,-2,-3, whereas a Layer-2
decoder may accept only Layer-1 and -2.)</LI>

<LI><B>Q:</B> So we have a family of three audio coding schemes. What does
the MPEG standard define, exactly?</LI>

<LI><B>A:</B> For each Layer, the standard specifies the bitstream format
and the decoder. To allow for future improvements, it does not specify
the encoder, but an informative chapter gives an example for an encoder
for each Layer.</LI>

<LI><B>Q:</B> What have the three audio Layers in common?</LI>

<LI><B>A:</B> All Layers use the same basic structure. The coding scheme
can be described as &quot;perceptual noise shaping&quot; or &quot;perceptual
subband / transform coding&quot;. The encoder analyzes the spectral components
of the audio signal by calculating a filterbank (transform) and applies
a psychoacoustic model to estimate the just noticeable noise-level. In
its quantization and coding stage, the encoder tries to allocate the available
number of data bits in a way to meet both the bitrate and masking requirements.<BR>
The decoder is much less complex. Its only task is to synthesize an audio
signal out of the coded spectral components.<BR>
All Layers use the same analysis filterbank (polyphase with 32 subbands).
Layer-3 adds a MDCT transform to increase the frequency resolution.<BR>
All Layers use the same &quot;header information&quot; in their bitstream,
to support the hierarchical structure of the standard.<BR>
All Layers have a similar sensitivity to biterrors. They use a bitstream
structure that contains parts that are more sensitive to biterrors (&quot;header&quot;,
&quot;bit allocation&quot;, &quot;scalefactors&quot;, &quot;side information&quot;)
and parts that are less sensitive (&quot;data of spectral components&quot;).<BR>
All Layers support the insertion of programm-associated information (&quot;ancillary
data&quot;) into their audio data bitstream.<BR>
All Layers may use 32, 44.1 or 48 kHz sampling frequency.<BR>
All Layers are allowed to work with similar bitrates:<BR>
Layer-1: from 32 kbps to 448 kbps<BR>
Layer-2: from 32 kbps to 384 kbps<BR>
Layer-3: from 32 kbps to 320 kbps<BR>
The last two statements refer to MPEG-1; with MPEG-2, there is an extension
for the sampling frequencies and bitrates (see below).<BR>
</LI>

<LI><B>Q:</B> What are the main differences between the three Layers, from
a global view?</LI>

<LI><B>A:</B> From Layer-1 to Layer-3, complexity increases (mainly true
for the encoder), overall codec delay increases, and performance increases
(sound quality per bitrate).</LI>

<LI><B>Q:</B> What are the main differences between MPEG-1 and MPEG-2 in
the audio part?</LI>

<LI><B>A:</B> MPEG-1 and MPEG-2 use the same family of audio codecs, Layer-1,
-2 and -3. The new audio features of MPEG-2 are a &quot;low sample rate
extension&quot; to address very low bitrate applications with limited bandwidth
requirements (the new sampling frequencies are 16, 22.05 or 24 kHz, the
bitrates extend down to 8 kbps), and a &quot;multichannel extension&quot;
to address surround sound applications with up to 5 main audio channels
(left, center, right, left surround, right surround) and optionally 1 extra
&quot;low frequency enhancement (LFE)&quot; channel for subwoofer signals;
in addition, a &quot;multilingual extension&quot; allows the inclusion
of up to 7 more audio channels.</LI>

<LI><B>Q:</B> Is this all compatible to each other?</LI>

<LI><B>A:</B> Well, more or less, yes - with the execption of the low sample
rate extension. Obviously, a pure MPEG-1 decoder is not able to handle
the new &quot;half&quot; sample rates.</LI>

<LI><B>Q:</B> You mean: compatible!? With all these extra audio channels?
Please explain!</LI>

<LI><B>A:</B> Compatibility has been a major topic during the MPEG-2 definition
phase. The main idea is to use the same basic bitstream format as defined
in MPEG-1, with the main data field carrying two audio signals (called
L0 and R0) as before, and the ancillary data field carrying the multichannel
extension information. Without going further into details, two terms should
be explained here: &quot;forwards compatible&quot;: the MPEG-2 decoder
has to accept any MPEG-1 audio bitstream (that represents one or two audio
channels) &quot;backwards compatible&quot;: the MPEG-1 decoder should be
able to decode the audio signals in the main data field (L0 and R0) of
the MPEG-2 bitstream &quot;Matrixing&quot; may be used to get the surround
information into L0 and R0: L0 = left signal + a * center signal + b *
left surround signal R0 = right signal + a * center signal + b * right
surround signal Therefore, a MPEG-1 decoder can reproduce a comprehensive
downmix of the full 5- channel information. A MPEG-2 decoder uses the multichannel
extension information (3 more audio signals) to reconstruct the five surround
channels.</LI>

<LI><B>Q:</B> In your footnotes, you indicate the use of some &quot;non-ISO&quot;
extension inside your Fraunhofer codec, called &quot;MPEG 2.5&quot;, to
further improve the performance at very low bitrates (e.g. 8 kbps mono).
What do you mean by this?</LI>

<LI><B>A:</B> Oh, yes. Well, the MPEG-2 standard allows bitrates as low
as 8 kbps, for the low sample rate extension. At such a low bitrate, the
useful audio bandwidth has to be limited anyway, e.g. to 3 kHz. Therefore,
the actual sample rate could be reduced, e.g. to 8 kHz. The lower the sample
rate, the better the frequency resolution, the worse the time resolution,
and the better the ratio between control information and audio payload
inside the bitstream format. As the MPEG-2 standard defines 16 kHz as lowest
sample rate, we introduced a further extension, again dividing the low
sample rates of MPEG-2 by 2, i.e. we introduced 8, 11.025, and 12 kHz -
and we named this extension to the extension &quot;MPEG 2.5&quot;. &quot;Layer-3&quot;
performs significantly better with 8 kbps @ 8 kHz or 16 kbps @ 11 kHz than
with 8 or 16 kbps @ 16 kHz.</LI>
</UL>

<P><A NAME="aboutLayer3"></A></P>

<H3>Advanced Features of Layer-3 - or: Why does Layer-3 perform so well?</H3>

<UL>
<LI><B>Q:</B> Well, I read your statement about &quot;CD-like&quot; performance,
achieved at a data reduction of 4:1 (or 384 kbps total bitrate) with Layer-1,
6..8:1 (or 256..192 kbps total bitrate) with Layer-2, and 12..14:1 (or
128..112 kbps total bitrate) with Layer-3. Can you explain a little further?</LI>

<LI><B>A:</B> Well, each audio Layer extends the features of the Layer
with the lower number. The simplest form is Layer-1. It has been designed
mainly for the DCC (Digital Compact Cassette), where it is used at 384
kbps (called &quot;PASC&quot;). Layer-2 has been designed as a trade-off
between complexity and performance. It achieves a good sound quality at
bitrates down to 192 kbps. Below, sound quality suffers. Layer-3 has been
designed for low bitrates right from the start. It adds a number of &quot;advanced
features&quot; to Layer-2: the frequency resolution is 18 times higher,
which allows a Layer-3 encoder to adapt the quantisation noise much better
to the masking threshold only Layer-3 uses entropy coding (like MPEG video)
to further reduce redundancy only Layer-3 uses a bit reservoir (like MPEG
video) to suppress artefacts in critical moments and Layer-3 may use more
advanced joint-stereo coding methods</LI>

<LI><B>Q:</B> I see. Sounds to me as if Layer-3 is something like a &quot;Layer-2++&quot;.
Now, tell me more about sound quality. How do you assess that?</LI>

<LI><B>A:</B> Today, there is no alternative to expensive listening tests.
During the ISO-MPEG process, a number of international listening tests
have been performed, with a lot of trained listeners. All these tests used
the &quot;triple stimulus, hidden reference&quot; method and the &quot;CCIR
impairment scale&quot; to assess the sound quality. The listening sequence
is &quot;ABC&quot;, with A = original, BC = pair of original / coded signal
with random sequence, and the listener has to evaluate both B and C with
a number between 1.0 and 5.0. The meaning of these values is: 5.0 = transparent
(this should be the original signal) 4.0 = perceptible, but not annoying
(first differences noticable) 3.0 = slightly annoying 2.0 = annoying 1.0
= very annoying</LI>

<LI><B>Q:</B> Listening tests are certainly an expensive task. Is there
really no alternative?</LI>

<LI><B>A:</B> Well, at least not today. Tomorrow may be different. To assess
sound quality with perceptual codecs, all traditional &quot;quality&quot;
parameters (like signal-to-noise ratio, total harmonic distortion, bandwidth)
are rather useless, as any codec may introduce noise and distortions as
long as these do not affect the perceived sound quality. So, listening
tests are necessary, and, if carefully prepared and performed, they lead
to rather reliable results.<BR>
Nevertheless, Fraunhofer-IIS works on the development and standardisation
of objective sound quality assessment tools, too. And there is already
a first product available (contact <A HREF="#Opticom">Opticom</A>), a real-time
measurement tool that nicely supports the analysis of perceptual audio
codecs. If you need more information about the Noise- to-Mask-Ratio (NMR)
technology, feel free to contact <A HREF="mailto:nmr@iis.fhg.de">nmr@iis.fhg.de</A>.</LI>

<LI><B>Q:</B> O.K., back to these listening tests and the performance evaluation.
Come on, tell me some results.</LI>

<LI><B>A:</B> Well, for more details you should study one of these <A HREF="#AES">AES</A>
papers or the MPEG documents. For Layer-3, the main result is that it always
performed superior at low bitrates (64 kbps per audio channel or below).
Well, this is not completely surprising, as Layer-3 uses the same tool
set as Layer-2, but with some additional advanced coding features that
all address the demands of very low bitrate coding. One impressive example
is the ISO-MPEG listening test carried out in September 94 at NTT Japan
(doc. ISO/IEC JTC1/SC29/WG11 N0848, 11.Nov. 94). Another interesting result
is the conclusion of the task group TG 10/2 within the ITU- R, which recommends
the use of low bit-rate audio coding schemes for digital sound-broadcasting
applications (ITU-R doc. BS.1115).</LI>

<LI><B>Q:</B> Very interesting! Tell me more about this recommendation!</LI>

<LI><B>A:</B> The task group TG 10/2 finished its work in 10/93. The recommendation
defines three fields of broadcast applications and recommends Layer-2 with
180 kbps per channel for distribution and contribution links (20 kHz bandwidth,
no audible impairments with up to 5 cascaded codec), Layer-2 with 128 kbps
per channel for emission (20 kHz bandwidth), and Layer-3 with 60 (120)
kbps for mono (stereo) signals for commentary links (15 kHz bandwidth).</LI>
</UL>

<P><A NAME="aboutCoding"></A></P>

<H3>Basics of Perceptual Audio Coding - or: What is the trick?</H3>

<P><I>Sorry - under construction...</I></P>

<P><A NAME="references"></A></P>

<H3>References - or: Where to find more information?</H3>

<P>For around 10 years, perceptual audio coding is a permanent topic at
various scientific conferences; e.g., the <A HREF="#AES">AES </A>(Audio
Engineering Society) organizes two conventions per year. You may find the
following papers helpful:</P>

<OL>
<LI>Brandenburg, Stoll, et al.: &quot;The ISO/MPEG-Audio Codec: A Generic
Standard for Coding of High Quality Digital Audio&quot;, 92nd AES, Vienna
Mar. 92, pp. 3336; revised version (&quot;ISO-MPEG-1 Audio: A Generic Standard...&quot;)
published in the Journal of AES, Vol.42, No. 10, Oct. 94</LI>

<LI>Eberlein, Popp, et al.: &quot;Layer-3, a Flexible Coding Standard&quot;,
94th AES, Berlin Mar. 93, pp. 3493 3) </LI>

<LI>Church, Grill, et al.: &quot;ISDN and ISO/MPEG Layer-3 Audio Coding:
Powerful New tools for Broadcast and Audio Production&quot;, 95th AES,
New York Oct. 93, pp. 3743</LI>

<LI>Grill, Herre, et al.: &quot;Improved MPEG-2 Audio Multi-Channel Encoding&quot;,
96th AES, Amsterdam Feb. 94, pp. 3865</LI>

<LI>Witte, Dietz, et al.: &quot;Single Chip Implementation of an ISO/MPEG
Layer-3 Decoder&quot;, 96th AES, Amsterdam Feb. 94, pp. 3805</LI>

<LI>Herre, Brandenburg, et al.: &quot;Second Generation ISO/MPEG Audio
Layer-3 Coding&quot;, 98th AES, Paris Feb. 95</LI>

<LI>Dietz, Popp, et al.: &quot;Audio Compression for Network Transmission&quot;,
99th AES, New York Oct. 95, pp. 4129</LI>

<LI>Brandenburg, Bosi: &quot;Overview of MPEG-Audio: Current and Future
Standards for Low Bit-Rate Audio Coding, 99th AES, New York Oct. 95, pp.
4130</LI>

<LI>Buchta, Meltzer, et al.: &quot;The WorldStar Sound Format&quot;, 101st
AES, Los Angeles Nov. 96, pp. 4385</LI>

<LI>Bosi, Brandenburg, et al: &quot;ISO/IEC MPEG-2 Advanced Audio Coding&quot;,
101st AES, Los Angeles Nov. 96, pp. 4382</LI>
</OL>

<P>Please note that these papers are not available electronically. You
have to order the preprints (&quot;pp. xxxx&quot;) directly from the AES.</P>

<H3>Addressess<A NAME="addresses"></A></H3>

<UL>
<LI><A NAME="AES"></A><FONT COLOR="#FF0000">AES</FONT>, 60 East 42nd Street,
Suite 2520 New York, NY 10165-2520, USA<BR>
fax: +1 212 682 0477<BR>
email: <A HREF="mailto:hq@aes.org">hq@aes.org<BR>
</A><A HREF="http://www.aes.org/">http://www.aes.org/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">AudioActive<A NAME="AudioActive"></A><BR>
</FONT><A HREF="http://www.audioactive.com/">http://www.audioactive.com/</A><BR>
</LI>

<LI><A NAME="AVT"></A><FONT COLOR="#FF0000">AVT Audio Video Technologies
GmbH</FONT>, Rathsbergstra&szlig;e 17 <BR>
D-90411 N&uuml;rnberg, Germany<BR>
fax: +49 911 5271 100<BR>
contact: Wolfgang Peters<BR>
email: <A HREF="mailto:WPeters@avt-nbg.de">WPeters@avt-nbg.de<BR>
</A><A HREF="http://www.avt-nbg.de">http://www.avt-nbg.de</A><BR>
</LI>

<LI><A NAME="Bertelsmann Publishing"></A><FONT COLOR="#FF0000">Bertelsmann
Publishing</FONT>, Neumarkter Stra&szlig;e 18<BR>
D-81664 M&uuml;nchen, Germany<BR>
fax: +49 89 43189 737<BR>
email: <A HREF="mailto:72662.3126@compuserve.com">72662.3126@compuserve.com<BR>
</A><A HREF="http://www.bep.de/">http://www.bep.de/</A><BR>
</LI>

<LI><A NAME="Broadcast Electronics"></A><FONT COLOR="#FF0000">Broadcast
Electronics Inc</FONT>, 4100 N 24th St.<BR>
Quincy, IL 62305-3606, USA<BR>
fax: +1 217 224 9607<BR>
email: <A HREF="mailto:bdcast@bdcast.com">bdcast@bdcast.com<BR>
</A><A HREF="http://www.marti.bdcast.com/">http://www.marti.bdcast.com/</A><BR>
</LI>

<LI><A NAME="CCS"></A><FONT COLOR="#FF0000">CCS Corporate Computer Systems
Europe GmbH</FONT>, Ludwigstr. 45<BR>
D-85396 Hallbergmoos, Germany<BR>
fax: +49 811 55 16 55<BR>
email: <A HREF="mailto:info@ccs-europe.com">info@ccs-europe.com<BR>
</A><FONT COLOR="#FF0000"><A HREF="http://www.ccs-europe.com/">http://www.ccs-europe.com/</A></FONT>
<BR>
</LI>

<LI><FONT COLOR="#FF0000">Cerberus Central Ltd<A NAME="Cerberus Sound &"></A></FONT>,
84 Marylebone High Street<BR>
London W1M 3DE, UK<BR>
fax: +44 171 637 3842<BR>
email: <A HREF="mailto:mail@cdj.co.uk">mail@cdj.co.uk<BR>
</A><FONT COLOR="#FF0000"><A HREF="http://www.cdj.co.uk/">http://www.cdj.co.uk/</A></FONT><BR>
</LI>

<LI><FONT COLOR="#FF0000">Deutsche Telekom AG<A NAME="Deutsche Telekom"></A></FONT>,
Technologiezentrum Darmstadt<BR>
Aussenstelle Berlin, Abteilung EK 21<BR>
Oranienburger Str. 70, D-10117 Berlin, Germany<BR>
fax: +49 30 2845 4146<BR>
</LI>

<LI><FONT COLOR="#FF0000">Dialog 4<A NAME="Dialog 4"></A></FONT> System
Engineering GmbH, Monreposstr. 55<BR>
D-71634 Ludwigsburg, Germany<BR>
fax: +49 7141 22667<BR>
email: <A HREF="mailto: info@dialog4.com">info@dialog4.com<BR>
</A><A HREF="http://www.dialog4.com/">http://www.dialog4.com/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">DIN Beuth<A NAME="DIN"></A></FONT> Verlag, Auslandsnormen<BR>
D-10772 Berlin, Germany<BR>
fax: +49 30 2601 1231<BR>
email: <A HREF="mailto:postmaster@din.de">postmaster@din.de</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Fraunhofer-IIS<A NAME="Fraunhofer-IIS"></A></FONT>,
Am Weichselgarten 3<BR>
D-91058 Erlangen, Germany<BR>
contact: Harald Popp<BR>
fax: +49 9131 776 399<BR>
email: <A HREF="mailto:layer3@iis.fhg.de">layer3@iis.fhg.de<BR>
</A><A HREF="http://www.iis.fhg.de/departs/amm/layer3/">http://www.iis.fhg.de/departs/amm/layer3/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">ISO Central Secretariat<A NAME="ISO Central"></A></FONT>,
Case postale 56,<BR>
CH-1211 Geneva 20, Switzerland<BR>
fax: +41 22 733 3430<BR>
email: <A HREF="mailto:central@isocs.iso.ch">central@isocs.iso.ch<BR>
</A><A HREF="http://www.iso.ch/">http://www.iso.ch/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">ITT Intermetall GmbH<A NAME="ITT Intermetall"></A></FONT>,
Hans-Bunte-Str. 19<BR>
D-79108 Freiburg, Germany<BR>
fax: +49 761 517 2395<BR>
email: <A HREF="mailto:info@itt-sc.de">info@itt-sc.de</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Macromedia<A NAME="Macromedia"></A></FONT> Inc.,
600 Townsend<BR>
San Francisco, CA 94103, USA<BR>
fax: +1 415 626 0554<BR>
<A HREF="http://www.macromedia.com/">http://www.macromedia.com/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Meister Electronic<A NAME="Meister"></A></FONT>
GmbH, K&ouml;lner Str. 37<BR>
D-51149 K&ouml;ln, Germany<BR>
fax: +49 2203 1701 30<BR>
</LI>

<LI><A NAME="Microsoft"></A><FONT COLOR="#FF0000">Microsoft Inc.</FONT>,
One Microsoft Way<BR>
Redmond, WA 98052 - 6399<BR>
<A HREF="http://www.microsoft.com/corpinfo/PRESS/1996/Dec96/ntshw2pr.htm">http://www.microsoft.com/corpinfo/PRESS/1996/Dec96/ntshw2pr.htm</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">MODE<A NAME="MODE"></A><BR>
</FONT><A HREF="http://www.mode.net/">http://www.mode.net/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">MPEG<A NAME="MPEG"></A><BR>
</FONT><A HREF="http://www.cselt.stet.it/mpeg/">http://www.cselt.stet.it/mpeg/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">NSM<A NAME="NSM"></A></FONT>, Im Tiergarten 20
- 30<BR>
D-55411 Bingen am Rhein, Germany<BR>
contact: Mr. Ballhorn<BR>
fax: +49 6721 407 519<BR>
<A HREF="http://www.nsm.de/nsm_it/">http://www.nsm.de/nsm_it/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Opticom<A NAME="Opticom"></A></FONT>, Am Weichselgarten
7<BR>
D-91058 Erlangen, Germany<BR>
fax: +49 9131 691325<BR>
email: <A HREF="mailto:info@opticom.de">info@opticom.de<BR>
</A><A HREF="http://www.opticom.de">http://www.opticom.de</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Proton Data<A NAME="Proton"></A></FONT>, Marrensdamm
12 b<BR>
D-24944 Flensburg, Germany<BR>
fax: +49 461 3816948<BR>
email: <A HREF="mailto:proton.data@t-online.de">proton.data@t-online.de</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Siemens AG<A NAME="Siemens"></A></FONT> Halbleiter,
P.O. Box 80 17 09<BR>
D-81617 Muenchen, Germany<BR>
fax: +49 89 4144 4697<BR>
email: <A HREF="mailto:Christine.Born@hl.siemens.de">Christine.Born@hl.siemens.de</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Sygna A/S<A NAME="Sygna"></A></FONT>, P.O.Box
191<BR>
N-5801 Sogndal, Norway<BR>
fax: +47 5767 6190<BR>
email: <A HREF="mailto:bach@sygna.no">bach@sygna.no<BR>
</A><A HREF="http://www.mode.net/partners/sygna.html">http://www.mode.net/partners/sygna.html</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">Telos Systems<A NAME="Telos"></A></FONT>, 2101
Superior Avenue<BR>
Cleveland, OH 44114, USA<BR>
fax: +1 216 241 4103<BR>
email: <A HREF="mailto:info@zephyr.com">info@zephyr.com<BR>
</A><A HREF="http://www.zephyr.com/">http://www.zephyr.com/</A><BR>
</LI>

<LI><FONT COLOR="#FF0000">WorldSpace<A NAME="WorldSpace"></A></FONT> 11
Dupont Circle, N.W., 9th Floor<BR>
Washington, DC 20036, USA<BR>
fax: +1 202 884 7900<BR>
email: <A HREF="mailto:gene@mail.worldspace.com">gene@mail.worldspace.com<BR>
</A><A HREF="http://www.worldspace.com">http://www.worldspace.com</A><BR>
</LI>
</UL>

<P><A NAME="aboutFraunhofer"></A></P>

<H3>About us - or: What is going on at our Fraunhofer Institute?</H3>

<UL>
<LI><B>Q:</B> Who is or was Fraunhofer? And what does your institute do?</LI>

<LI><B>A:</B> As researcher, inventor and entrepreneur, Joseph von Fraunhofer
(1787 - 1826) won high acclaim for his scientific and commercial achievements.
When the Fraunhofer-Gesellschaft was founded in Munich in 1949, his name
was chosen as the &quot;guiding light&quot; of the association.<BR>
Today, the Fraunhofer-Gesellschaft employs a staff of around 8.000 persons
and operates 46 research institutes in Germany and one resource centre
in the United States, with a research volume of around 1 billion DM. 70
% of its income is obtained by contract research for public authorities
as well as for industrial clients.<BR>
The <A HREF="#Fraunhofer-IIS">Fraunhofer Institut Integrierte Schaltungen
(IIS)</A> was founded in Erlangen in 1985. It is headed by Prof. Dr.Ing.
Dieter Seitzer and Dr. Heinz Gerh&auml;user. Today, a staff of 160 persons
works on projects in the field of information electronics, developing microelectronic
solutions at chip-, board- and system level. In its department &quot;Audio
&amp; Multimedia&quot;, headed by Dr. Karlheinz Brandenburg, around 40
engineers concentrate on the development and real-time implementation of
signal processing algorithms in the field of audiovisual communications.</LI>

<LI><B>Q:</B> So you focus on &quot;contract research&quot;. What does
this mean exactly?</LI>

<LI><B>A:</B> Simply put: we have to earn our money. In case of our institute,
we are funded by public money for less than 20 % - the rest of our budget
has to be financed by research &amp; development projects. You may call
this work &quot;applied research&quot;, i.e. in contrast to a university,
we focus on real-world applications, and in contrast to an engineeering
office, we focus on state-of-the-art applications that bear some technical
risks (and therefore need some further research). With other words, we
are always trying to stay at the leading edge of technology. Take audio
coding as an example. We started in 1987, in a close cooperation with the
University of Erlangen, to develop an advanced audio coding scheme for
future broadcast services (Eureka 147, DAB radio). In 1991, our algorithm
(&quot;Layer-3&quot;) became the most powerful member of audio coding schemes
of the international ISO-MPEG standard. Since then, we work on industrial
applications as well as on further audiovisual research projects, e.g.
MPEG-4 scalable audio coding, MPEG-2 NBC audio coding, or MPEG-4 audiovisual
terminals.</LI>

<LI><B>Q:</B> I am interested in your Layer-3 technology. What can you
do for me?</LI>

<LI><B>A:</B> Well - basically, you may use our knowhow as a cost-effective
road to your application. We expect a certain renumeration for our development
work that we carried out in advance. We call this a &quot;know-how share&quot;.
In addition, you may want us to work on some special R&amp;D tasks for
you, so you have to pay for this extra effort, too. This is the principle.
In case of Layer-3, we have advanced simulation sources (C) for encoder
and decoder as well as DSP source and assembler code for decoders on DSP
5600x (Motorola), DSP 32C (AT&amp;T), TMS320C30 (TI), and MAS 3503 C (ITT),
and for encoders on a hybrid solution (32C + 5600x) as well as on a pure
5600x (2 DSPs) solution. We expect a single 5630x Layer-3 encoder until
the end of 1996. Depending on your specific technical needs, the knowhow-share
sum may range from several 10.000.- $ to more than 100.000.- $. In any
case, we expect significantly more money for the encoder, as this is the
part that is responsible for the performance of a Layer-3 system (and so
it is the part where most of our knowhow is concentrated). So you know
the framework. We are open for any discussion and any new ideas - so feel
free to contact us.<BR>
Oh - by the way you are interested in some rough ASIC estimations for a
Layer-3 stereo decoder. You will need a computation power of around 12
MIPs, a Data ROM of around 2.5 Kwords, a Data RAM of around 4.5 Kwords,
and a Programm ROM of around 2 to 4 Kwords (depending on the instruction
set). The word length should be 20 bit, at least.</LI>

<LI><B>Q:</B> What else do I have to keep in mind, if I want to use Layer-3
in my application? Are there patents involved? How may I address this topic?</LI>

<LI><B>A:</B> You are right. For all MPEG audio coding schemes, patent
rights exist. Using MPEG audio, you use these rights - and in order not
to violate them, you should establish a license contract with the patent
holders. This is true for all MPEG audio Layers. In case of Layer-3, there
are currently two entities that may give licenses, Thomson Multimedia,
Paris, and Fraunhofer-IIS, Erlangen. Due to an agreement between them,
Thomson is in charge of consumer-oriented applications, and Fraunhofer-IIS
is in charge of professional-oriented applications. License contracts typically
address only the patent issue. Due to the rules of ISO-MPEG, the license
has to be given non-exclusively on fair and reasonable terms. Of course,
details depend on the specific business model.<BR>
So there are four steps for a Layer-3 application. First, defining the
technical requirements and finding the most cost-effective road to meet
them. Second, following that road to the final solution. Third, defining
the license rules depending on the business model. Four, signing the resulting
license contract.</LI>
</UL>

<P>Fraunhofer Institut Integrierte Schaltungen IIS, Am Weichselgarten 3,
D-91058 Erlangen, Germany, Fax: +49-9131-776-399</P>

<P>FAQ, 19. December 1996, by Harald Popp</P>

</BODY>
</HTML>
