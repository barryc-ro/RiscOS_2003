/******	IRQ.c **************************************************************

Project:	STB-400
Component:	MPEGDriver
This file:	Interrupt handling

Copyright 1999 Pace Micro Technology plc. All rights reserved.

This material is the confidential trade secret and proprietary information
of Pace Micro Technology plc. It may not be reproduced, used, sold, or
transferred to any third party without the prior written consent of
Pace Micro Technology plc.

History:
Date		Who	Change
----------------------------------------------------------------------------
06/10/1999	BJGA	Created
07/10/1999	BJGA	Implemented IRQ_EnableCommonIRQs, IRQ_DisableCommonIRQs
11/10/1999	BJGA	Changed to use nINT4; implemented IRQ dispatch
20/10/1999	BJGA	Implemented video header parser coroutine
26/10/1999	BJGA	Uses new STB-400 interrupt allocation symbols;
			items renamed as per the reorganisation of Types.h;
			picture list implemented (added NewPictureDecode());
			reconstruction frame pointers set up for P- and B-pictures;
			sequence and GOP header items persist when necessary
09/11/1999	BJGA	Video decode now works as far as the issuing of SWI
			MPEGControl_Play at the end of video prefill. Too many
			details to list...
11/11/1999	BJGA	Prefill picture skips now use PID rather than VSync to
			trigger restart - this is possible with type 3 skips, and
			increases the commonality with prefill picture decodes;
			removal of frame struct in prefill skips moved from BBF
			to PID - this allows testing of picture type in PID
			independently of any state variable; delayed issuing of
			MPEGControl_Play until the headers of the first
			non-prefill picture have been decoded; moved slice header
			actions into separate function
12/11/1999	BJGA	Simplified video prefill state machine; added support
			for field pictures (including the consequences of the
			necessary changes to Types.h)
17/11/199	BJGA	Implemented normal-play moving video: this involved
			increasing the number of frame structs to 5 and
			dyncmically allocating frame buffers to them,
			implememting a frame display list, and adding to the
			functionality of INT_PID, INT_VS and INT_PSD;
			worked around a 3520 bug that required VID_FFP to be
			written before VID_BFP; separated WriteDecodeInstruction
			and RemoveFrameFromList into separate functions
23/11/1999	BJGA	Redesigned state machine for greater commonality between
			video prefill and normal play, also introducing stalling
			during video play to prevent buffer underrun; introduced
			error, skip/repeat, stall, underrun counting; simple
			horizontal scaling calculation added; field display
			control support started
25/11/1999	BJGA	Field display control implemented; fixed bug in display
			of certain clips by changing frame buffer allocation
			algorithm; attempt to support field-picture video
			(thwarted by a bug in the 3520)
30/11/1999	BJGA	Now decodes field pictures 1 field ahead of display
			(frame pictures retain 1 frame delay to avoid timing
			issues when downscaling) - works around 3520 bug.
			Has a surprisingly large number of side-effects (eg
			start-code hit now has to be re-enabled on PSD interrupt)
01/12/1999	BJGA	Can now handle transitions between frame pictures and
			field pictures (either way) in the same clip, by either
			inserting a field delay into decoding, or by squeezing
			a frame decode into one field interval; also has more
			robust header parsing, to deal with stream corruption
			within a single set of headers
02/12/1999	BJGA	Only starts a new frame struct if the previous headers
			have finished parsing (more resilient against bitstream
			errors); resets pipeline after a while, if it fails to
			return to idle state, or if no slice header is parsed
09/12/1999	BJGA	Different values of XDO/XDS needed for PAL and NTSC
25/01/2000	BJGA	Unused f_codes initialised to 0xF instead of 0xFF;
			inverted sense of VID_HDS.QMI to suit hardware
			rather than data sheet - fixes video blocking bug;
			implemented audio start/stop; enabled VSyncs between
			waiting_for_play_command and waiting_for_presentation_start;
			adjusted VID_XDO and VID_XDS as per new hardware timing scheme
31/01/2000	BJGA	Split video and audio IRQ handlers; implemented audio header
			parsing, in order to set sample frequencies correctly;
			adjusted VID_XDO and VID_XDS back again

***************************************************************************/

/************/
/* Includes */
/************/

#include "kernel.h"
#include "swis.h"

#include "Global/DevNos.h"
#include "Global/RISCOS.h"
#include "Global/SWIs.h"
#include "Global/IO/GenericIO.h"
#include "Global/IO/IOMD.h"
#include "DebugLib/DebugLib.h"
#include "MPEG/MPEG2cCard.h"
#include "MPEG/MPEGCtrl.h"

#include "Clk.h"
#include "Co.h"
#include "Defs.h"
#include "IRQ.h"
#include "ModHdr.h"
#include "Module.h"
#include "Registers.h"
#include "STi3520L.h"
#include "Types.h"

/*****************/
/* Private types */
/*****************/

/**********************/
/* Private prototypes */
/**********************/

static void static_INT_SCH (unsigned int *video_ints);
static void static_INT_BBF (unsigned int *video_ints);
static void static_INT_VS (bool field, unsigned int *video_ints);
static void static_INT_PSD (unsigned int *video_ints);
static void static_INT_PID (unsigned int *video_ints);
static void static_INT_HFF (unsigned int *video_ints);
static void static_INT_BBE (void);
static void static_INT_PER (void);
static void static_INT_SER (void);
static void static_INT_PDE (void);
static void static_INT_VHR (void);
static void static_INT_SFC (void);
static void static_ProcessVideoHdr (void *argument);
static void static_NewPictureDecode (void);
static void static_ProcessVideoSequenceHdr (void);
static void static_ProcessVideoSequenceExt (void);
static void static_ProcessVideoSequenceDisplayExt (void);
static void static_ProcessVideoGOPHdr (void);
static void static_ProcessVideoPictureHdr (void);
static void static_ProcessVideoPictureCodingExt (void);
static void static_ProcessVideoQuantMatrixExt (void);
static void static_ProcessVideoPictureDisplayExt (void);
static void static_ProcessVideoUserData (void);
static void static_ProcessVideoDTG1UserData (void);
static void static_ProcessVideoSliceHdr (void);
static unsigned int static_GetVideoHdrBits (unsigned char bits);
static void static_PerhapsWriteNewInstruction (void);
static void static_SetUpDisplayForNewAU (void);
static void static_WriteDecodeInstruction (bool FIS);
static void static_WriteSkipInstruction (bool FIS);
static void static_RemoveFrameFromList (frame_t *removed_frame, bool D_list);
static void static_SetNextDisplayField (bool top_field);

/********************/
/* Public variables */
/********************/

/*********************/
/* Private variables */
/*********************/

static int CommonIRQsClaimedCount = 0;
static int VideoPrefillSize = -1; /* in units of 256 bytes */

/*********************/
/* Private constants */
/*********************/

#define PICTURE_START_CODE      0x00
#define SLICE_START_CODE        0x01
#define USER_DATA_START_CODE    0xB2
#define SEQUENCE_HEADER_CODE    0xB3
#define SEQUENCE_ERROR_CODE     0xB4
#define EXTENSION_START_CODE    0xB5
#define SEQUENCE_END_CODE       0xB7
#define GROUP_START_CODE        0xB8

#define SEQUENCE_EXTENSION                      0x1
#define SEQUENCE_DISPLAY_EXTENSION              0x2
#define QUANT_MATRIX_EXTENSION                  0x3
#define COPYRIGHT_EXTENSION                     0x4
#define SEQUENCE_SCALABLE_EXTENSION             0x5
#define PICTURE_DISPLAY_EXTENSION               0x7
#define PICTURE_CODING_EXTENSION                0x8
#define PICTURE_SPATIAL_SCALABLE_EXTENSION      0x9
#define PICTURE_TEMPORAL_SCALABLE_EXTENSION     0xA

#define I_PICTURE       0x1
#define P_PICTURE       0x2
#define B_PICTURE       0x3

#define TOP_FIELD_PICTURE       0x1
#define BOTTOM_FIELD_PICTURE    0x2
#define FRAME_PICTURE           0x3

static const unsigned int frame_rate_table[16] =
{
  0, 23976, 24000, 25000, 29970, 30000, 50000, 59940, 60000, 0, 0, 0, 0, 0, 0, 0
};

static const unsigned int mpeg_1_pixel_aspect_ratio_table[16] =
{
  0,
  (unsigned int) (0x10000 / 1.0000),
  (unsigned int) (0x10000 / 0.6735),
  (unsigned int) (0x10000 / 0.7031),
  (unsigned int) (0x10000 / 0.7615),
  (unsigned int) (0x10000 / 0.8055),
  (unsigned int) (0x10000 / 0.8437),
  (unsigned int) (0x10000 / 0.8935),
  (unsigned int) (0x10000 / 0.9157),
  (unsigned int) (0x10000 / 0.9815),
  (unsigned int) (0x10000 / 1.0255),
  (unsigned int) (0x10000 / 1.0695),
  (unsigned int) (0x10000 / 1.0950),
  (unsigned int) (0x10000 / 1.1575),
  (unsigned int) (0x10000 / 1.2015),
  0
};

static const unsigned char default_intra_quantizer_matrix[64] =
{
  0x08, 0x10, 0x10, 0x13, 0x10, 0x13, 0x16, 0x16,
  0x16, 0x16, 0x16, 0x16, 0x1A, 0x18, 0x1A, 0x1B,
  0x1B, 0x1B, 0x1A, 0x1A, 0x1A, 0x1A, 0x1B, 0x1B,
  0x1B, 0x1D, 0x1D, 0x1D, 0x22, 0x22, 0x22, 0x1D,
  0x1D, 0x1D, 0x1B, 0x1B, 0x1D, 0x1D, 0x20, 0x20,
  0x22, 0x22, 0x25, 0x26, 0x25, 0x23, 0x23, 0x22,
  0x23, 0x26, 0x26, 0x28, 0x28, 0x28, 0x30, 0x30,
  0x2E, 0x2E, 0x38, 0x38, 0x3A, 0x45, 0x45, 0x53
};

/********************/
/* Public functions */
/********************/

/******	IRQ_HandleVideoIRQ() ***********************************************

Purpose:	Video IRQ entry point

***************************************************************************/

void IRQ_HandleVideoIRQ (void)
{
  static unsigned int video_ints; /* must be static because the coroutine only takes a copy of the address on entry */
  do
  {
    video_ints = VID_ITS;
//    dprintf (("IRQ", "IRQ_HandleVideoIRQ: VID_ITS before masking = %06X\n", video_ints));
    video_ints  &= VID_ITM;
    
    if (video_ints != 0)  /* quick reject if no video interrupts */
    {
      /* First deal with interrupt handlers that may need to update          */
      /* |video_ints|. These must clear their own bit in |video_ints| before */
      /* returning, unless they wish to be re-called immediately. Only one   */
      /* interrupt handler should be called for each iteration of the loop.  */
      while ((video_ints & (VIDEO_INT_SCH | VIDEO_INT_BBF | VIDEO_INT_VSB | VIDEO_INT_VST | VIDEO_INT_PSD | VIDEO_INT_PID | VIDEO_INT_HFF)) != 0)
      {
        if (video_ints & VIDEO_INT_SCH) static_INT_SCH (&video_ints);
        else if (video_ints & VIDEO_INT_BBF) static_INT_BBF (&video_ints);
        else if (video_ints & VIDEO_INT_VSB) static_INT_VS (false, &video_ints);
        else if (video_ints & VIDEO_INT_VST) static_INT_VS (true, &video_ints);
        else if (video_ints & VIDEO_INT_PSD) static_INT_PSD (&video_ints);
        else if (video_ints & VIDEO_INT_PID) static_INT_PID (&video_ints);
        else if (video_ints & VIDEO_INT_HFF) static_INT_HFF (&video_ints);
//        dprintf (("IRQ", "IRQ_HandleVideoIRQ: video_ints = %06X\n", video_ints));
      }
      /* Now deal with the other interrupts. */
/*    if (video_ints & VIDEO_INT_BFF) static_INT_BFF ();*/
/*    if (video_ints & VIDEO_INT_HFE) static_INT_HFE ();*/
      if (video_ints & VIDEO_INT_BBE) static_INT_BBE ();
      if (video_ints & VIDEO_INT_PER) static_INT_PER ();
/*    if (video_ints & VIDEO_INT_WFE) static_INT_WFE ();*/
/*    if (video_ints & VIDEO_INT_RFF) static_INT_RFF ();*/
/*    if (video_ints & VIDEO_INT_BMI) static_INT_BMI ();*/
      if (video_ints & VIDEO_INT_SER) static_INT_SER ();
      if (video_ints & VIDEO_INT_PDE) static_INT_PDE ();
/*    if (video_ints & VIDEO_INT_ABE) static_INT_ABE ();*/
/*    if (video_ints & VIDEO_INT_WFN) static_INT_WFN ();*/
/*    if (video_ints & VIDEO_INT_RFN) static_INT_RFN ();*/
/*    if (video_ints & VIDEO_INT_ABF) static_INT_ABF ();*/
/*    if (video_ints & VIDEO_INT_SCR) static_INT_SCR ();*/
/*    if (video_ints & VIDEO_INT_ERR) static_INT_ERR ();*/
    }
  }
  /* Only exit when we're satisfied that we're not about to raise another IRQ. */
  /* This also allows for the clearing of any interrupts that may have been */
  /* triggered, but already serviced within an interrupt handler (having been */
  /* detected by using reads from VID_STA rather than VID_ITS). */
  while (video_ints != 0);
}

/******	IRQ_HandleAudioIRQ() ***********************************************

Purpose:	Audio IRQ entry point

***************************************************************************/

void IRQ_HandleAudioIRQ (void)
{
  static unsigned int audio_ints;
  do
  {
    audio_ints = AUD_ITR & AUD_ITM;
    dprintf (("IRQ", "IRQ_HandleAudioIRQ: AUD_ITR = %04X\n", audio_ints));
    
    if (audio_ints != 0)  /* quick reject if no audio interrupts */
    {
/*    if (audio_ints & AUDIO_INT_CSS) static_INT_CSS ();*/
      if (audio_ints & AUDIO_INT_VHR) static_INT_VHR ();
/*    if (audio_ints & AUDIO_INT_VPR) static_INT_VPR ();*/
/*    if (audio_ints & AUDIO_INT_CRC) static_INT_CRC ();*/
/*    if (audio_ints & AUDIO_INT_ADF) static_INT_ADF ();*/
/*    if (audio_ints & AUDIO_INT_POU) static_INT_POU ();*/
      if (audio_ints & AUDIO_INT_SFC) /*static_INT_SFC ()*/;
/*    if (audio_ints & AUDIO_INT_DCH) static_INT_DCH ();*/
/*    if (audio_ints & AUDIO_INT_IFT) static_INT_IFT ();*/
/*    if (audio_ints & AUDIO_INT_IFF) static_INT_IFF ();*/
/*    if (audio_ints & AUDIO_INT_FNP) static_INT_FNP ();*/
    }
  }
  /* Only exit when we're satisfied that we're not about to raise another IRQ. */
  while (audio_ints != 0);
}

/******	IRQ_EnableCommonIRQs() *********************************************

Purpose:	Performs actions common to video and audio IRQ claiming
Out:		Pointer to error block
Notes:		Usage is counted so that it may be called more than once

***************************************************************************/

_kernel_oserror *IRQ_EnableCommonIRQs (void)
{
  _kernel_oserror *e = NULL;
  if (CommonIRQsClaimedCount == 0)
  {
    /* Get on TickerV */
    e = _swix (OS_Claim, _INR(0,2), TickerV, tickerv_handler, Module_PrivateWord);
  }
  CommonIRQsClaimedCount++;
  if (e)
  {
    /* If something went wrong, decrement the count again, and release interrupts */
    IRQ_DisableCommonIRQs ();
  }
  return e;
}

/******	IRQ_DisableCommonIRQs() ********************************************

Purpose:	Decrements common-IRQ usage counter, and releases common
		interrupts when it reaches zero

***************************************************************************/

void IRQ_DisableCommonIRQs (void)
{
  CommonIRQsClaimedCount--;
  if (CommonIRQsClaimedCount <= 0)
  {
    CommonIRQsClaimedCount = 0;
    /* Get off TickerV */
    _swix (OS_Release, _INR(0,2), TickerV, tickerv_handler, Module_PrivateWord);
  }
}

/******	IRQ_EnableVideoPrefillIRQs() ***************************************

Purpose:	Enables interrupts needed in video prefilling
Out:		Pointer to error block

***************************************************************************/

_kernel_oserror *IRQ_EnableVideoPrefillIRQs (void)
{
  _kernel_oserror *e = NULL;
  bool irqs_were_enabled = !_kernel_irqs_disabled ();
  int discard;
  dprintf (("IRQ", "EnableVideoPrefillIRQs\n"));
  
  /* Mask off all interrupts inside 3520 */
  WRITE_VID_ITM(0);
  
  /* Clear all the interrupt bits in case any erroneous interrupts are generated as soon as we enable them */
  READ_VID_ITS(discard);
  
  /* Claim 3520 video IRQs */
  e = _swix (OS_ClaimDeviceVector, _INR(0,4), IOMDr_MPEGVideo_DevNo /* aka 12, aka IRQRQB bit 4, aka nINT4 */,
    sti3520l_video_irq_handler, Module_PrivateWord);
  
  if (!e)
  {
    /* Enable nINT4 in IOMD */
    if (irqs_were_enabled) _kernel_irqs_off ();
    * (volatile unsigned char *) (IOC + IOCIRQMSKB) |= IOMDr_MPEGVideo_IRQ_bit;
    if (irqs_were_enabled) _kernel_irqs_on ();
    
    /* Initialise things local to this source file */
    Stream.video.header_parser = Co_Create (&static_ProcessVideoHdr); /* initialise coroutine */
    VideoPrefillSize = -1; /* special value to flag that it hasn't been calculated yet */
    
    /* Enable appropriate interrupts (BBE is deferred until we've parsed the first headers, PSD until we enable decoding) */
    WRITE_VID_ITM(VID_ITM | VIDEO_INT_SCH | VIDEO_INT_BBF | VIDEO_INT_PER | VIDEO_INT_PID | VIDEO_INT_SER | VIDEO_INT_PDE);
    VID_CTL &= ~VID_CTL_EDC;              /* don't start decoding the first frame until we've reached buffer threshold */
    VID_TIS = VID_TIS_FIS | VID_TIS_EXE;  /* kick off the sequence header search */
  }
  
  return e;
}

/******	IRQ_EnableVideoIRQs() **********************************************

Purpose:	Enables interrupts needed in video play mode
Out:		Pointer to error block

***************************************************************************/

_kernel_oserror *IRQ_EnableVideoIRQs (void)
{
  _kernel_oserror *e = NULL;
  
  /* Update state machine */
  Stream.video.prefill_state = ps_waiting_for_presentation_start;
  dprintf (("IRQ", "EnableVideoIRQs: video.prefill_state = waiting_for_presentation_start\n"));
  
  return e;
}

/******	IRQ_DisableVideoIRQs() *********************************************

Purpose:	Disables video interrupts

***************************************************************************/

void IRQ_DisableVideoIRQs (void)
{
  dprintf (("IRQ", "DisableVideoIRQs\n"));
  WRITE_VID_ITM(0);  /* mask off all video interrupts */
  VID_CTL &= ~VID_CTL_EDC;  /* stop video decoding */
  
  Co_Destroy (&Stream.video.header_parser); /* finalise coroutine */
  
  /* Release 3520 video IRQs */
  _swix (OS_ReleaseDeviceVector, _INR(0,4), IOMDr_MPEGVideo_DevNo /* aka 12, aka IRQRQB bit 4, aka nINT4 */,
    sti3520l_video_irq_handler, Module_PrivateWord);
}

/******	IRQ_EnableAudioPrefillIRQs() ***************************************

Purpose:	Enables interrupts needed in audio prefilling
Out:		Pointer to error block

***************************************************************************/

_kernel_oserror *IRQ_EnableAudioPrefillIRQs (void)
{
  _kernel_oserror *e = NULL;
  bool irqs_were_enabled = !_kernel_irqs_disabled ();
  int discard;
  clk discard_clk;
  dprintf (("IRQ", "EnableAudioPrefillIRQs\n"));
  
  /* Mask off all interrupts inside 3520 */
  WRITE_AUD_ITM(0);
  WRITE_AUD_IMS(0);
  
  /* Clear all the interrupt bits in case any erroneous interrupts are generated as soon as we enable them */
  READ_AUD_ITR(discard);
  READ_AUD_ANC(discard);
  READ_AUD_PTS(discard_clk);
  READ_AUD_HDR(discard);
  READ_AUD_SYS(discard);
  READ_AUD_ITS(discard);
  
  /* Claim 3520 audio IRQs */
  e = _swix (OS_ClaimDeviceVector, _INR(0,4), IOMDr_MPEGAudio_DevNo /* aka 10, aka IRQRQB bit 2, aka nINT6 */,
    sti3520l_audio_irq_handler, Module_PrivateWord);
  
  if (!e)
  {
    /* Enable nINT6 in IOMD */
    if (irqs_were_enabled) _kernel_irqs_off ();
    * (volatile unsigned char *) (IOC + IOCIRQMSKB) |= IOMDr_MPEGAudio_IRQ_bit;
    if (irqs_were_enabled) _kernel_irqs_on ();
    
    /* Enable appropriate interrupts */
//    AUD_ITM_8 |= AUDIO_INT_SFC>>8;
    AUD_ITM_0 |= AUDIO_INT_VHR>>0;
    
    /* Assume a 44.1 kHz sample rate unless told otherwise */
    STi3520L_SetPCMClock (sr_44k1, false, false);
  }
  
  return e;
}

/******	IRQ_EnableAudioIRQs() **********************************************

Purpose:	Enables interrupts needed in audio play mode
Out:		Pointer to error block

***************************************************************************/

_kernel_oserror *IRQ_EnableAudioIRQs (void)
{
  _kernel_oserror *e = NULL;
  int retry_count = 200;
  int dummy_counter;
  
  /* Update state machine - audio starts immediately */
  Stream.audio.state = stream_open;
  dprintf (("IRQ", "EnableAudioIRQs: audio.state = stream_open\n"));
  
  AUD_RST = 1;
  /* Ensure the restart bit clears itself - if it doesn't then try writing the register again */
  while ((retry_count-- > 0) && ((AUD_RST & 1) == 0))
  {
    for (dummy_counter = 0; dummy_counter < 100; dummy_counter++); /* wait a while */
  }
  if (retry_count == 0) dprintf (("IRQ", "EnableAudioIRQs: audio restart failed\n"));
  
  AUD_MUT = 0; /* unmute */
  AUD_PLY = 1; /* start decoding */
  return e;
}

/******	IRQ_DisableAudioIRQs() *********************************************

Purpose:	Disables audio interrupts

***************************************************************************/

void IRQ_DisableAudioIRQs (void)
{
  dprintf (("IRQ", "DisableAudioIRQs\n"));
  
  WRITE_AUD_ITM(0);  /* mask off all audio interrupts */
  WRITE_AUD_IMS(0);
  
  AUD_MUT = 1; /* mute */
  AUD_PLY = 0; /* stop decoding */
  
  /* Release 3520 audio IRQs */
  _swix (OS_ReleaseDeviceVector, _INR(0,4), IOMDr_MPEGAudio_DevNo /* aka 10, aka IRQRQB bit 2, aka nINT6 */,
    sti3520l_audio_irq_handler, Module_PrivateWord);
}

/******	IRQ_AudioFast() ****************************************************

Purpose:	Flags that the next time an audio frame decode starts, it
		must be played fast
Notes:		It is the caller's responsibility to ensure that audio
		fasts or slows are not requested so frequently that they
		cause hysteresis

***************************************************************************/

void IRQ_AudioFast (void)
{
  if (Stream.audio_fast_slow_state == afss_normal_speed)
  {
    Stream.audio_fast_slow_state = afss_next_frame_fast;
  }
}

/******	IRQ_AudioSlow() ****************************************************

Purpose:	Flags that the next time an audio frame decode starts, it
		must be played slow
Notes:		It is the caller's responsibility to ensure that audio
		fasts or slows are not requested so frequently that they
		cause hysteresis

***************************************************************************/

void IRQ_AudioSlow (void)
{
  if (Stream.audio_fast_slow_state == afss_normal_speed)
  {
    Stream.audio_fast_slow_state = afss_next_frame_slow;
  }
}


/*********************/
/* Private functions */
/*********************/

/******	static_INT_SCH() ***************************************************

Purpose:	Handles Start Code Hit video IRQ
In:		Pointer to IRQ_Handler()'s |video_ints| variable
Notes:		This is enabled whenever we launch a task instruction with
		the EXE bit set, and is disabled as soon as it is triggered.
		During parsing of headers, VID_STA.SCH is repeatedly toggled,
		but we don't want this to cause an interrupt as soon as header
		parsing is complete, so VID_ITS is re-read at the end of
		header parsing to clear the SCH bit.

***************************************************************************/

static void static_INT_SCH (unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_SCH\n"));
  VID_ITM_0 &= ~(VIDEO_INT_SCH>>0); /* disable start-code hit IRQ */
  /* Enter coroutine */
  Co_SwitchTo (&Stream.video.header_parser, video_ints);
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~VIDEO_INT_SCH;
}

/******	static_INT_BBF() ***************************************************

Purpose:	Handles video BitBuffer Full video IRQ
Notes:		This is active throughout prefill and normal play. It is
		primarily used to signal that one of the conditions for
		decoding to continue has become true.

***************************************************************************/

static void static_INT_BBF (unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_BBF\n"));
  static_PerhapsWriteNewInstruction ();
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~VIDEO_INT_BBF;
}

/******	static_INT_VS() ****************************************************

Purpose:	Handles VSync Top and VSync Bottom video IRQs
In:		Top-field (not-bottom-field) flag
Notes:		This is enabled when video goes into normal play mode. It is used
		for updating display parameters, and for pacing the decode process
		during normal play so it stays in step with the display process.

***************************************************************************/

static void static_INT_VS (bool field, unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_VS%c\n", field ? 'T' : 'B'));
  if (Stream.video.state == stream_prefilling)
  {
    if (Stream.video.prefill_state == ps_waiting_for_presentation_start)
    {
      /* If the *next* VSync is the correct interlace phase for our */
      /* first frame, then kickstart the video play state machine   */
      if (Stream.display_frames->top_field_first != field)
      {
        /* Update state machine */
        Stream.fields_till_next_AU = 1;
        Stream.vid_flags.first_frame_displayed = false;
        Stream.video.state = stream_open;
        dprintf (("IRQ", "INT_VS: video.state = stream_open\n"));
        /* Decode the first B-frame */
        static_PerhapsWriteNewInstruction ();
      }
    }
  }
  else if (Stream.video.state == stream_open || Stream.video.state == stream_closing)
  {
    /* Update state machine again once we've started displaying the first frame */
    if (Stream.vid_flags.first_frame_displayed == false) Stream.vid_flags.first_frame_displayed = true;
    
    /* Now more generic stuff */
    Stream.fields_into_this_PU ++;
    Stream.fields_till_next_AU --;
    
    if (Stream.current_picture_structure == ps_frame_picture || Stream.current_picture_structure == ps_frame_picture_extension)
    {
      if (Stream.display_frames->progressive_frame == true)
      {
        /* For progressive frames, we turn on automatic field selection (top-bottom alternating regardless) */
        VID_DCF_0 &= ~VID_DCF_USR; /* note this bit isn't latched, so has immediate effect */
      }
      else
      {
        /* For non-progressive frames, we turn on user field selection */
        VID_DCF_0 |= VID_DCF_USR; /* note this bit isn't latched, so has immediate effect */
        /* In trick play, slow-mo and pause, we just leave the first field displaying throughout */
        /* Otherwise, the second field is displayed on the second (ie next-latched) and subsequent fields (ie for repeat-frames and stalls) */
        /* (When a frame decode follows a field decode, so the frame decode doesn't start until the second VSync, this is taken care of during writing of the task instruction) */
        if (Stream.video.speed_indicator == 1 && Stream.rs_flags.trick_play_mode == false && Stream.fields_into_this_PU == 0)
        {
          static_SetNextDisplayField (!Stream.display_frames->top_field_first); /* here, the relevant bits *are* latched next VSync */
        }
      }
    }
    else
    {
      /* Whilst decoding field pictures, always enable user field selection, but only change the choice of field when writing the task instruction */
      /* This enables us to avoid displaying any part of a frame buffer that the 3520 is currently using as scratch workspace! */
      VID_DCF_0 |= VID_DCF_USR; /* note this bit isn't latched, so has immediate effect */
    }
    
    dprintf (("IRQ", "INT_VS: fields_till_next_AU = %d\n", Stream.fields_till_next_AU));
    if (Stream.fields_till_next_AU == 0)
    {
      if (Stream.vid_flags.final_instruction_has_been_written_during_this_AU == false)
      {
        /* Oh dear, we've stalled. Try again in two fields' time */
        Stream.video.since_open.stalls += 1;
        Stream.video.since_reset.stalls += 1;
        Stream.fields_till_next_AU = 2;
        if (Stream.current_picture_structure == ps_second_field_picture) /* ie first decode within the PU */ Stream.field_to_trigger_second_decode_on += 2;
        if (Stream.video.state == stream_closing) Stream.vid_flags.stalled_while_closing = true;
        if ((VID_VBL & 0x3FFF) >= (VID_VBT & 0x3FFF))
        {
          /* The pipeline has stalled, but there's plenty of data in the buffer. */
          /* If this happens too many times, we assume the chip has entered a locked state, and apply a pipeline reset */
          
          Stream.consecutive_pipeline_stalls ++;
          if (Stream.consecutive_pipeline_stalls % 8 == 0)
          {
            STi3520L_PipelineReset ();
            Stream.vid_flags.parsing_headers = true; /* to force re-use of the current frame struct */
          }
        }
      }
      else
      {
        dprintf (("IRQ", "INT_VS: current_picture_structure = %d\n", Stream.current_picture_structure));
        Stream.consecutive_pipeline_stalls = 0;
        if (Stream.current_picture_structure == ps_second_field_picture || Stream.current_picture_structure == ps_frame_picture_extension) /* ie first of two decodes within the PU */
        {
          Stream.fields_till_next_AU = 1; /* ideally, we want this done in one field only, irrespective of pause etc. */
        }
        else
        {
          /* Set countdown to next frame, taking slow-mo, pause etc into account */
          Stream.fields_till_next_AU = 2; /* default */
          if (Stream.display_frames->seq.progressive_sequence == true)
          {
            if (Stream.display_frames->repeat_first_field == true)
            {
              if (Stream.display_frames->top_field_first == true)
              {
                Stream.fields_till_next_AU = 6;
              }
              else
              {
                Stream.fields_till_next_AU = 4;
              }
            }
            else
            {
              if (Stream.display_frames->repeat_first_field && Stream.display_frames->top_field_first)
              {
                Stream.fields_till_next_AU = 4; /* first step in 3:2 pulldown support */
              }
            }
          }
          Stream.fields_till_next_AU *= Stream.video.speed_indicator;
          if (Stream.fields_till_next_AU == 0)
          {
            Stream.fields_till_next_AU = -2;
            /* For pause mode, we rely upon this not reaching 0 for a long time! */
            /* We use -2 instead of -1 so that the field polarity can be preserved when exiting pause */
          }
          /***** Add on two fields here if there's a repeat-frame pending (and not pause!!) */
          if (Stream.current_picture_structure == ps_first_field_picture || (Stream.current_picture_structure == ps_frame_picture && Stream.prev_picture_structure != ps_frame_picture))
          {
            Stream.fields_till_next_AU --; /* account for different field polarity of next picture */
          }
        }
        
        /* Whatever the picture_structure, flag that we've stalled (only persists until the last instruction is written) */
        Stream.vid_flags.final_instruction_has_been_written_during_this_AU = false;
      }
    }
    /* See if we now fit the condition for writing the next instruction */
    static_PerhapsWriteNewInstruction ();
  }
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~(field ? VIDEO_INT_VST : VIDEO_INT_VSB);
}

/******	static_INT_PSD() ***************************************************

Purpose:	Handles Pipeline Starting to Decode video IRQ
In:		Pointer to IRQ_Handler()'s |video_ints| variable
Notes:		This is enabled throughout normal play.

***************************************************************************/

static void static_INT_PSD (unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_PSD\n"));
  /* If start-code hit has already happened then fake an interrupt */
  if (VID_STA_0 & VIDEO_INT_SCH>>0 != 0)
  {
    *video_ints |= VIDEO_INT_SCH;
  }
  VID_ITM_0 |= VIDEO_INT_SCH>>0; /* enable start-code hit IRQ */
  /* If the decoder latches the next task before we've decoded the next headers, wait with 1-field granularity (ie unset VID_TIS.RPT) */
  VID_TIS = 0;
  dprintf (("IRQ", "INT_PSD: RFP = %04X, FFP = %04X, BFP = %04X\n", VID_RFP & 0x3FFF, VID_FFP & 0x3FFF, VID_BFP & 0x3FFF));
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~VIDEO_INT_PSD;
}

/******	static_INT_PID() ***************************************************

Purpose:	Handles Pipeline IDle video IRQ
In:		Pointer to IRQ_Handler()'s |video_ints| variable
Notes:		This is enabled throughout prefill and normal play. It is
		used to signal that one of the conditions for continuing
		decoding after a skip operation, or a decode during prefill,
		has become true.

***************************************************************************/

static void static_INT_PID (unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_PID\n"));
  if (!Stream.vid_flags.had_phoney_pipeline_idle_IRQ)
  {
    /* We always get one extra interrupt at the very beginning of a stream */
    /* I suspect this is due to the termination of the initial sequence-header-search task */
    Stream.vid_flags.had_phoney_pipeline_idle_IRQ = true;
  }
  else
  {
    if (!Stream.vid_flags.last_instruction_was_a_decode)
    {
      /* We have just completed a skip operation */
      /* Remove unwanted frame from both decode and display lists (unless we're the first of a */
      /* field pair, in which case do it after the second picture, which will also be skipped) */
      if (Stream.current_picture_structure != ps_first_field_picture)
      {
        static_RemoveFrameFromList (Stream.decode_frames, false);
        static_RemoveFrameFromList (Stream.decode_frames, true);
      }
      /* Force a header search (won't have been done automatically in this case) */
      VID_HDS = VID_HDS_SOS | VID_HDS_HDS;
      VID_ITM_0 |= VIDEO_INT_SCH>>0; /* enable start-code hit IRQ */
    }
    Stream.vid_flags.this_frames_data_have_been_decoded = true;
    static_PerhapsWriteNewInstruction ();
  }
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~VIDEO_INT_PID;
}

/******	static_INT_HFF() ***************************************************

Purpose:	Handles Header FIFO Full video IRQ
In:		Pointer to IRQ_Handler()'s |video_ints| variable
Notes:		This is enabled when the header FIFO has emptied during
		parsing of video headers. It is disabled when a slice header
		has been found, indicating the end of header parsing.

***************************************************************************/

static void static_INT_HFF (unsigned int *video_ints)
{
  dprintf (("IRQ", "INT_HFF\n"));
  /* Re-enter coroutine */
  Co_SwitchTo (&Stream.video.header_parser, video_ints);
  /* Clear out our bit in |video_ints| */
  *video_ints &= ~VIDEO_INT_HFF;
}

/******	static_INT_BBE() ***************************************************

Purpose:	Handles Bit Buffer Empty video IRQ
Notes:		This is enabled all the time, except during the parsing of the
		initial headers, and during play-out. It is used to count the
		number of video underruns that have occurred (hopefully none)

***************************************************************************/

static void static_INT_BBE (void)
{
  dprintf (("IRQ", "INT_BBE\n"));
  /* Don't count the underrun that happens naturally as part of play-out! */
  if (Stream.video.state != stream_closing)
  {
    Stream.video.since_open.underruns += 1;
    Stream.video.since_reset.underruns += 1;
  }
}

/******	static_INT_PER() ***************************************************

Purpose:	Handles Pipeline ERror video IRQ
Notes:		This is enabled throughout prefill and normal play, in order
		to count the occurrences of pipeline errors.

***************************************************************************/

static void static_INT_PER (void)
{
  dprintf (("IRQ", "INT_PER\n"));
  Stream.video.since_open.pipeline_errors += 1;
  Stream.video.since_reset.pipeline_errors += 1;
}

/******	static_INT_SER() ***************************************************

Purpose:	Handles Severe ERror video IRQ
Notes:		This is enabled throughout prefill and normal play, in order to
		count the occurrences of severe (macroblock overflow) errors.

***************************************************************************/

static void static_INT_SER (void)
{
  dprintf (("IRQ", "INT_SER\n"));
  Stream.video.since_open.severe_errors += 1;
  Stream.video.since_reset.severe_errors += 1;
}

/******	static_INT_PDE() ***************************************************

Purpose:	Handles Picture Decode Error video IRQ
Notes:		This is enabled throughout prefill and normal play, in order to
		count the occurrences of picture decode (macroblock underflow) errors.

***************************************************************************/

static void static_INT_PDE (void)
{
  dprintf (("IRQ", "INT_PDE\n"));
  Stream.video.since_open.picture_decode_errors += 1;
  Stream.video.since_reset.picture_decode_errors += 1;
}

/******	static_INT_VHR() ***************************************************

Purpose:	Handles Valid Header Registered audio IRQ
Notes:		This is enabled throughout prefill and normal play.

***************************************************************************/

static void static_INT_VHR (void)
{
  sample_rate old_sampling_frequency = (sample_rate) Stream.audio_header.fields.sampling_frequency;
  dprintf (("IRQ", "INT_VHR\n"));
  Stream.audio_header.word = AUD_HDR;
  if (!Stream.aud_flags.pcmclk_set_up_for_this_stream || (sample_rate) Stream.audio_header.fields.sampling_frequency != old_sampling_frequency)
  {
    STi3520L_SetPCMClock ((sample_rate) Stream.audio_header.fields.sampling_frequency, false, false);
    Stream.aud_flags.pcmclk_set_up_for_this_stream = true;
  }
}

/******	static_INT_SFC() ***************************************************

Purpose:	Handles Sampling Frequency Changed audio IRQ
Notes:		This is enabled throughout prefill and normal play.

***************************************************************************/

static void static_INT_SFC (void)
{
  dprintf (("IRQ", "INT_SFC\n"));
  STi3520L_SetPCMClock ((sample_rate) (AUD_SFR & 3), false, false);
}

/******	static_ProcessVideoHdr() *******************************************

Purpose:	Main coroutine entry point for video header parser
In:		Coroutine argument (address of IRQ_Handler()'s |video_ints| variable)

***************************************************************************/

static void static_ProcessVideoHdr (void *argument)
{
  unsigned int data;  /* for holding the results of static_GetVideoHdrBits */
  unsigned int *video_ints = argument;
  while (true)
  {
    /* Flush any cached data */
    static_GetVideoHdrBits (0);
    
    /* Header data FIFO contains a start code in one or other of its two bytes */
    if ((VID_SCM & 1) == 0) static_GetVideoHdrBits (8);
    data = static_GetVideoHdrBits (8);
    switch (data)
    {
      case SEQUENCE_HEADER_CODE:
        /* Start a new picture struct */
        if (!Stream.vid_flags.parsing_headers) static_NewPictureDecode ();
        static_ProcessVideoSequenceHdr ();
        break;
      case GROUP_START_CODE:
        /* If this is the first header for this picture, start a new picture struct */
        if (!Stream.vid_flags.parsing_headers) static_NewPictureDecode ();
        static_ProcessVideoGOPHdr ();
        break;
      case PICTURE_START_CODE:
        /* If this is the first header for this picture, start a new picture struct */
        if (!Stream.vid_flags.parsing_headers) static_NewPictureDecode ();
        static_ProcessVideoPictureHdr ();
        break;
      case EXTENSION_START_CODE:
        switch (static_GetVideoHdrBits (4))
        {
          case SEQUENCE_EXTENSION:
            static_ProcessVideoSequenceExt ();
            break;
          case SEQUENCE_DISPLAY_EXTENSION:
            static_ProcessVideoSequenceDisplayExt ();
            break;
          case PICTURE_CODING_EXTENSION:
            static_ProcessVideoPictureCodingExt ();
            break;
          case QUANT_MATRIX_EXTENSION:
            static_ProcessVideoQuantMatrixExt ();
            break;
          case PICTURE_DISPLAY_EXTENSION:
            static_ProcessVideoPictureDisplayExt ();
            break;
        }
        break;
      case USER_DATA_START_CODE:
        static_ProcessVideoUserData ();
        break;
      case SLICE_START_CODE:
        /* Now we've processed all the headers, take any necessary actions */
        static_ProcessVideoSliceHdr ();
        /* Sort out interrupt state between sets of headers */
        VID_ITM_8 &= ~(VIDEO_INT_HFF>>8); /* disable header fifo full IRQ, so we only return when the start-code detector has hit the next picture */
        *video_ints = (*video_ints | VID_ITS) & VID_ITM & ~VIDEO_INT_SCH & ~VIDEO_INT_HFF; /* clear the SCH and HFF bits in both VID_ITS and |video_ints| */
        /* Wait until the next set of headers arrive */
        Co_SwitchTo (Co_MainRoutine, NULL);
        break;
    }
    /* If the last-read header was a slice header, then by the time we get here, picture decoding is complete and an       */
    /* automatic header search has already been launched and completed. Otherwise, we have to launch the search ourselves: */
    if (data != SLICE_START_CODE)
    {
      VID_HDS = VID_HDS_SOS | VID_HDS_HDS;      
    }
  }
}

/******	static_NewPictureDecode() ******************************************

Purpose:	Sets up frame struct when we start to decode a new picture

***************************************************************************/

static void static_NewPictureDecode (void)
{
  frame_t *new_frame;
  /* Unless the new picture is (probably) the second in a pair of field pictures, we need to start a new frame struct */
  if (Stream.current_picture_structure != ps_first_field_picture)
  {
    dprintf (("IRQ", "NewPictureDecode: new frame struct\n"));
    /* Remove a picture struct from the unused list (there will always be at least one unused at this point) */
    new_frame = Stream.unused_frames;
    Stream.unused_frames = new_frame->decode_link;
    /* Add it on the front of the decoding list */
    new_frame->decode_link = Stream.decode_frames;
    Stream.decode_frames = new_frame;
    new_frame->on_decode_list = true;
    /* Write picture parameters into the first picture_t struct */
    Stream.decode_frames->lastpic = &Stream.decode_frames->pic1;
    /* Flags that we haven't assigned a frame buffer to this frame struct yet */
    Stream.vid_flags.buffer_assigned_to_this_frame = false;
  }
  else
  {
    dprintf (("IRQ", "NewPictureDecode: reused frame struct\n"));
    /* Write picture parameters into the second picture_t struct */
    Stream.decode_frames->lastpic = &Stream.decode_frames->pic2;
  }
  Stream.vid_flags.parsing_headers = true;
#ifdef DEBUGLIB
  {
    frame_t *frame = Stream.decode_frames;
    int items = 0;
    dprintf (("IRQ", "NewPictureDecode: decode frames list = "));
    while (frame != NULL)
    {
      dprintf (("IRQ", "%d ", ((int) frame - (int) Stream.frame) / sizeof (frame_t)));
      frame = frame->decode_link;
      if (++items > 10) break;
    }
  }
  dprintf (("IRQ", "\n"));
#endif
}

/******	static_ProcessVideoSequenceHdr() ***********************************

Purpose:	Parses MPEG sequence_header()

***************************************************************************/

static void static_ProcessVideoSequenceHdr (void)
{
  dprintf (("IRQ", "ProcessVideoSequenceHdr\n"));
  /* Set decoding state flags */
  Stream.last_video_header_layer_decoded = lvhld_sequence;
  Stream.vid_flags.sequence_header_received_since_picture_header = true;
  
  Stream.decode_frames->seq.mpeg2 = false;  /* assume MPEG-1 until we find a sequence_extension */
  Stream.decode_frames->seq.display_horizontal_size =
    Stream.decode_frames->seq.coded_horizontal_size = static_GetVideoHdrBits (12);
  Stream.decode_frames->seq.display_vertical_size =
    Stream.decode_frames->seq.coded_vertical_size = static_GetVideoHdrBits (12);
  Stream.decode_frames->seq.active_horizontal_size =
    Stream.decode_frames->seq.protected_horizontal_size =
    Stream.decode_frames->seq.active_vertical_size =
    Stream.decode_frames->seq.protected_vertical_size = 0; /* these cannot be determined until we have calculated seq.coded_aspect_ratio */
  Stream.decode_frames->seq.display_aspect_ratio =
    Stream.decode_frames->seq.coded_aspect_ratio = 0;  /* these aren't calculated until picture is displayed */
  Stream.decode_frames->seq.active_aspect_ratio =
    Stream.decode_frames->seq.protected_aspect_ratio = 0;  /* flag value => match coded aspect ratio unless Active Format Description is found */
  Stream.decode_frames->seq.active_area_is_at_top = false; /* default setting, unless changed by Active Format Description */
  WRITE_VID_DFS(((Stream.decode_frames->seq.coded_horizontal_size + 15) / 16) * ((Stream.decode_frames->seq.coded_vertical_size + 15) / 16));
  WRITE_VID_DFW((Stream.decode_frames->seq.coded_horizontal_size + 15) / 16);
  Stream.decode_frames->seq.aspect_ratio_information = static_GetVideoHdrBits (4);
  Stream.decode_frames->seq.frame_rate = frame_rate_table [static_GetVideoHdrBits (4)];
  Stream.decode_frames->seq.bit_rate = static_GetVideoHdrBits (18);
  static_GetVideoHdrBits (1);  /* skip marker bit */
  Stream.decode_frames->seq.vbv_buffer_size = static_GetVideoHdrBits (10);
  static_GetVideoHdrBits (1);  /* skip constrained parameters flag */
  /* The code for loading the quantization matrices is identical to that for processing quant_matrix_extension() */
  static_ProcessVideoQuantMatrixExt ();
  /* Set sensible values in case the sequence extensions are absent */
  Stream.decode_frames->seq.profile_and_level_indication = 0;  /* unknown */
  Stream.decode_frames->seq.progressive_sequence = true;       /* MPEG-1 is progressive only */
  Stream.decode_frames->seq.chroma_format = 1;                 /* MPEG-1 only uses 4:2:0 */
  Stream.decode_frames->seq.low_delay = false;                 /* typically */
  Stream.decode_frames->seq.video_format = 5;                  /* unspecified */
  Stream.decode_frames->seq.color_primaries = 1;               /* ITU-R BT.709 */
  Stream.decode_frames->seq.transfer_characteristics = 1;      /* ITU-R BT.709 */
  Stream.decode_frames->seq.matrix_coefficients = 1;           /* ITU-R BT.709 */
}

/******	static_ProcessVideoSequenceExt() ***********************************

Purpose:	Parses MPEG sequence_extension()

***************************************************************************/

static void static_ProcessVideoSequenceExt (void)
{
  dprintf (("IRQ", "ProcessVideoSequenceExt\n"));
  Stream.decode_frames->seq.mpeg2 = true;
  Stream.decode_frames->seq.profile_and_level_indication = static_GetVideoHdrBits (8);
  Stream.decode_frames->seq.progressive_sequence = static_GetVideoHdrBits (1);
  Stream.decode_frames->seq.chroma_format = static_GetVideoHdrBits (2);
  Stream.decode_frames->seq.display_horizontal_size =
    Stream.decode_frames->seq.coded_horizontal_size |= static_GetVideoHdrBits (2) << 12;
  Stream.decode_frames->seq.display_vertical_size =
    Stream.decode_frames->seq.coded_vertical_size |= static_GetVideoHdrBits (2) << 12;
  WRITE_VID_DFS(((Stream.decode_frames->seq.coded_horizontal_size + 15) / 16) * ((Stream.decode_frames->seq.coded_vertical_size + 15) / 16));
  WRITE_VID_DFW((Stream.decode_frames->seq.coded_horizontal_size + 15) / 16);
  Stream.decode_frames->seq.bit_rate |= static_GetVideoHdrBits (12) << 18;
  static_GetVideoHdrBits (1);  /* skip marker bit */
  Stream.decode_frames->seq.vbv_buffer_size |= static_GetVideoHdrBits (8) << 10;
  Stream.decode_frames->seq.low_delay = static_GetVideoHdrBits (1);
  Stream.decode_frames->seq.frame_rate *= static_GetVideoHdrBits (2) + 1;
  Stream.decode_frames->seq.frame_rate /= static_GetVideoHdrBits (5) + 1;
}

/******	static_ProcessVideoSequenceDisplayExt() ****************************

Purpose:	Parses MPEG sequence_display_extension()

***************************************************************************/

static void static_ProcessVideoSequenceDisplayExt (void)
{
  dprintf (("IRQ", "ProcessVideoSequenceDisplayExt\n"));
  Stream.decode_frames->seq.video_format = static_GetVideoHdrBits (3);
  if (static_GetVideoHdrBits (1) == 1)
  {
    Stream.decode_frames->seq.color_primaries = static_GetVideoHdrBits (8);
    Stream.decode_frames->seq.transfer_characteristics = static_GetVideoHdrBits (8);
    Stream.decode_frames->seq.matrix_coefficients = static_GetVideoHdrBits (8);
  }
  /* else the defaults from static_ProcessVideoSequenceHdr persist */
  Stream.decode_frames->seq.display_horizontal_size = static_GetVideoHdrBits (14);
  static_GetVideoHdrBits (1);  /* skip marker bit */
  Stream.decode_frames->seq.display_vertical_size = static_GetVideoHdrBits (14);
}

/******	static_ProcessVideoGOPHdr() ****************************************

Purpose:	Parses MPEG group_of_pictures_header()

***************************************************************************/

static void static_ProcessVideoGOPHdr (void)
{
  dprintf (("IRQ", "ProcessVideoGOPHdr\n"));
  /* Set decoding state flags */
  Stream.last_video_header_layer_decoded = lvhld_gop;
  Stream.vid_flags.gop_header_received_since_picture_header = true;
  
  Stream.decode_frames->gop.time_code = static_GetVideoHdrBits (25);
  Stream.decode_frames->gop.closed_gop = static_GetVideoHdrBits (1);
  Stream.decode_frames->gop.broken_link = static_GetVideoHdrBits (1);
}

/******	static_ProcessVideoPictureHdr() ************************************

Purpose:	Parses MPEG picture_header()

***************************************************************************/

static void static_ProcessVideoPictureHdr (void)
{
  dprintf (("IRQ", "ProcessVideoPictureHdr\n"));
  /* If necessary, clone sequence and GOP-related variables from the previously-decoded picture */
  if (Stream.current_picture_structure != ps_first_field_picture)
  {
    if (!Stream.vid_flags.sequence_header_received_since_picture_header) Stream.decode_frames->seq = Stream.decode_frames->decode_link->seq;
    if (!Stream.vid_flags.gop_header_received_since_picture_header) Stream.decode_frames->gop = Stream.decode_frames->decode_link->gop;
  }
  /* Set decoding state flags */
  Stream.last_video_header_layer_decoded = lvhld_picture;
  Stream.vid_flags.sequence_header_received_since_picture_header = false;
  Stream.vid_flags.gop_header_received_since_picture_header = false;
  
  Stream.decode_frames->temporal_reference = static_GetVideoHdrBits (10);
  Stream.decode_frames->lastpic->picture_coding_type = static_GetVideoHdrBits (3);
  Stream.decode_frames->lastpic->vbv_delay = static_GetVideoHdrBits (16);
  if (Stream.decode_frames->lastpic->picture_coding_type == P_PICTURE ||
      Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE)
  {
    /* The 3520 overloads MPEG-1 full_pel_forward_vector/forward_f_code and MPEG-2 f_code[0,0] */
    Stream.decode_frames->lastpic->forward_horizontal_f_code = static_GetVideoHdrBits (4);
    /* f_code[0,1] register not used in MPEG-1 mode */
    Stream.decode_frames->lastpic->forward_vertical_f_code = 0xF;
  }
  else
  {
    /* Forward f_codes not used for I pictures */
    Stream.decode_frames->lastpic->forward_horizontal_f_code =
      Stream.decode_frames->lastpic->forward_vertical_f_code = 0xF;
  }
  if (Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE)
  {
    /* The 3520 overloads MPEG-1 full_pel_backward_vector/backward_f_code and MPEG-2 f_code[1,0] */
    Stream.decode_frames->lastpic->backward_horizontal_f_code = static_GetVideoHdrBits (4);
    /* f_code[1,1] register not used in MPEG-1 mode */
    Stream.decode_frames->lastpic->backward_vertical_f_code = 0xF;
  }
  else
  {
    /* Backward f_codes not used for I or P pictures */
    Stream.decode_frames->lastpic->backward_horizontal_f_code =
      Stream.decode_frames->lastpic->backward_vertical_f_code = 0xF;
  }
  /* Ignore extra_bit_picture and extra_information_picture */
  
  /* Set sensible values in case the picture extensions are absent */
  Stream.next_picture_structure = ps_frame_picture; /* for MPEG-1 */
  Stream.decode_frames->lastpic->intra_dc_precision = 0;  /**/
  Stream.decode_frames->lastpic->picture_structure = 0;   /**  these are the values the VID_PPR1/2 registers require in MPEG-1 mode */
  Stream.decode_frames->lastpic->picture_flags.byte = 0;  /**/
  Stream.decode_frames->top_field_first = true;
  Stream.decode_frames->repeat_first_field = false;
  Stream.decode_frames->progressive_frame = true; /* although value is meaningless, because both fields are the same in MPEG-1 */
  Stream.decode_frames->frame_center_horizontal_offset [0] = 0;
  Stream.decode_frames->frame_center_horizontal_offset [1] = 0;
  Stream.decode_frames->frame_center_horizontal_offset [2] = 0;
  Stream.decode_frames->frame_center_vertical_offset [0] = 0;
  Stream.decode_frames->frame_center_vertical_offset [1] = 0;
  Stream.decode_frames->frame_center_vertical_offset [2] = 0;
  Stream.decode_frames->lastpic->active_format = 0xFF; /* magic value to flag that AFD hasn't been found */

  /* Get a new reconstruction frame pointer, unless we already have one */
  if (!Stream.vid_flags.buffer_assigned_to_this_frame)
  {
    Stream.decode_frames->frame_buffer = Stream.unused_frame_buffers;
    if (Stream.decode_frames->frame_buffer == NULL)
    {
      /* In this case, all the frame buffers are already in use. */
      /* The currently displaying frame will *definitely* be a B-frame, and so will be the next one to become available. */
      /* We have to double-book it now, because we'd miss the hardware latch otherwise... */
      Stream.decode_frames->frame_buffer = Stream.display_frames->frame_buffer;
    }
    else
    {
      /* Remove a frame_buffer struct from the unused list */
      Stream.unused_frame_buffers = Stream.decode_frames->frame_buffer->unused_link;
    }
    /* Either way, increment the usage count */
    Stream.decode_frames->frame_buffer->usage_count ++;
    /* Flag that we've assigned a buffer now */
    Stream.vid_flags.buffer_assigned_to_this_frame = true;
  }
  WRITE_VID_RFP(Stream.decode_frames->frame_buffer->addr);
  
  /* Set up the predictor frame pointers (which depend upon picture_coding_type) */
  {
    frame_t *frame;
    frame_t *next_frame; /* because we may be removing the frame from the list, we have to work this out first */
    int anchor_frames_found = 0;
    unsigned int BFP = 0;
    unsigned int FFP = 0;
    for (frame = Stream.decode_frames->decode_link; frame != NULL; frame = next_frame)
    {
      next_frame = frame->decode_link;
      if (frame->lastpic->picture_coding_type != B_PICTURE)
      {
        anchor_frames_found++;
        /* For anchor frames, the most recent anchor frame is written to VID_FFP */
        if (Stream.decode_frames->lastpic->picture_coding_type != B_PICTURE && anchor_frames_found == 1) FFP = frame->frame_buffer->addr;
        /* For anchor frames, the second-most recent anchor frame is no longer required as a predictor */
        if (Stream.decode_frames->lastpic->picture_coding_type != B_PICTURE && anchor_frames_found == 2) static_RemoveFrameFromList (frame, true);
        /* For B-frames, the most recent anchor frame is written to VID_BFP */
        if (Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE && anchor_frames_found == 1) BFP = frame->frame_buffer->addr;
        /* For B-frames, the second-most recent anchor frame is written to VID_FFP */
        if (Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE && anchor_frames_found == 2) FFP = frame->frame_buffer->addr;
      }
    }
    WRITE_VID_FFP(FFP); /* it seems that these writes will intermittently */
    WRITE_VID_BFP(BFP); /* fail if we do them in the opposite order!!     */
  }
  dprintf (("IRQ", "ProcessVideoPictureHdr: RFP = %04X, FFP = %04X, BFP = %04X\n", VID_RFP & 0x3FFF, VID_FFP & 0x3FFF, VID_BFP & 0x3FFF));
  
  /* Add the frame into the display list (this depends upon the picture_coding_type too) */
  if (Stream.current_picture_structure != ps_first_field_picture /* note that this still refers to the previous picture */)
  {
    frame_t *frame_to_insert_after = NULL;
    frame_t *previous = NULL;
    frame_t *rover = Stream.display_frames;
    while (rover != NULL)
    {
      /* Anchor frames are added at the end of the list */
      if (Stream.decode_frames->lastpic->picture_coding_type != B_PICTURE && rover->display_link == NULL)
        frame_to_insert_after = rover;
      /* B-frames are added before the last anchor frame on the list */
      if (Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE && rover->lastpic->picture_coding_type != B_PICTURE)
        frame_to_insert_after = previous;
      previous = rover;
      rover = rover->display_link;
    }
    if (frame_to_insert_after == NULL)
    {
      Stream.decode_frames->display_link = Stream.display_frames;
      Stream.display_frames = Stream.decode_frames;
    }
    else
    {
      Stream.decode_frames->display_link = frame_to_insert_after->display_link;
      frame_to_insert_after->display_link = Stream.decode_frames;
    }
    Stream.decode_frames->on_display_list = true;
  }
#ifdef DEBUGLIB
  {
    frame_t *frame = Stream.display_frames;
    int items = 0;
    const char *coding_names = " IPB";
    dprintf (("IRQ", "ProcessVideoPictureHdr: display frames list = "));
    while (frame != NULL)
    {
      dprintf (("IRQ", "%d (%d,%c) ", ((int) frame - (int) Stream.frame) / sizeof (frame_t), frame->temporal_reference, coding_names[frame->pic1.picture_coding_type]));
      frame = frame->display_link;
      if (++items > 10) break;
    }
  }
  dprintf (("IRQ", "\n"));
#endif
}

/******	static_ProcessVideoPictureCodingExt() ******************************

Purpose:	Parses MPEG picture_coding_extension()

***************************************************************************/

static void static_ProcessVideoPictureCodingExt (void)
{
  dprintf (("IRQ", "ProcessVideoPictureCodingExt\n"));
  Stream.decode_frames->lastpic->forward_horizontal_f_code = static_GetVideoHdrBits (4);
  Stream.decode_frames->lastpic->forward_vertical_f_code = static_GetVideoHdrBits (4);
  Stream.decode_frames->lastpic->backward_horizontal_f_code = static_GetVideoHdrBits (4);
  Stream.decode_frames->lastpic->backward_vertical_f_code = static_GetVideoHdrBits (4);
  Stream.decode_frames->lastpic->intra_dc_precision = static_GetVideoHdrBits (2);
  Stream.decode_frames->lastpic->picture_structure = static_GetVideoHdrBits (2);
  Stream.decode_frames->lastpic->picture_flags.byte = static_GetVideoHdrBits (6);
  Stream.decode_frames->repeat_first_field = static_GetVideoHdrBits (1); /* used only for parsing picture_display_extension */
  static_GetVideoHdrBits (1); /* ignore chroma_420_type */
  Stream.decode_frames->progressive_frame = static_GetVideoHdrBits (1); /* used in WSS signal and deciding whether to freeze fields or frames */
  /* Ignore composite_display_flag, v_axis, field_sequence, sub_carrier, burst_amplitude and sub_carrier_phase */
  
  /* Set next_picture_structure and frame's top_field_first flag */
  if (Stream.decode_frames->lastpic->picture_structure == FRAME_PICTURE)
  {
    Stream.next_picture_structure = ps_frame_picture;
    dprintf (("IRQ", "ProcessVideoPictureCodingExt: frame_picture\n"));
    Stream.decode_frames->top_field_first = Stream.decode_frames->lastpic->picture_flags.bits.top_field_first;
  }
  else
  {
    switch (Stream.current_picture_structure)
    {
      case ps_first_field_picture:
        Stream.next_picture_structure = ps_second_field_picture;
        dprintf (("IRQ", "ProcessVideoPictureCodingExt: second_field_picture\n"));
        break;
      case ps_second_field_picture:
        Stream.next_picture_structure = ps_first_field_picture;
        dprintf (("IRQ", "ProcessVideoPictureCodingExt: first_field_picture\n"));
        /* Copy top_field_first from last frame (should be more resilient if an odd number of pictures are lost due to errors) */
        Stream.decode_frames->top_field_first = Stream.decode_frames->decode_link->top_field_first;
        break;
      case ps_frame_picture:
      case ps_frame_picture_extension:
        /* It's possible to switch between field and frame pictures within the same clip */
        Stream.next_picture_structure = ps_first_field_picture;
        dprintf (("IRQ", "ProcessVideoPictureCodingExt: first_field_picture\n"));
        /* The current field type must be used to determine top_field_first flag */
        Stream.decode_frames->top_field_first = (Stream.decode_frames->lastpic->picture_structure == TOP_FIELD_PICTURE);
        break;
    }
  }
}

/******	static_ProcessVideoQuantMatrixExt() ********************************

Purpose:	Parses MPEG quant_matrix_extension() or the quant matrix
		part of the sequence_header()

***************************************************************************/

static void static_ProcessVideoQuantMatrixExt (void)
{
  unsigned int coeff;   /* counter for loading quantization matrices */
  dprintf (("IRQ", "ProcessVideoQuantMatrixExt\n"));
  
  /* VERY IMPORTANT:                                                  */
  /* The data sheet is wrong, bit VID_HDS.QMI must be set for *intra* */
  /* quantizer matrices, and clear for *non-intra* quantizer matrices */
  
  if (static_GetVideoHdrBits (1) == 0)
  {
    /* Load default intra quantizer matrix (if necessary) */
    if (!Stream.vid_flags.default_intra_quantizer_matrix_loaded)
    {
      VID_HDS = VID_HDS_QMI; /* select intra table */
      for (coeff = 0; coeff < 64; coeff ++)
      {
        VID_QMW = default_intra_quantizer_matrix[coeff];
      }
      Stream.vid_flags.default_intra_quantizer_matrix_loaded = true;
    }
  }
  else
  {
    /* Load intra quantizer matrix from stream */
    VID_HDS = VID_HDS_QMI; /* select intra table */
    for (coeff = 0; coeff < 64; coeff ++)
    {
      VID_QMW = static_GetVideoHdrBits (8);
    }
    Stream.vid_flags.default_intra_quantizer_matrix_loaded = false;
  }
  if (static_GetVideoHdrBits (1) == 0)
  {
    /* Load default non-intra quantizer matrix (if necessary) */
    if (!Stream.vid_flags.default_non_intra_quantizer_matrix_loaded)
    {
      VID_HDS = 0; /* select non-intra table */
      for (coeff = 0; coeff < 64; coeff ++)
      {
        VID_QMW = 16; /* all coefficients of default non-intra matrix are 16 */
      }
      Stream.vid_flags.default_non_intra_quantizer_matrix_loaded = true;
    }
  }
  else
  {
    /* Load non-intra quantizer matrix from stream */
    VID_HDS = 0; /* select non-intra table */
    for (coeff = 0; coeff < 64; coeff ++)
    {
      VID_QMW = static_GetVideoHdrBits (8);
    }
    Stream.vid_flags.default_non_intra_quantizer_matrix_loaded = false;
  }
  
  /* Do nothing - if we're parsing sequence_header() then there's nothing else to do; if we're parsing quant_matrix_extension(), */
  /* then the following bits are chroma quant matrices, which will be skipped by the header search when we return. */
  /* Chroma quantizer matrices are not supported by the 3520, and are not required by Simple Profile or Main Profile. */
}

/******	static_ProcessVideoPictureDisplayExt() *****************************

Purpose:	Parses MPEG picture_display_extension()

***************************************************************************/

static void static_ProcessVideoPictureDisplayExt (void)
{
  unsigned char number_of_frame_center_offsets;
  unsigned char offset_no;
  signed short horizontal_offset = 0;
  signed short vertical_offset = 0;
  dprintf (("IRQ", "ProcessVideoPictureDisplayExt\n"));
  /* Determine the number of frame centre offsets */
  if (Stream.decode_frames->seq.progressive_sequence == 1)
  {
    if (Stream.decode_frames->repeat_first_field == true)
    {
      if (Stream.decode_frames->lastpic->picture_flags.bits.top_field_first == 1)
      {
        number_of_frame_center_offsets = 3;
      }
      else
      {
        number_of_frame_center_offsets = 2;
      }
    }
    else
    {
      number_of_frame_center_offsets = 1;
    }
  }
  else
  {
    if (Stream.decode_frames->lastpic->picture_structure == FRAME_PICTURE)
    {
      if (Stream.decode_frames->repeat_first_field == true)
      {
        number_of_frame_center_offsets = 3;
      }
      else
      {
        number_of_frame_center_offsets = 2;
      }
    }
    else
    {
      number_of_frame_center_offsets = 1;
    }
  }
  
  /* Set up all three pairs of offsets, repeating the final coded pair if necessary, */
  /* in case the picture is displayed for longer than expected */
  for (offset_no = 0; offset_no < 3; offset_no++)
  {
    if (offset_no < number_of_frame_center_offsets)
    {
      horizontal_offset = (signed short) static_GetVideoHdrBits (16);
      static_GetVideoHdrBits (1); /* skip marker bit */
      vertical_offset = (signed short) static_GetVideoHdrBits (16);
      static_GetVideoHdrBits (1); /* skip marker bit */
    }
    Stream.decode_frames->frame_center_horizontal_offset [offset_no] = horizontal_offset;
    Stream.decode_frames->frame_center_vertical_offset [offset_no] = vertical_offset;
  }
}

/******	static_ProcessVideoUserData() **************************************

Purpose:	Parses MPEG user_data()

***************************************************************************/

static void static_ProcessVideoUserData (void)
{
  /* This code is designed to expect DiviCom/C-Cube (closed captions) or DTG1 (AFD) format user data. */
  /* This is achieved by assuming DiviCom/C-Cube format, and treating DTG1 format as a special instance of it! */
  unsigned char dataLength;
  unsigned char dataType;
  unsigned char extDataType;
  bool first_chunk = true;
  bool DiviCom_format;
  dprintf (("IRQ", "ProcessVideoUserData\n"));
  do
  {
    dataLength = static_GetVideoHdrBits (8);
    if (dataLength == 0)
    {
      /* End of data - don't pull any more from header FIFO */
      /* It would make the code messy not to use break in this function */
      break;
    }
    dataType = static_GetVideoHdrBits (8);
    if (dataType == 0xFF)
    {
      extDataType = static_GetVideoHdrBits (8);
    }
    else
    {
      extDataType = 0xFF;
    }
    if (first_chunk)
    {
      /* Determine format of data */
      if (dataType == 0x44 && dataLength == 0x54)
      {
        /* This is highly unlikely to be used by DiviCom or C-Cube, but check the rest of the DTG1 magic word, to be sure */
        if (static_GetVideoHdrBits (16) == 0x3147)
        {
          /* It *is* DTG1 format */
          static_ProcessVideoDTG1UserData ();
        }
        /* If it wasn't DTG1 then we've messed things up by reading 16 bits. */
        /* If it was DTG1, then don't try to interpret any remaining user data. */
        /* Either way, we want to exit the function now. */
        break;
      }
      else if ((dataType == 0x02 && dataLength == 0x05) ||
               (dataType == 0x04 && dataLength == 0x05) ||
               (dataType == 0x05 && dataLength == 0x01) ||
               (dataType == 0x06 && dataLength == 0x02) ||
               (dataType == 0x07 && dataLength == 0x01) ||
               (dataType == 0x08 && dataLength == 0x03) ||
               (dataType == 0x09 && dataLength == 0x02) ||
               (dataType == 0x09 && dataLength == 0x04) ||
               (dataType == 0x0A && dataLength == 0x02) ||
               (dataType == 0x0A && dataLength == 0x04))
      {
        /* Looks like DiviCom format */
        DiviCom_format = true;
      }
      else if ((dataType == 0x02 && dataLength == 0x06) ||
               (dataType == 0x04 && dataLength == 0x06) ||
               (dataType == 0x05 && dataLength == 0x02) ||
               (dataType == 0x06 && dataLength == 0x03) ||
               (dataType == 0x07 && dataLength == 0x02) ||
               (dataType == 0x08 && dataLength == 0x04) ||
               (dataType == 0x09 && dataLength == 0x03) ||
               (dataType == 0x0A && dataLength == 0x03))
      {
        /* Looks like C-Cube format */
        DiviCom_format = false;
      }
      else
      {
        /* Unknown format - just exit function (data will be skipped by the next header search) */
        break;
      }
      first_chunk = false;
    }
    /* Closed captioning support goes here */
  }
  while (dataLength != 0);
}

/******	static_ProcessVideoDTG1UserData() **********************************

Purpose:	Parses DTG1 format MPEG user_data()

***************************************************************************/

static void static_ProcessVideoDTG1UserData (void)
{
  bool active_format_flag;
  dprintf (("IRQ", "ProcessVideoDTG1UserData\n"));
  static_GetVideoHdrBits (1); /* skip zero bit */
  active_format_flag = static_GetVideoHdrBits (1);
  static_GetVideoHdrBits (6); /* skip reserved bits */
  if (active_format_flag == true)
  {
    static_GetVideoHdrBits (4); /* skip reserved bits */
    Stream.decode_frames->lastpic->active_format = static_GetVideoHdrBits (4);
  }
}

/******	static_ProcessVideoSliceHdr() **************************************

Purpose:	Deals with the completion of header parsing

***************************************************************************/

static void static_ProcessVideoSliceHdr (void)
{
  dprintf (("IRQ", "ProcessVideoSliceHdr\n"));
  /* Calculate the video buffer prefill threshold if we haven't done so already */
  if (VideoPrefillSize == -1)
  {
    VideoPrefillSize = (Stream.decode_frames->seq.bit_rate * Stream.decode_frames->lastpic->vbv_delay) / (2048 * 90000 / 400);
    /* The multiplication should be 32-bit safe, because even the 15Mbit/s theoretical maximum rate of */
    /* the 3520 equates to &9999 (16 bits) * 400bits/s, and vbv_delay is also a 16 bit value.          */
    /* Now cap the value by vbv_buffer_size, in case one of the above values was silly */
    VideoPrefillSize = MIN(VideoPrefillSize, Stream.decode_frames->seq.vbv_buffer_size * (16 * 1024 / 2048));
    /* Now cap the value by the size of our allocated bit buffer */
    VideoPrefillSize = MIN(VideoPrefillSize, (SDRAM_VIDEO_BIT_BUFFER_END - SDRAM_VIDEO_BIT_BUFFER_START - 256) / 256);
    WRITE_VID_VBT(VideoPrefillSize);
    /* Since we have now finished parsing the initial headers, we can enable the video underrun interrupt */
    /* (we always get a couple of underruns during initial header parsing, so it's silly to count them) */
    VID_ITM_0 |= VIDEO_INT_BBE>>0; /* enable bit buffer empty IRQ */
  }
  Stream.vid_flags.parsing_headers = false;
  Stream.vid_flags.next_frames_headers_have_been_decoded = true;
  static_PerhapsWriteNewInstruction ();
}

/******	static_GetVideoHdrBits() *******************************************

Purpose:	Fetches the next few bits from the video header FIFO
In:		Number of bits to fetch (up to 32, may cross byte/word boundaries)
		or 0 to discard cached data and force a fresh data fetch next time
Out:		Value of bits (unused bits are zero)
Notes:		The coroutine can exited through this function

***************************************************************************/

static unsigned int static_GetVideoHdrBits (unsigned char bits)
{
  static unsigned short fifo; /* 16 bits most recently read from the FIFO */
  static unsigned char cached_bits = 0; /* the number of bits from |fifo| that have not yet been returned */
  unsigned int data = 0; /* for building up the return value */
  unsigned char bits_this_time;
  if (bits == 0)
  {
    cached_bits = 0;
  }
  else
  {
    while (bits > 0)
    {
      if (cached_bits == 0)
      {
        if ((VID_STA_0 & (VIDEO_INT_HFE>>0)) != 0)
        {
          VID_ITM_8 |= VIDEO_INT_HFF>>8;  /* enable header fifo full IRQ */
          Co_SwitchTo (Co_MainRoutine, NULL);
        }
        fifo = VID_HDF;
        fifo = (fifo << 8) | (fifo >> 8); /* switch bytesex to little-endian */
        cached_bits = 16;
      }
      bits_this_time = MIN(bits, cached_bits);
      data <<= bits_this_time;
      data |= (fifo >> (cached_bits - bits_this_time)) & ((1 << bits_this_time) - 1);
      bits -= bits_this_time;
      cached_bits -= bits_this_time;
    }
  }
  return data;
}

/******	static_PerhapsWriteNewInstruction() ********************************

Purpose:	May or may not write the next task instruction, depending
		upon whether all of the appropriate conditions have been
		met. Typically called whenever we suspect that one of the
		conditions has become satisfied, in case it was the last one
		we were waiting for.

***************************************************************************/

static void static_PerhapsWriteNewInstruction (void)
{
  bool time_to_write_instruction = false;
  bool use_FIS_bit = false;
  dprintf (("IRQ", "PerhapsWriteNewInstruction\n"));
  if (Stream.vid_flags.next_frames_headers_have_been_decoded &&
      Stream.vid_flags.this_frames_data_have_been_decoded &&
      (VID_VBL & 0x3FFF) >= (VID_VBT & 0x3FFF))
  {
    if (Stream.video.state == stream_prefilling)
    /* or if we want to skip the next frame */
    {
      time_to_write_instruction = true;
      use_FIS_bit = true;
    }
    else
    {
      if ((Stream.next_picture_structure != ps_first_field_picture || Stream.current_picture_structure == ps_frame_picture) && Stream.fields_till_next_AU == 1 ||
          (Stream.next_picture_structure == ps_first_field_picture && Stream.current_picture_structure != ps_frame_picture) && Stream.fields_into_this_PU == Stream.field_to_trigger_second_decode_on)
      {
        time_to_write_instruction = true;
      }
    }
  }
  
  if (time_to_write_instruction)
  {
    /* Check to see if we've just finished decoding the first or only picture of the prefill anchor frames */
    if (Stream.video.state == stream_prefilling && Stream.next_picture_structure != ps_first_field_picture && Stream.vid_flags.last_instruction_was_a_decode)
    {
      Stream.vid_flags.prefill_anchor_frames_decoded ++;
      dprintf (("IRQ", "PerhapsWriteNewInstruction: prefill_anchor_frames_decoded = %d\n", Stream.vid_flags.prefill_anchor_frames_decoded));
    }
    /* Are we ready to start display (discounting issues about synchronisation and field polarity) ? */
    if (Stream.video.state == stream_prefilling && Stream.vid_flags.prefill_anchor_frames_decoded == 2)
    {
      /* Update state machine */
      Stream.video.prefill_state = ps_waiting_for_play_command;
      dprintf (("IRQ", "PerhapsWriteNewInstruction: video.prefill_state = waiting_for_play_command\n"));
      /* Enable vsync interrupts now - but don't take any action on them until we receive the play command.         */
      /* This is necessary so that we can clear the relevant bits in VID_ITS - otherwise, if it takes a long time   */
      /* for audio prefilling to complete, then the first interrupt will have both VID_ITS.VST and VID_ITS.VSB set! */
      VID_ITM_0 |= (VIDEO_INT_VSB>>0 | VIDEO_INT_VST>>0);
      /* Tell control unit that we've finished - we may be re-entered via SWI MPEGVideo_Play at this point */
      _swix (MPEGControl_Play, _INR(0,1), StreamFlags_VideoPresent, Stream.csh);
    }
    else
    {
      if (Stream.current_picture_structure == ps_frame_picture && Stream.next_picture_structure != ps_frame_picture)
      {
        /* Moving into field-based video, we need to update display, but hold off decode by one field */
        /* Next time we trigger on fields_into_this_PU = 0, instead of fields_till_next_AU = 1 */
        Stream.fields_into_this_PU = -1;
        Stream.field_to_trigger_second_decode_on = 0;
        Stream.prev_picture_structure = Stream.current_picture_structure;
        Stream.current_picture_structure = ps_frame_picture_extension;
        Stream.vid_flags.final_instruction_has_been_written_during_this_AU = true; /* pretend it was an instruction */
        static_SetUpDisplayForNewAU ();
      }
      else
      {
        if (Stream.video.state == stream_prefilling && Stream.decode_frames->lastpic->picture_coding_type == B_PICTURE)
        /* or if a skip-next-frame is pending */
        {
          static_WriteSkipInstruction (use_FIS_bit);
        }
        else
        {
          static_SetUpDisplayForNewAU ();
          static_WriteDecodeInstruction (use_FIS_bit);
          /* Enable decoding if necessary */
          if (Stream.vid_flags.prefill_anchor_frames_decoded == 0)
          {
            dprintf (("IRQ", "PerhapsWriteNewInstruction: enabling decoding\n"));
            VID_CTL |= VID_CTL_EDC;
            VID_ITM_0 |= VIDEO_INT_PSD>>0; /* enable pipeline starting to decode video IRQ */
          }
        }
        /* Set state flags */
        Stream.vid_flags.next_frames_headers_have_been_decoded = false;
        Stream.vid_flags.this_frames_data_have_been_decoded = false;
      }
    }
  }
}

/******	static_SetUpDisplayForNewAU() **************************************

Purpose:	Changes the display parameters to suit the next access unit (not presentation unit)

***************************************************************************/

static void static_SetUpDisplayForNewAU (void)
{
  dprintf (("IRQ", "SetUpDisplayForNewAU\n"));
  if (Stream.video.state == stream_open || Stream.video.state == stream_closing)
  {
    /* Advance the display frame, but not when initiating any second decode within a PU */
    /* Also do it at the start of a frame_picture_extension (but not at the end of it) */
    if (Stream.next_picture_structure == ps_second_field_picture ||
        (Stream.next_picture_structure == ps_frame_picture && Stream.current_picture_structure == ps_frame_picture) ||
        (Stream.current_picture_structure == ps_frame_picture_extension && Stream.fields_into_this_PU == -1))
    {
      /* Remove the previously displayed frame from the display list (but not if there wasn't a previously decoded frame!) */
      if (Stream.vid_flags.first_frame_displayed == true)
      {
        dprintf (("IRQ", "SetUpDisplayForNewAU: removing frame %d from display list\n", ((int) Stream.display_frames - (int) Stream.frame) / sizeof (frame_t)));
        static_RemoveFrameFromList (Stream.display_frames, false);
      }
      dprintf (("IRQ", "SetUpDisplayForNewAU: about to display frame %d\n", ((int) Stream.display_frames - (int) Stream.frame) / sizeof (frame_t)));
      /* Set up display parameters for the new frame */
      WRITE_VID_XFS(((Stream.display_frames->seq.coded_horizontal_size + 15) / 16) * ((Stream.display_frames->seq.coded_vertical_size + 15) / 16));
      WRITE_VID_XFW((Stream.display_frames->seq.coded_horizontal_size + 15) / 16);
      {
        unsigned int adder;
        unsigned int actual_display_width;
        adder = (Stream.display_frames->seq.coded_horizontal_size-1)*256;
        if (adder % 719 == 0) adder = adder / 719; else adder = adder / 719 + 1;
        WRITE_VID_LSR(adder - 1);
        actual_display_width = (Stream.display_frames->seq.coded_horizontal_size-1)*256/adder+1;
// NTSC
//        WRITE_VID_XDS(102+actual_display_width+6-1);
// PAL
        WRITE_VID_XDS(112+actual_display_width+6-1);
      }
      WRITE_VID_DCF(VID_DCF | VID_DCF_EVD);
      WRITE_VID_DFP(Stream.display_frames->frame_buffer->addr);
      /* Set state flags/variables */
      Stream.fields_into_this_PU = -1; /* start an incrementing count of how many fields the frame has been displayed for */
      Stream.field_to_trigger_second_decode_on = 0; /* default, used unless first decode stalls */
    }
    if (Stream.next_picture_structure == ps_frame_picture || (Stream.current_picture_structure == ps_frame_picture_extension && Stream.fields_into_this_PU == -1))
    {
      /* Always display a frame's first field at the first VSync */
      /* However, if the frame decode followed a field decode, then we're just coming up to the second (or fourth, sixth etc.) VSync of the PU */
      /* so we may need to display the opposite field (but only for progressive_frames or when in normal-speed play) */
      if (Stream.current_picture_structure != ps_frame_picture &&
          (Stream.display_frames->display_link->progressive_frame || (Stream.video.speed_indicator == 1 && Stream.rs_flags.trick_play_mode == false)))
      {
        static_SetNextDisplayField (!Stream.display_frames->top_field_first);
      }
      else
      {
        static_SetNextDisplayField (Stream.display_frames->top_field_first);
      }
    }
    else
    {
      /* When decoding a field, always display the field of the opposite polarity */
      static_SetNextDisplayField (Stream.decode_frames->lastpic->picture_structure == BOTTOM_FIELD_PICTURE);
    }
  }
}

/******	static_WriteDecodeInstruction() ************************************

Purpose:	Unconditionally writes the next task instruction, as a decode task
In:		Whether to set the FIS bit, to cause the instruction to be executed immediately

***************************************************************************/

static void static_WriteDecodeInstruction (bool FIS)
{
  dprintf (("IRQ", "WriteDecodeInstruction%s\n", FIS ? ", FIS" : ""));
  /* debug-only code for stopping decode after a fixed number of pictures
  {
    static int count = 12;
    if (count-- == 0)
    {
      WRITE_VID_ITM(0);
      return;
    }
  } */
  VID_PFH = (Stream.decode_frames->lastpic->backward_horizontal_f_code << 4) | Stream.decode_frames->lastpic->forward_horizontal_f_code;
  VID_PFV = (Stream.decode_frames->lastpic->backward_vertical_f_code << 4) | Stream.decode_frames->lastpic->forward_vertical_f_code;
  VID_PPR1 = (Stream.decode_frames->lastpic->picture_coding_type << 4) | (Stream.decode_frames->lastpic->intra_dc_precision << 2) | Stream.decode_frames->lastpic->picture_structure;
  VID_PPR2 = Stream.decode_frames->lastpic->picture_flags.byte;
  VID_TIS = (Stream.decode_frames->seq.mpeg2 ? VID_TIS_MP2 : 0) | ((Stream.next_picture_structure != ps_frame_picture || FIS) ? 0 : VID_TIS_RPT) | (FIS ? VID_TIS_FIS : 0) | VID_TIS_EXE;
  Stream.vid_flags.last_instruction_was_a_decode = true;
  
  if (Stream.next_picture_structure != ps_second_field_picture)
  {
    /* If we just finished decoding a B-frame, remove it from the decoding list, since it's never going to be used as a predictor */
    if (Stream.decode_frames->decode_link != NULL) /* exempt the first frame, since there's no previous in this case! */
    {
      if (Stream.decode_frames->decode_link->lastpic->picture_coding_type == B_PICTURE)
      {
        dprintf (("IRQ", "WriteDecodeInstruction: removing B-frame %d from decode list\n", ((int) Stream.decode_frames->decode_link - (int) Stream.frame) / sizeof (frame_t)));
        static_RemoveFrameFromList (Stream.decode_frames->decode_link, true);
      }
    }
  }
  
  /* Set state flags/variables */
  Stream.vid_flags.final_instruction_has_been_written_during_this_AU = true; /* but not if we're to be followed by skip(s) */
  Stream.prev_picture_structure = Stream.current_picture_structure;
  Stream.current_picture_structure = Stream.next_picture_structure;
}

/******	static_WriteSkipInstruction() **************************************

Purpose:	Unconditionally writes the next task instruction, as a skip task
In:		Whether to set the FIS bit, to cause the instruction to be executed immediately

***************************************************************************/

static void static_WriteSkipInstruction (bool FIS)
{
  dprintf (("IRQ", "WriteSkipInstruction%s\n", FIS ? ", FIS" : ""));
  VID_TIS = (3 << VID_TIS_SKP_SHIFT) | (FIS ? VID_TIS_FIS : 0) | VID_TIS_EXE; 
  Stream.vid_flags.last_instruction_was_a_decode = false;
}

/******	static_RemoveFrameFromList() ***************************************

Purpose:	Removes a frame struct from the decode or display frames lists;
		if it is no longer on either, then places it on the unused list
In:		Pointer to frame struct to remove; which list to remove it from

***************************************************************************/

static void static_RemoveFrameFromList (frame_t *removed_frame, bool D_list)
{
  frame_t *previous = NULL;
  frame_t *rover;
  if (D_list)
  {
    rover = Stream.decode_frames;
    while (rover != removed_frame && rover != NULL)
    {
      previous = rover;
      rover = rover->decode_link;
    }
    if (rover == NULL)
    {
      dprintf (("IRQ", "RemoveFrameFromList: WARNING - attempt to remove a frame from a list it wasn't on\n"));
      return; /* should never happen if I get the rest of the code right! */
    }
    if (previous == NULL) Stream.decode_frames = removed_frame->decode_link;
    else previous->decode_link = removed_frame->decode_link;
    removed_frame->decode_link = NULL;
    removed_frame->on_decode_list = false;
#ifdef DEBUGLIB
    {
      frame_t *frame = Stream.decode_frames;
      int items = 0;
      dprintf (("IRQ", "RemoveFrameFromList: decode frames list = "));
      while (frame != NULL)
      {
        dprintf (("IRQ", "%d ", ((int) frame - (int) Stream.frame) / sizeof (frame_t)));
        frame = frame->decode_link;
        if (++items > 10) break;
      }
    }
    dprintf (("IRQ", "\n"));
#endif
  }
  else
  {
    rover = Stream.display_frames;
    while (rover != removed_frame && rover != NULL)
    {
      previous = rover;
      rover = rover->display_link;
    }
    if (rover == NULL)
    {
      dprintf (("IRQ", "RemoveFrameFromList: WARNING - attempt to remove a frame from a list it wasn't on\n"));
      return; /* should never happen if I get the rest of the code right! */
    }
    if (previous == NULL) Stream.display_frames = removed_frame->display_link;
    else previous->display_link = removed_frame->display_link;
    removed_frame->display_link = NULL;
    removed_frame->on_display_list = false;
#ifdef DEBUGLIB
    {
      frame_t *frame = Stream.display_frames;
      int items = 0;
      dprintf (("IRQ", "RemoveFrameFromList: display frames list = "));
      while (frame != NULL)
      {
        dprintf (("IRQ", "%d ", ((int) frame - (int) Stream.frame) / sizeof (frame_t)));
        frame = frame->display_link;
        if (++items > 10) break;
      }
    }
    dprintf (("IRQ", "\n"));
#endif
  }
  
  if (!removed_frame->on_decode_list && !removed_frame->on_display_list)
  {
    /* Move frame struct to unused list */
    dprintf (("IRQ", "RemoveFrameFromList: returning frame %d to unused list\n", ((int) removed_frame - (int) Stream.frame) / sizeof (frame_t)));
    removed_frame->decode_link = Stream.unused_frames;
    Stream.unused_frames = removed_frame;
    /* And if its frame_buffer usage count goes to zero, move that to the unused frame_buffer struct list too */
    removed_frame->frame_buffer->usage_count --;
    if (removed_frame->frame_buffer->usage_count == 0)
    {
      removed_frame->frame_buffer->unused_link = Stream.unused_frame_buffers;
      Stream.unused_frame_buffers = removed_frame->frame_buffer;
    }
  }
}

/******	static_SetNextDisplayField() ***************************************

Purpose:	Sets up which field (top or bottom) is displayed,
		independently of the vertical filter configuration
In:		Top (or not-bottom) field flag
Notes:		Setting is not latched until the next VSync

***************************************************************************/

static void static_SetNextDisplayField (bool top_field)
{
  static const unsigned char dam_fld[7][2] =
  {
    {
      0 * (VID_DCF_FLD>>8) | 6 << (VID_DCF_DAM_SHIFT-8),
      1 * (VID_DCF_FLD>>8) | 6 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 2 << (VID_DCF_DAM_SHIFT-8),
      1 * (VID_DCF_FLD>>8) | 2 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 3 << (VID_DCF_DAM_SHIFT-8),
      1 * (VID_DCF_FLD>>8) | 7 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 3 << (VID_DCF_DAM_SHIFT-8),
      1 * (VID_DCF_FLD>>8) | 3 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 4 << (VID_DCF_DAM_SHIFT-8),
      0 * (VID_DCF_FLD>>8) | 4 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 0 << (VID_DCF_DAM_SHIFT-8),
      0 * (VID_DCF_FLD>>8) | 0 << (VID_DCF_DAM_SHIFT-8)
    },
    {
      0 * (VID_DCF_FLD>>8) | 0 << (VID_DCF_DAM_SHIFT-8),
      1 * (VID_DCF_FLD>>8) | 0 << (VID_DCF_DAM_SHIFT-8)
    }
  };
  dprintf (("IRQ", "SetNextDisplayField: %s\n", top_field ? "top" : "bottom"));
  VID_DCF_8 = VID_DCF_8 & ~0x0F | dam_fld [VID_DCF_0 & 0x7] [top_field == false];
}
