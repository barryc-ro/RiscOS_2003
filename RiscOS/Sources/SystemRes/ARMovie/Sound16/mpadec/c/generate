#if 0
#define DIAGS 1
#endif

#ifdef TEST
#define DIAGS 1
#endif
/* generate.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#include "mpa.h"
#include "fxptparams.h"
#include "soundtypes.h"
#include "sdata.h"
#include "filter.h"
#ifdef DIAGS
#include "frame.h"
#include "tables.h"
#include "bits.h"
#include "decode.h"
#endif
#include "generate.h"
#include "use_asm.h"


#define MAXGROUP 1			/* might be 3, 6 or even 12 */


#if 0
#define diags 2
#endif

#define CBITS	21			/* total bits of coefficient in 2's comp fixed-point */
#define CIBITS	5			/* max int part is 10 -> sign(0)+4 bits before point */
#define CFBITS	(CBITS-CIBITS)		/* number of bits in fractional part */
#define CLFBITS	10			/* do lowest bits (all in frac part) separately */
#define CHFBITS (CFBITS-CLFBITS)	/* how many fraction bits in upper part */

/* Convert a floating point constant to its CIBITS.CFBITS fixed-point representation */
#define Cx(c) ((int32)((c) * (1 << CFBITS) + 0.5))

#define SBITS	20			/* total bits in intermediate results */
#define SIBITS  5			/* number of bits whole part, 2's comp: +/-15.xx max */
#define SFBITS  (SBITS-SIBITS)		/* number of fraction bits */

/*
 * Macro to re-position the point for different
 * scale factors: does rounding for down-shifts
 */
#define FXPTADJ(v,old,new) \
    do \
    { \
	if ((old) < (new)) \
	    v <<= ((old) < (new)) ? (new)-(old) : 0; \
	else if ((old) > (new)) \
	    v = ((v) + (1 << ((old) <= (new) ? 0 : (old)-(new)-1))) \
		>> ((old) > (new) ? (old)-(new) : 0); \
    } while (0)

#if FBITS != SFBITS
# error "CAN'T COPE WITH FBITS != SFBITS!!!"
#define FBITS_TO_SFBITS(v) FXPTADJ(FBITS, SFBITS)
#else
#define FBITS_TO_SFBITS(v) do { } while (0)
#endif

/*
 * Consistency checks: must allow for 2-stage multiplication of
 * intermediate results by CIBITS.CLFBITS and then by .(z+s+CLFBITS)
 */
#if SBITS+CIBITS+CHFBITS > 32 || SBITS+1+CLFBITS > 32
# error !  fixed point scaling is faulty
#endif

/* Coefficients */
/* coeff_64[i] = 1/(2cos((2i+1)pi/64)), i = 0..15 */
#define C64_00	Cx( 0.50060299823519630134)
#define C64_01	Cx( 0.50547095989754365998)
#define C64_02	Cx( 0.51544730992262454697)
#define C64_03	Cx( 0.53104259108978417447)
#define C64_04	Cx( 0.55310389603444452782)
#define C64_05	Cx( 0.58293496820613387367)
#define C64_06	Cx( 0.62250412303566481615)
#define C64_07	Cx( 0.67480834145500574602)

#define C64_08	Cx( 0.74453627100229844977)
#define C64_09	Cx( 0.83934964541552703873)
#define C64_10	Cx( 0.97256823786196069368)
#define C64_11	Cx( 1.16943993343288495513)
#define C64_12	Cx( 1.48416461631416627719)
#define C64_13	Cx( 2.05778100995341155075)
#define C64_14	Cx( 3.40760841846871878544)
#define C64_15	Cx(10.19000812354805680808)
/* coeff_32[i] = 1/(2cos((2i+1)pi/32)), i = 0..7 */
#define C32_0	Cx (0.50241928618815570551)
#define C32_1	Cx (0.52249861493968888063)
#define C32_3	Cx (0.64682178335999012954)
#define C32_2	Cx (0.56694403481635770368)
#define C32_7	Cx (5.10114861868916385728)
#define C32_6	Cx (1.72244709823833392773)
#define C32_4	Cx (0.78815462345125022472)
#define C32_5	Cx (1.06067768599034747133)
/* coeff_16[i] = 1/(2cos((2i+1)pi/16)), i = 0..3 */
#define C16_0	Cx (0.50979557910415916894)
#define C16_1	Cx (0.60134488693504528054)
#define C16_3	Cx (2.56291544774150617864)
#define C16_2	Cx (0.89997622313641570462)
/* coeff_8[i] =  1/(2cos((2i+1)pi/8)), i = 0..2 */
#define C8_0    Cx (0.54119610014619698439)
#define C8_1    Cx (1.30656296487637652781)
/* coeff_4 =  1/(2cos(pi/4)) */
#define C_4 Cx (0.70710678118654752440)


const int32 bglcoeffs[16+8+4+2+1] =
{
    /* coeff_64[], reordered */
    C64_00, C64_01, C64_03, C64_02, C64_07, C64_06, C64_04, C64_05,
    C64_15, C64_14, C64_12, C64_13, C64_08, C64_09, C64_11, C64_10,
    /* coeff_32[], reordered */
    C32_0, C32_1, C32_3, C32_2, C32_7, C32_6, C32_4, C32_5,
    /* coeff_16[], reordered */
    C16_0, C16_1, C16_3, C16_2,
    /* coeff_8[], order unmodified */
    C8_0, C8_1,
    /* coeff_4 */
    C_4
};


/*
 * Multiply a fixed-point coefficient c (CIBITS.CFBITS) by
 * a fixed-point value v in working precision (SIBITS.SFBITS).
 */
#if 0
/* out-of-line implementation for reference */
static int32 fixmult (int32 v, int32 c)
{
    int32 clo, chi, pp1, pp2, prod;
    chi = c >> CLFBITS;				/* get high part of c */
    clo = c ^ (chi << CLFBITS);			/* and low part of c  */
    /*
     * First multiply v by by low part of c:
     *
     *	SIBITS.SFBITS * .CFBITS -> (SIBITS).(SFBITS+CFBITS)
     *
     * This produces a result apparently having SIBITS+SFBITS+CFBITS total,
     * but in fact only the lowest CLFBITS of the RHS are non-zero so it
     * would only overflow if SIBITS+SFBITS+CLFBITS > 32, and we ensure
     * that this is not so.  Well, in fact we are a little more careful,
     * and to avoid problems with combining the 2's complement LHS with
     * what is an unsigned RHS (see extraction of low part of coeff, above)
     * we allow for an extra sign bit (always 0) at the top of the low
     * part, giving 1+CFBITS as the effective size of the RHS.  Hence we
     * require that SIBITS+SFBITS+1+CLFBITS <= 32; this is checked above.
     */
    pp1 = clo * v;
    /*
     * To maximise accuracy, add the partial products at the highest
     * precision we can.  This involves scaling the low part down to the
     * current precision of the high part, which is SFBITS+CHFBITS.
     */
    FXPTADJ(pp1, SFBITS+CFBITS, SFBITS+CHFBITS);
    /*
     * Multiply v by high part of coefficient:
     *
     *      SIBITS.SFBITS * CIBITS.CHFBITS -> (SIBITS+CIBITS).(SFBITS+CHFBITS)
     *
     * total bits must be <= 32, of course.
     */
    pp2 = chi * v;
    /*
     * Now add partial products in same precision to give the full product.
     */
    prod = pp1 + pp2;
    /*
     * Scale product to working precision (.SFBITS of fraction).
     */
    FXPTADJ(prod, SFBITS+CHFBITS, SFBITS);
    /*
     * And at that, we're done.
     */
    return prod;
}
#endif
#define FIXMULT(r, c, v) \
    do { \
	int32 v_ = v, c_ = c; \
	int32 clo_, chi_, pp1_, pp2_, prod_; \
	chi_ = c_ >> CLFBITS; \
	clo_ = c_ ^ (chi_ << CLFBITS); \
	pp1_ = clo_ * v_; \
	FXPTADJ(pp1_, SFBITS+CFBITS, SFBITS+CHFBITS); \
	pp2_ = chi_ * v_; \
	prod_ = pp1_ + pp2_; \
	FXPTADJ(prod_, SFBITS+CHFBITS, SFBITS); \
	r = prod_; \
    } while (0)
#define FIXMULT2(v, cl, ch) \
    do { \
	int32 pp1_, pp2_, prod_; \
	pp1_ = (cl) * v; \
	FXPTADJ(pp1_, SFBITS+CFBITS, SFBITS+CHFBITS); \
	pp2_ = (ch) * v; \
	prod_ = pp1_ + pp2_; \
	FXPTADJ(prod_, SFBITS+CHFBITS, SFBITS); \
	v = prod_; \
    } while (0)



#if 0
static void sum4 (int32 a[4])
{
    int32 a0, a1, a2, a3;
    a0 = a[0];
    a1 = a[1];
    a2 = a[2];
    a3 = a[3];
    a[0] = a0      + a2 + a3;
    a[1] =    + a1 + a2 + a3;
    a[2] =    + a1      + a3;

/*  a[3] =                a3; */
}
#endif

#if USE_ASM || 1
extern void sum8_asm (int32 a[8]);
#define sum8(a) sum8_asm(a)
#else
static void sum8 (int32 a[8])
{
    int32 a0, a1, a2, a3, a4, a5, a6, a7;
    a0 = a[0];
    a1 = a[1];
    a2 = a[2];
    a3 = a[3];
    a4 = a[4];
    a5 = a[5];
    a6 = a[6];
    a7 = a[7];
    a[0] = (0 + a0                + a4      + a6 + a7);
    a[1] = (0           + a2 + a3 + a4      + a6 + a7);
    a[2] = (0           + a2 + a3      + a5 + a6 + a7);
    a[3] = (0      + a1                + a5 + a6 + a7);
    a[4] = (0      + a1                + a5      + a7);
    a[5] = (0                + a3      + a5      + a7);
    a[6] = (0                + a3                + a7);
/*  a[7] = (0                                    + a7); */
}
#endif


#if 0
static void sum8xx (int32 a[8])
{
    a6 += a7;
    a4 += a6;
    a2 += a3;
    a6 += a5;
    a5 += a7;
    a9 = a3 + a7;
    a8 = a3 + a5;
    a7 = a1 + a5;
    a5 = a2 + a6;
    a6 = a1 + a6;
    a2 = a2 + a4;
    a0 = a0 + a4;
    a[0] = a0;
    a[1] = a2;
    a[2] = a5;
    a[3] = a6;
    a[4] = a7;
    a[5] = a8;
    a[6] = a9;
}
#endif

static void sum16 (int32 a[16])
{
    int32 u0;
    int32 t0, t1;
    int32 s0, s1, s2, s3;
    int32 r0, r1, r2, r3, r4, r5, r6, r7;


    u0 = a[ 1];
    t0 = a[ 2];
    t1 = a[ 3];
    s0 = a[ 4];
    s1 = a[ 5];
    s2 = a[ 6];
    s3 = a[ 7];
    a[ 4] = t0 + t1;
    s2 += s3;
    a[ 2] = s0 + s2;
    a[ 6] = s1 + s2;
    r0 = a[ 8];
    r1 = a[ 9];
    r2 = a[10];
    r3 = a[11];
    r4 = a[12];
    a[10] = s1 + s3;
    a[ 8] = u0;
    a[12] = t1;
    r5 = a[13];
    r6 = a[14];
    r7 = a[15];
    a[14] = s3;
    r6 += r7;
    r4 += r6;
    a[ 1] = r0 + r4;
    r2 += r3;
    a[ 3] = r2 + r4;
    r6 += r5;
    a[ 5] = r2 + r6;
    a[ 7] = r1 + r6;
    r5 += r7;
    a[ 9] = r1 + r5;
    a[11] = r3 + r5;
    a[13] = r3 + r7;
}

#if SFBITS != 15
# error SFBITS definition broken!
#endif

#define GSIZE 16

static void bglgen_out_M (int32 a[32], sdata_M *outx, sdata_M *outy)
{
    int32 x;
    int32 *b = a + 16;
#define X(n) outx[n*GSIZE*2]
#define Y(n) outy[n*GSIZE*2]
    X(15) = (x = b[15]);   Y(15) = -(x + a[ 1]);
    X(14) = (x = b[14]);   Y(14) = -(x + a[ 2]);
    X(13) = (x = b[13]);   Y(13) = -(x + a[ 3]);
    X(12) = (x = b[12]);   Y(12) = -(x + a[ 4]);
    X(11) = (x = b[11]);   Y(11) = -(x + a[ 5]);
    X(10) = (x = b[10]);   Y(10) = -(x + a[ 6]);
    X( 9) = (x = b[ 9]);   Y( 9) = -(x + a[ 7]);
    X( 8) = (x = b[ 8]);   Y( 8) = -(x + a[ 8]);
    X( 7) = (x = b[ 7]);   Y( 7) = -(x + a[ 9]);
    X( 6) = (x = b[ 6]);   Y( 6) = -(x + a[10]);
    X( 5) = (x = b[ 5]);   Y( 5) = -(x + a[11]);
    X( 4) = (x = b[ 4]);   Y( 4) = -(x + a[12]);
    X( 3) = (x = b[ 3]);   Y( 3) = -(x + a[13]);
    X( 2) = (x = b[ 2]);   Y( 2) = -(x + a[14]);
    X( 1) = (x = b[ 1]);   Y( 1) = -(x + a[15]);


    X( 0) = (x = b[ 0]);   Y( 0) = -(x);

    X(16) = 0;             Y(16) = -(a[0]);

#undef X
#undef Y
}

void bglgen_M (fsamp_M *y, sdata_M *outx, sdata_M *outy)
{
    fsamp_M b[32], a[32];
    const int32 *cp;
    int i;
    fsamp_M *ip;
    cp = bglcoeffs;
    for (i = 0; i < 2; ++i)
    {
	do
	{
	    int32 c = *cp++;
	    int32 p = y[0], q = y[1], v;
	    y += 2;
	    v = p + q;				/* produce sum for next stage */
	    FBITS_TO_SFBITS (v);		/* scale to working precision */
	    a[i] = v;				/* store away */
	    v = p - q;				/* produce difference */
	    FBITS_TO_SFBITS (v);		/* scale to working precision */
	    FIXMULT (v, c, v);
	    a[i+2] = v;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = a;
    for (i = 0; i < 2; ++i)
    {
	int32 clo, chi;
	do
	{
	    int32 p = ip[0], q = ip[1], v;
	    ip += 2;
	    if ((i & (1 << 2)) == 0)
	    {
		clo = *cp++;				/* coeff_32[i] */
		chi  = clo >> CLFBITS;			/* get high part of c */
		clo ^= chi << CLFBITS;			/* and low part of c  */
	    }
	    b[i] = p + q;
	    v = p - q;
	    FIXMULT2 (v, clo, chi);
	    b[i+2] = v;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = b;
    for (i = 0; i < 2; ++i)
    {
	int32 clo, chi;
	do
	{
	    int32 p = ip[0], q = ip[1], v;
	    ip += 2;
	    if ((i & (3 << 2)) == 0)
	    {
		clo = *cp++;				/* coeff_32[i] */
		chi  = clo >> CLFBITS;			/* get high part of c */
		clo ^= chi << CLFBITS;			/* and low part of c  */
	    }
	    a[i] = p + q;
	    v = p - q;
	    FIXMULT2 (v, clo, chi);
	    a[i+2] = v;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = a;
    i = 0;
    do
    {
	int32 clo, chi;
	clo = *cp++;
	chi  = clo >> CLFBITS;			/* get high part of c */
	clo ^= chi << CLFBITS;			/* and low part of c  */
	do
	{
	    int32 p = ip[0], q = ip[1], v;
	    ip += 2;
	    b[i] = p + q;
	    v = p - q;
	    FIXMULT2 (v, clo, chi);
	    b[i+2] = v;
	} while ((i += 4) < 32);
	i = i - 32 + 1;
    } while (i < 2);

    /* Final stage... */
    {
	int j;
	ip = b;
	for (j = 0; j < 16; j++)
	{
	    int32 p = ip[0], q = ip[1], v;
	    ip += 2;
	    a[j] = p + q;
	    v = p - q;
	    FIXMULT2 (v, C_4 & ~((~0) << CLFBITS), C_4 >> CLFBITS);
	    a[16+j] = v;
	}
    }
    /* Preparatory work for final stage */
    sum16 (&a[ 0]); sum16 (&a[16]);
    bglgen_out_M (a, outx, outy);
}


#define XSIZE (GSIZE+MAXGROUP-1)

#if USE_ASM
extern void bglgen_S (fsamp_S *y, sdata_S *outx, sdata_S *outy);
#else
void bglgen_S (fsamp_S *y, sdata_S *outx, sdata_S *outy)
{
    const int32 *cp;
    int i;
    struct sp { fsamp_M l, r; };
    union data
    {
	fsamp_M r[2][32];
	struct sp s[32];
	fsamp_M t[32][2];
	fsamp_M c[32*2];
    } a, b;
    struct sp *ip;
    int32 m, xl, xr;
    cp = bglcoeffs;
    for (i = 0; i < 2; ++i)
    {
	do
	{
	    int32 clo, chi, vl, vr;
	    int32 pl = y[0].p.l, pr = y[0].p.r, ql = y[1].p.l, qr = y[1].p.r;
	    y += 2;
	    clo = *cp++;		/* coeff_64[x] */
	    chi  = clo >> CLFBITS;	/* get high part of c */
	    clo ^= chi << CLFBITS;	/* and low part of c  */

	    vl = pl + ql;		/* produce sum for next stage */
	    vr = pr + qr;
#if 0
	    FBITS_TO_SFBITS (vl);	/* scale to working precision */
	    FBITS_TO_SFBITS (vr);
#endif
	    a.s[i].l = vl;		/* store away */
	    a.s[i].r = vr;

	    vl = pl - ql;		/* produce difference */
	    vr = pr - qr;
#if 0
	    FBITS_TO_SFBITS (vl);	/* scale to working precision */
	    FBITS_TO_SFBITS (vr);
#endif
	    FIXMULT2 (vl, clo, chi);	/* multiply by appropriate coeff */
	    FIXMULT2 (vr, clo, chi);
	    a.s[i+2].l = vl;
	    a.s[i+2].r = vr;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = a.s;
    for (i = 0; i < 2; ++i)
    {
	int32 clo, chi;
	do
	{
	    int32 pl = ip[0].l, pr = ip[0].r, ql = ip[1].l, qr = ip[1].r, vl, vr;
	    ip += 2;
	    if ((i & (1 << 2)) == 0)
	    {
		clo = *cp++;		/* coeff_32[x] */
		chi  = clo >> CLFBITS;	/* get high part of c */
		clo ^= chi << CLFBITS;	/* and low part of c  */
	    }
	    b.s[i].l = pl + ql;
	    b.s[i].r = pr + qr;
	    vl = pl - ql;
	    vr = pr - qr;
	    FIXMULT2 (vl, clo, chi);
	    FIXMULT2 (vr, clo, chi);
	    b.s[i+2].l = vl;
	    b.s[i+2].r = vr;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = b.s;
    for (i = 0; i < 2; ++i)
    {
	int32 clo, chi;
	do
	{
	    int32 pl = ip[0].l, pr = ip[0].r, ql = ip[1].l, qr = ip[1].r, vl, vr;
	    ip += 2;
	    if ((i & (3 << 2)) == 0)
	    {
		clo = *cp++;		/* coeff_16[x] */
		chi  = clo >> CLFBITS;	/* get high part of c */
		clo ^= chi << CLFBITS;	/* and low part of c  */
	    }
	    a.s[i].l = pl + ql;
	    a.s[i].r = pr + qr;
	    vl = pl - ql;
	    vr = pr - qr;
	    FIXMULT2 (vl, clo, chi);
	    FIXMULT2 (vr, clo, chi);
	    a.s[i+2].l = vl;
	    a.s[i+2].r = vr;
	} while ((i += 4) < 32);
	i = i - 32;
    }
    ip = a.s;
    for (i = 0; i < 2; ++i)
    {
	int32 clo, chi;
	clo = *cp++;			/* coeff_8[i] */
	chi  = clo >> CLFBITS;		/* get high part of c */
	clo ^= chi << CLFBITS;		/* and low part of c  */
	do
	{
	    int32 pl = ip[0].l, pr = ip[0].r, ql = ip[1].l, qr = ip[1].r, vl, vr;
	    ip += 2;
	    b.s[i].l = pl + ql;
	    b.s[i].r = pr + qr;
	    vl = pl - ql;
	    vr = pr - qr;
	    FIXMULT2 (vl, clo, chi);
	    FIXMULT2 (vr, clo, chi);
	    b.s[i+2].l = vl;
	    b.s[i+2].r = vr;
	} while ((i += 4) < 32);
	i = i - 32;
    }

    /* Final stage of regular synthesis */
    ip = b.s;
    for (i = 0; i < 16; i++)
    {
	int32 pl = ip[0].l, pr = ip[0].r, ql = ip[1].l, qr = ip[1].r, vl, vr;
	ip += 2;
	a.r[0][i] = pl + ql;
	a.r[1][i] = pr + qr;

	vl = pl - ql;
	vr = pr - qr;
	FIXMULT2 (vl, C_4 & ~((~0) << CLFBITS), C_4 >> CLFBITS);
	FIXMULT2 (vr, C_4 & ~((~0) << CLFBITS), C_4 >> CLFBITS);
	a.r[0][16+i] = vl;
	a.r[1][16+i] = vr;
    }
    /* Do larger lumps of irregular combination in a loop */
    for (i = 0; i < 4; ++i)
    {
	int32 *v = &a.c[2+i*16];
	int32 a0, a1, a2, a3, a4, a5, a6, a7;
	a0 = v[0];
	a1 = v[1];
	v[0] = a0 + a1;
	v += 2;
	a0 = v[0];
	a1 = v[1];
	a2 = v[2];
	a3 = v[3];
	v[0] = a0      + a2 + a3;
	v[1] =    + a1 + a2 + a3;
	v[2] =    + a1      + a3;
	/*  v[3] =                a3; */
	v += 4;
	a0 = v[0];
	a1 = v[1];
	a2 = v[2];
	a3 = v[3];
	a4 = v[4];
	a5 = v[5];
	a6 = v[6];
	a7 = v[7];
	v[0] = (0 + a0                + a4      + a6 + a7);
	v[1] = (0           + a2 + a3 + a4      + a6 + a7);
	v[2] = (0           + a2 + a3      + a5 + a6 + a7);
	v[3] = (0      + a1                + a5 + a6 + a7);
	v[4] = (0      + a1                + a5      + a7);
	v[5] = (0                + a3      + a5      + a7);
	v[6] = (0                + a3                + a7);
    /*  v[7] = (0                                    + a7); */
    }
    m = i | 0xFFFF;
    outx += XSIZE*2*(2*7+1);
    outy += XSIZE*2*(2*7+1);
    for (i = 7; i >= 0; --i)
    {
	xl = a.r[0][24+i];        xr = a.r[1][24+i];
	outx->x =  (xl) & m | (xr) << 16;   outx -= XSIZE*2*2;
	xl = xl + a.r[0][ 15-i];  xr = xr + a.r[1][ 15-i];
	outy->x = -(xl) & m | -(xr) << 16;  outy -= XSIZE*2*2;
    }
    outx += XSIZE*2*(4*3+2) + XSIZE*2*1;
    outy += XSIZE*2*(4*3+2) + XSIZE*2*1;
    for (i = 3; i >= 0; --i)
    {
	xl = a.r[0][20+i]; 	xr = a.r[1][20+i];
	outx->x =  (xl) & m | (xr) << 16;  outx -= XSIZE*2*4;
	xl = xl + a.r[0][ 7-i];	xr = xr + a.r[1][ 7-i];
	outy->x = -(xl) & m | -(xr) << 16; outy -= XSIZE*2*4;
    }
    outx += XSIZE*2*(8*1+4) + XSIZE*2*2;
    outy += XSIZE*2*(8*1+4) + XSIZE*2*2;
    for (i = 1; i >= 0; --i)
    {
	xl = a.r[0][18+i];     xr = a.r[1][18+i];
	outx->x = (xl) & m | (xr) << 16;    outx -= XSIZE*2*8;
	xl += a.r[0][3-i];     xr += a.r[1][3-i];
	outy->x = -(xl) & m | -(xr) << 16;  outy -= XSIZE*2*8;
    }
    outx += XSIZE*2*4;
    outy += XSIZE*2*4;
    xl = a.r[0][17];      xr = a.r[1][17];
    outx[XSIZE*2*8].x = (xl) & m | (xr) << 16;
    xl = xl + a.r[0][1];  xr = xr + a.r[1][1];
    outy[XSIZE*2*8].x = -(xl) & m | -(xr) << 16;

#if 0
    outx[XSIZE*2*16].x = 0;
#endif
    xl = a.r[0][0];  xr = a.r[1][0];
    outy[XSIZE*2*16].x = -(xl) & m | -(xr) << 16;

    xl = a.r[0][16]; xr = a.r[1][16];
    outx[XSIZE*2*0].x =  (xl) & m |  (xr) << 16;
    outy[XSIZE*2*0].x = -(xl) & m | -(xr) << 16;
}
#endif


/*
 * SPARE *MUST* be defined as an even number > 0, but its value
 * is otherwise arbitrary: memmove happens once every SPARE
 * calls here.
 */
#define SPARE 128

void generate_mono (fsamp_M fsamp[32], int16 *samples, int ngroup)
{
    static struct synbuf
    {
	int pos;
	sdata_M buf[SPARE+(16+1)*2*XSIZE];
    } sbuf ={1};
    struct synbuf *sp;
    int pos;
    sdata_M *bp, *outx, *outy;

    sp = &sbuf;
    pos = sp->pos;
    if (pos == 0)
    {
	memmove (&sp->buf[SPARE], &sp->buf[0], (16+1)*2*XSIZE*sizeof(sp->buf[0]));
	pos = SPARE;
    }
    bp = &sp->buf[pos];
    sp->pos = pos - 1;

    if ((pos & 1) == 0)
    {
	outx = bp; outy = bp + XSIZE;
    }
    else
    {
	outy = bp; outx = bp + XSIZE;
    }
    bglgen_M (fsamp, outx, outy);
    filter_M (outx, samples);

#if 0 /* defined(DIAGS) && 0 */
    if (diags > 1)
    {
	int i;
	fprintf (stderr, "gen: [");
	for (i = 0; i < 17; ++i)
	    fprintf (stderr, " %d", outx[XSIZE*2*i]);
	fprintf (stderr, " --- ");
	for (i = 0; i < 17; ++i)
	    fprintf (stderr, " %d", outy[XSIZE*2*i]);
	fprintf (stderr, " ]\n");
    }
#endif
#if 0 || (defined(DIAGS) && 0)
    if (diags)
    {
	int i;
	fprintf (stderr, "out: [");
	for (i = 0; i < 32; ++i)
	    fprintf (stderr, " %d", samples[i]);
	fprintf (stderr, " ]\n");
    }
#endif
}

void generate_stereo (fsamp_S fsamp[32], int16 *samples, int ngroup)
{
    static struct synbuf
    {
	int pos;
	sdata_S buf[SPARE+(16+1)*2*XSIZE];
    } sbuf ={1};
    struct synbuf *sp;
    int pos;
    sdata_S *bp;

//#if defined(DIAGS) && 1
//    if (diags > 1)
//    {
//	int i;
//	fprintf (stderr, "fsamp: [");
//	for (i = 0; i < 32; ++i)
//	    if (diags == 3)
//		fprintf (stderr, " %d", fsamp[i].p.l);
//	    else if (diags == 4)
//		fprintf (stderr, " %d", fsamp[i].p.r);
//	    else
//		fprintf (stderr, " %d/%d", fsamp[i].p.l, fsamp[i].p.r);
//	fprintf (stderr, " ]\n");
//    }
//#endif

    sp = &sbuf;
    pos = sp->pos;
    if (pos == 0)
    {
	memmove (&sp->buf[SPARE], &sp->buf[0], (16+1)*2*XSIZE*sizeof(sp->buf[0]));
	pos = SPARE;
    }
    bp = &sp->buf[pos];
    sp->pos = pos - 1;
    if (pos & 1)
    {
	bp += XSIZE;
	bglgen_S (fsamp, bp, bp-XSIZE);
    }
    else
	bglgen_S (fsamp, bp, bp+XSIZE);
    filter_S (bp, samples);
//#if defined(DIAGS) && 1
//    if (diags > 1)
//    {
//	int i;
//	fprintf (stderr, "gen: [");
//	for (i = 0; i < 17; ++i)
//	    if (diags == 3)
//		fprintf (stderr, " %d", bp[XSIZE*(2*i + (pos&1))].p.l);
//	    else if (diags == 4)
//		fprintf (stderr, " %d", bp[XSIZE*(2*i + (pos&1))].p.r);
//	    else
//		fprintf (stderr, " %d/%d",
//			 bp[XSIZE*(2*i + (pos&1))].p.l,
//			 bp[XSIZE*(2*i + (pos&1))].p.r);
//	fprintf (stderr, " --- ");
//	for (i = 0; i < 16; ++i)
//	    if (diags == 3)
//		fprintf (stderr, " %d", bp[XSIZE*(2*i + 1-(pos&1))].p.l);
//	    else if (diags == 4)
//		fprintf (stderr, " %d", bp[XSIZE*(2*i + 1-(pos&1))].p.r);
//	    else
//		fprintf (stderr, " %d/%d",
//			 bp[XSIZE*(2*i + 1-(pos&1))].p.l,
//			 bp[XSIZE*(2*i + 1-(pos&1))].p.r);
//
//	fprintf (stderr, " ]\n");
//    }
//    if (diags)
//    {
//	int i;
//	fprintf (stderr, "out: [");
//	for (i = 0; i < 32; ++i)
//	    if (diags == 3)
//		fprintf (stderr, " %d", samples[i*2+0]);
//	    else if (diags == 4)
//		fprintf (stderr, " %d", samples[i*2+1]);
//	    else
//		fprintf (stderr, " %d/%d", samples[i*2+1], samples[i*2+0]);
//	fprintf (stderr, " ]\n");
//    }
//#endif
}


