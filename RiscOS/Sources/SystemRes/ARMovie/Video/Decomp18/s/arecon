        GET     Hdr:ListOpts
        GET     Hdr:Macros
        GET     Hdr:APCS.<APCS>
        GET     Hdr:Proc

	AREA	|test$$code|,CODE,READONLY

	IMPORT	startcode
	IMPORT	ashowbits
	IMPORT	agetbits
	IMPORT	syntax_arith_coding
	IMPORT	getheader
	IMPORT	decoder_reset
	IMPORT	memset63
	IMPORT	memset64
	IMPORT	addblock
	IMPORT	mark_top_mvs

        IMPORT  ashowbits
        IMPORT  aflushbits
        IMPORT  agetbits1
        IMPORT  agetbits
	IMPORT	decode_a_symbol

; All the following labels are externally referenced,
; although some of them only in prototype definitions:

        EXPORT  oldrefframe
        EXPORT  newframe
	;EXPORT  edgeframe
        EXPORT  bframe

        EXPORT  trb
        EXPORT  trd
        EXPORT  itrd
        EXPORT  roundtab
        EXPORT  coded_picture_width
        EXPORT  mv_outside_frame
        EXPORT  adv_pred_mode
        EXPORT  reconstruct ; code
	EXPORT	MV
	EXPORT	MV_d3_log
	EXPORT	modemap
	EXPORT	pb_frame
	EXPORT  mb_width
	EXPORT	mb_height

	EXPORT	newgob
	EXPORT	find_pmv ; code which should use __value_in_regs
	EXPORT	reconblock_b ; code
	EXPORT	chrom_width
	EXPORT	long_vectors
	EXPORT	motion_decode ; code which should use __value_in_regs
	EXPORT	motion_decode_noapcs ; code which should use __value_in_regs
	EXPORT	motion_decode_ret ; code

	EXPORT	quants_stored_ptr
	EXPORT	pict_type

	EXPORT	agetMBs_sac ; code
        EXPORT  getblock ; code
        EXPORT  get_sac_block ; code
        EXPORT	base
        EXPORT	bquant
        EXPORT  quant
        EXPORT	zig_zag_scan

	EXPORT	cumf_COD
	EXPORT	cumf_MCBPC
	EXPORT	cumf_MCBPC_intra
	EXPORT	cumf_MODB
	EXPORT	cumf_UVCBPB
	EXPORT	cumf_YCBPB
	EXPORT	cumf_CBPY
	EXPORT	cumf_CBPY_intra
	EXPORT	cumf_DQUANT
	EXPORT	cumf_MVD
	EXPORT	cumf_INTRADC

; The following code labels are only used internally:
;
; arec
; arecc
; arech
; arechc
; arecv
; arecvc
; arec4
; arec4c
;   These are now exit routes for the function arecon_comp, and are entered with
;   r4-r11 and the return address already on the stack.
;
; areco
; areco_add
; arecho
; arecho_add
; arecvo
; arecvo_add
; arec4o
; arec4o_add
;   These are routines that are effectively BL'ed to from recon_comp_obmc.
;   Flag preservation is not required.
;
; arecon_comp
; recon_comp_obmc
;   These were declared as exports in a previous version, so they are still treated
;   here as APCS functions although they're now only called internally.
;
; return
;   This is probably just dead code
;
; BJGA 09-Mar-2001



;rec (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
;		    R0		      R1      R2      R3      [sp,#40]
; 5 args
arec

	AND r9,r0,#3
	MOV r9,r9,LSL #3
	RSB r10,r9,#32

	MOV r12,r6

loop	LDMIA r0,{r4,r5,r6,r7,r8}

	TEQ r9,#0
	MOVNE r4,r4,LSR r9
	ORRNE r4,r4,r5,LSL r10
	MOVNE r5,r5,LSR r9
	ORRNE r5,r5,r6,LSL r10
	MOVNE r6,r6,LSR r9
	ORRNE r6,r6,r7,LSL r10
	MOVNE r7,r7,LSR r9
	ORRNE r7,r7,r8,LSL r10

	STMIA r1,{r4,r5,r6,r7}

	ADD r0,r0,r3
	ADD r1,r1,r2

	SUBS  r12,r12,#1
	BNE  loop

        Return  "r4-r11"

;recc (unsigned char *s, unsigned char *d, int lx, int h));
arecc

	AND r9,r0,#3
	MOV r9,r9,LSL #3
	RSB r10,r9,#32

reccloop
	LDMIA r0,{r4,r5,r12}

	TEQ r9,#0
	MOVNE r4,r4,LSR r9
	ORRNE r4,r4,r5,LSL r10
	MOVNE r5,r5,LSR r9
	ORRNE r5,r5,r12,LSL r10

	STMIA r1,{r4,r5}

	ADD r0,r0,r2
	ADD r1,r1,r2

	SUBS  r6,r6,#1
	BNE  reccloop

        Return  "r4-r11"

;rech (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arech
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        SUB     r0,r0,r3	; r4 = sp - lx2
        CMP     r6,#0
        ; This has the neat side effect of setting the carry flag!
arech_loop
	LDRB	r8,[r0,r3]!

	LDRB	r9,[r0,#1]
	LDRB	r10,[r0,#2]
	ADC	r8,r8,r9
	MOV	r5,r8,LSR #1

	ADC	r9,r10,r9
	MOV	r9,r9,LSR #1
	LDRB	r8,[r0,#3]
	ORR	r5,r5,r9,LSL #8

	ADC	r10,r10,r8
	MOV	r10,r10,LSR #1
	LDRB	r9,[r0,#4]
	ORR	r5,r5,r10,LSL #16

	ADC	r8,r9,r8
	MOV	r8,r8,LSR #1
	LDRB	r10,[r0,#5]
	ORR	r5,r5,r8,LSL #24

	ADC	r9,r9,r10
	LDRB	r8,[r0,#6]
	MOV	r7,r9,LSR #1

	ADC	r10,r8,r10
	MOV	r10,r10,LSR #1
	LDRB	r9,[r0,#7]
	ORR	r7,r7,r10,LSL #8

	ADC	r8,r8,r9
	MOV	r8,r8,LSR #1
	LDRB	r10,[r0,#8]
	ORR	r7,r7,r8,LSL #16

	ADC	r9,r10,r9
	MOV	r9,r9,LSR #1
	LDRB	r8,[r0,#9]
	ORR	r7,r7,r9,LSL #24

	ADC	r10,r10,r8
	LDRB	r9,[r0,#10]
	MOV	r12,r10,LSR #1

	ADC	r8,r9,r8
	MOV	r8,r8,LSR #1
	LDRB	r10,[r0,#11]
	ORR	r12,r12,r8,LSL #8

	ADC	r9,r9,r10
	MOV	r9,r9,LSR #1
	LDRB	r8,[r0,#12]
	ORR	r12,r12,r9,LSL #16

	ADC	r10,r8,r10
	MOV	r10,r10,LSR #1
	LDRB	r9,[r0,#13]
	ORR	r12,r12,r10,LSL #24

	ADC	r8,r8,r9
	LDRB	r10,[r0,#14]
	MOV	lr,r8,LSR #1

	ADC	r9,r10,r9
	MOV	r9,r9,LSR #1
	LDRB	r8,[r0,#15]
	ORR	lr,lr,r9,LSL #8

	ADC	r10,r10,r8
	MOV	r10,r10,LSR #1
	LDRB	r9,[r0,#16]
	ORR	lr,lr,r10,LSL #16

	ADC	r8,r9,r8
	MOV	r8,r8,LSR #1
	ORR	lr,lr,r8,LSL #24

	STMIA	r1,{r5,r7,r12,lr}

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arech_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"

;rechc (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arechc
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        SUB     r0,r0,r3	; r4 = sp - lx2
        CMP     r6,#0
        ; This has the neat side effect of setting the carry flag!
arechc_loop
	LDRB	r12,[r0,r3]!

	LDRB	lr,[r0,#1]
	LDRB	r10,[r0,#2]
	ADC	r12,r12,lr
	MOV	r5,r12,LSR #1

	ADC	lr,r10,lr
	MOV	lr,lr,LSR #1
	LDRB	r12,[r0,#3]
	ORR	r5,r5,lr,LSL #8

	ADC	r10,r10,r12
	MOV	r10,r10,LSR #1
	LDRB	lr,[r0,#4]
	ORR	r5,r5,r10,LSL #16

	ADC	r12,lr,r12
	MOV	r12,r12,LSR #1
	LDRB	r10,[r0,#5]
	ORR	r5,r5,r12,LSL #24

	ADC	lr,lr,r10
	LDRB	r12,[r0,#6]
	MOV	r7,lr,LSR #1

	ADC	r10,r12,r10
	MOV	r10,r10,LSR #1
	LDRB	lr,[r0,#7]
	ORR	r7,r7,r10,LSL #8

	ADC	r12,r12,lr
	MOV	r12,r12,LSR #1
	LDRB	r10,[r0,#8]
	ORR	r7,r7,r12,LSL #16

	ADC	lr,r10,lr
	MOV	lr,lr,LSR #1
	ORR	r7,r7,lr,LSL #24

	STMIA	r1,{r5,r7}

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arechc_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"


;recv (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arecv
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        CMP     r6,#0
        SUB	r0,r0,#4	; allow for the LDMIA/B trick below
        ADD     r3,r0,r3	; r3 = sp - lx2
	AND	r12,r0,#3
	MOV	r12,r12,LSL #3
	RSB	r10,r12,#32
	MOV	r11,#&ff
	ORR	r11,r11,r11,LSL#16
	SUB	r2,r2,#16
        ; This has the neat side effect of setting the carry flag!
arecv_loop
	TEQ	r12,#0
	LDMIB	r0!,{r4,r5,r7}
	MOVNE	r4,r4,LSR r12
	ORRNE	r4,r4,r5,LSL r10
	MOVNE	r5,r5,LSR r12
	ORRNE	r5,r5,r7,LSL r10
	LDMIB	r3!,{r7,r8,r9}
	MOVNE	r7,r7,LSR r12
	ORRNE	r7,r7,r8,LSL r10
	MOVNE	r8,r8,LSR r12
	ORRNE	r8,r8,r9,LSL r10

	AND	r9,r11,r4
	AND	lr,r11,r7
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r4,r11,r4,LSR#8
	AND	r7,r11,r7,LSR#8
	ADC	r4,r4,r7
	ADD	r4,r4,#&10000
	MOV	r4,r4,LSR#1
	BIC	r4,r4,#&8000
	ORR	r4,r9,r4,LSL#8

	AND	r9,r11,r5
	AND	lr,r11,r8
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r5,r11,r5,LSR#8
	AND	r8,r11,r8,LSR#8
	ADC	r5,r5,r8
	ADD	r5,r5,#&10000
	MOV	r5,r5,LSR#1
	BIC	r5,r5,#&8000
	ORR	r5,r9,r5,LSL#8

	LDMIA	r3!,{r7,r8,r9}
	STMIA	r1!,{r4,r5}
	MOVNE	r7,r7,LSR r12
	ORRNE	r7,r7,r8,LSL r10
	MOVNE	r8,r8,LSR r12
	ORRNE	r8,r8,r9,LSL r10

	LDMIA	r0!,{r4,r5,r9}
	MOVNE	r4,r4,LSR r12
	ORRNE	r4,r4,r5,LSL r10
	MOVNE	r5,r5,LSR r12
	ORRNE	r5,r5,r9,LSL r10

	AND	r9,r11,r4
	AND	lr,r11,r7
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r4,r11,r4,LSR#8
	AND	r7,r11,r7,LSR#8
	ADC	r4,r4,r7
	ADD	r4,r4,#&10000
	MOV	r4,r4,LSR#1
	BIC	r4,r4,#&8000
	ORR	r4,r9,r4,LSL#8

	AND	r9,r11,r5
	AND	lr,r11,r8
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r5,r11,r5,LSR#8
	AND	r8,r11,r8,LSR#8
	ADC	r5,r5,r8
	ADD	r5,r5,#&10000
	MOV	r5,r5,LSR#1
	BIC	r5,r5,#&8000
	ORR	r5,r9,r5,LSL#8

	STMIA	r1!,{r4,r5}

	SUB	r4,r3,r0
	SUB	r4,r4,#6*4
	ADD	r0,r0,r4
	ADD	r3,r3,r4

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arecv_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"
;recvc (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arecvc
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        CMP     r6,#0
        SUB	r0,r0,#4	; allow for the LDMIA/B trick below
        ADD     r3,r0,r3	; r3 = sp - lx2
	AND	r12,r0,#3
	MOV	r12,r12,LSL #3
	RSB	r10,r12,#32
	MOV	r11,#&ff
	ORR	r11,r11,r11,LSL#16
	SUB	r2,r2,#8
        ; This has the neat side effect of setting the carry flag!
arecvc_loop
	TEQ	r12,#0
	LDMIB	r0!,{r4,r5,r7}
	MOVNE	r4,r4,LSR r12
	ORRNE	r4,r4,r5,LSL r10
	MOVNE	r5,r5,LSR r12
	ORRNE	r5,r5,r7,LSL r10
	LDMIB	r3!,{r7,r8,r9}
	MOVNE	r7,r7,LSR r12
	ORRNE	r7,r7,r8,LSL r10
	MOVNE	r8,r8,LSR r12
	ORRNE	r8,r8,r9,LSL r10

	AND	r9,r11,r4
	AND	lr,r11,r7
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r4,r11,r4,LSR#8
	AND	r7,r11,r7,LSR#8
	ADC	r4,r4,r7
	ADD	r4,r4,#&10000
	MOV	r4,r4,LSR#1
	BIC	r4,r4,#&8000
	ORR	r4,r9,r4,LSL#8

	AND	r9,r11,r5
	AND	lr,r11,r8
	ADC	r9,r9,lr
	ADD	r9,r9,#&10000
	MOV	r9,r9,LSR#1
	BIC	r9,r9,#&8000

	AND	r5,r11,r5,LSR#8
	AND	r8,r11,r8,LSR#8
	ADC	r5,r5,r8
	ADD	r5,r5,#&10000
	MOV	r5,r5,LSR#1
	BIC	r5,r5,#&8000
	ORR	r5,r9,r5,LSL#8

	STMIA	r1!,{r4,r5}

	SUB	r4,r3,r0
	SUB	r4,r4,#3*4
	ADD	r0,r0,r4
	ADD	r3,r3,r4

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arecvc_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"

;rec4 (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arec4
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        SUB     r4,r0,r3	; r4 = sp - lx2
        CMP     r6,#0
        ; This has the neat side effect of setting the carry flag!
arec4_loop
	LDRB	r8,[r0,r3]!
	LDRB	r10,[r4,r3]!

	LDRB	r9,[r0,#1]
	LDRB	r11,[r4,#1]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r5,r8,LSR #2

	LDRB	r8,[r0,#2]
	LDRB	r10,[r4,#2]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r5,r5,r9,LSL #8

	LDRB	r9,[r0,#3]
	LDRB	r11,[r4,#3]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r8,r8,LSR #2
	ORR	r5,r5,r8,LSL #16

	LDRB	r8,[r0,#4]
	LDRB	r10,[r4,#4]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r5,r5,r9,LSL #24

	LDRB	r9,[r0,#5]
	LDRB	r11,[r4,#5]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r7,r8,LSR #2

	LDRB	r8,[r0,#6]
	LDRB	r10,[r4,#6]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r7,r7,r9,LSL #8

	LDRB	r9,[r0,#7]
	LDRB	r11,[r4,#7]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r8,r8,LSR #2
	ORR	r7,r7,r8,LSL #16

	LDRB	r8,[r0,#8]
	LDRB	r10,[r4,#8]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r7,r7,r9,LSL #24

	LDRB	r9,[r0,#9]
	LDRB	r11,[r4,#9]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r12,r8,LSR #2

	LDRB	r8,[r0,#10]
	LDRB	r10,[r4,#10]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r12,r12,r9,LSL #8

	LDRB	r9,[r0,#11]
	LDRB	r11,[r4,#11]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r8,r8,LSR #2
	ORR	r12,r12,r8,LSL #16

	LDRB	r8,[r0,#12]
	LDRB	r10,[r4,#12]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	r12,r12,r9,LSL #24

	LDRB	r9,[r0,#13]
	LDRB	r11,[r4,#13]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	lr,r8,LSR #2

	LDRB	r8,[r0,#14]
	LDRB	r10,[r4,#14]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	lr,lr,r9,LSL #8

	LDRB	r9,[r0,#15]
	LDRB	r11,[r4,#15]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r11
	MOV	r8,r8,LSR #2
	ORR	lr,lr,r8,LSL #16

	LDRB	r8,[r0,#16]
	LDRB	r10,[r4,#16]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r11
	MOV	r9,r9,LSR #2
	ORR	lr,lr,r9,LSL #24

	STMIA	r1,{r5,r7,r12,lr}

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arec4_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"



;rec4c (unsigned char *s, unsigned char *d, int lx, int lx2, int h));
arec4c
        			; r0 = sp2 - lx2
        			; r1 = d
        			; r2 = lx
        			; r3 = lx2
        SUB     r4,r0,r3	; r4 = sp - lx2
        CMP     r6,#0
        ; This has the neat side effect of setting the carry flag!
arec4c_loop
	LDRB	r8,[r0,r3]!
	LDRB	r10,[r4,r3]!

	LDRB	r9,[r0,#1]
	LDRB	r12,[r4,#1]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r12
	MOV	r5,r8,LSR #2

	LDRB	r8,[r0,#2]
	LDRB	r10,[r4,#2]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r12
	MOV	r9,r9,LSR #2
	ORR	r5,r5,r9,LSL #8

	LDRB	r9,[r0,#3]
	LDRB	r12,[r4,#3]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r12
	MOV	r8,r8,LSR #2
	ORR	r5,r5,r8,LSL #16

	LDRB	r8,[r0,#4]
	LDRB	r10,[r4,#4]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r12
	MOV	r9,r9,LSR #2
	ORR	r5,r5,r9,LSL #24

	LDRB	r9,[r0,#5]
	LDRB	r12,[r4,#5]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r12
	MOV	lr,r8,LSR #2

	LDRB	r8,[r0,#6]
	LDRB	r10,[r4,#6]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r12
	MOV	r9,r9,LSR #2
	ORR	lr,lr,r9,LSL #8

	LDRB	r9,[r0,#7]
	LDRB	r12,[r4,#7]
	ADC	r8,r8,r9
	ADC	r8,r8,r10
	ADD	r8,r8,r12
	MOV	r8,r8,LSR #2
	ORR	lr,lr,r8,LSL #16

	LDRB	r8,[r0,#8]
	LDRB	r10,[r4,#8]
	ADC	r9,r8,r9
	ADC	r9,r9,r10
	ADD	r9,r9,r12
	MOV	r9,r9,LSR #2
	ORR	lr,lr,r9,LSL #24

	STMIA	r1,{r5,lr}

        ADD	r1,r1,r2
	SUBS	r6,r6,#1
        BGT     arec4c_loop ; In the case when this jump is taken the carry flag is set
        Return  "r4-r11"


;these have 10 args :-(

;reco (unsigned char *s, int *d, int lx, int lx2, int addflag,int c, int xa, int xb, int ya, int yb));
;		R0	   R1	   R2      R3
; [sp,#40]    	addflag
; [sp,#44]	c
; [sp,#48]	xa
; [sp,#52]	xb
; [sp,#56]	ya
; [sp,#60]	yb
; [sp,#64]      omp
;using:
;r0123456789
areco
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADD	r0,r0,r6
	ADD	r1,r1,r6,LSL#2
	SUB	r7,r7,r6
	ADR R10,OM_table
        ; r10= omp
        ; r10= &omp[c]

	ADD R10,R10,R3,LSL #6 ;om = &omp[c][ya]
	ADD R10,R10,R8,LSL #3

	SUBS r8,r9,r8
	SUB	r2,r2,r7
	ADD	r10,r10,r6
	RSB	r3,r7,#8
recoplaceloop
	MOV	r5,r7
recoinloop
	LDRB r11,[r0],#1
	LDRB lr,[r10],#1
	LDRB r4,[r0],#1
	MUL	r6,r11,lr
	LDRB	lr,[r10],#1
	; Stall
	MUL	r9,r4,lr
	LDRB	r4,[r0],#1
	LDRB	lr,[r10],#1
	STMIA	r1!,{r6,r9}
	MUL	r6,r4,lr
	LDRB	r4,[r0],#1
	LDRB	lr,[r10],#1
	SUBS	r5,r5,#4
	MUL	r9,r4,lr
	STMIA	r1!,{r6,r9}
	BGT recoinloop

	ADD	r10,r10,r3
	ADD	r0,r0,r2
	ADD	r1,r1,r3,LSL#2

	SUBS	R8,R8,#1
	BGT	recoplaceloop

        EXIT

;else
areco_add
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r5 = c
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR R10,OM_table
        ; r10= omp
        ; r10= &omp[c]

	ADD R10,R10,R3,LSL #6 ;om = &omp[c][ya]
	ADD R10,R10,R8,LSL #3

	SUBS r8,r9,r8
	ADD	r0,r0,r6
	ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	SUB	r7,r7,r6
	SUB	r2,r2,r7
	RSB	r3,r7,#8

recoaddloop
	MOV	r5,r7
recoaddinloop
	LDMIA r1,{r6,r9}

	LDRB r11,[r0],#1
	LDRB lr,[r10],#1
	LDRB r4,[r0],#1
	MLA r6,r11,lr,r6
	LDRB lr,[r10],#1
	; Stall
	MLA r9,r4,lr,r9
	LDRB r4,[r0],#1
	LDRB lr,[r10],#1
	STMIA r1!,{r6,r9}

	LDMIA r1,{r6,r9}

	MLA r6,r4,lr,r6
	LDRB r4,[r0],#1
	LDRB lr,[r10],#1
	SUBS r5,r5,#4
	MLA r9,r4,lr,r9
	STMIA r1!,{r6,r9}

	BGT	recoaddinloop

	ADD r10,r10,r3

	ADD r0,r0,r2
	ADD r1,r1,r3,LSL#2

	SUBS R8,R8,#1
	BGT recoaddloop

        EXIT

;end



;recho (unsigned char *s, int *d, int lx, int lx2, int addflag,int c, int xa, int xb, int ya, int yb));
arecho
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR R10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUBS	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; Now allow for increments as we go
        SUB	r7,r7,r6
        SUB	r2,r2,r7
        RSB	r3,r7,#8
        ; scratch r4,r9
        ; So GT, so C set!
recho_noadd_jloop
        MOV	r5,r7
        LDRB	r11,[r0]
recho_noadd_iloop
        LDRB	r12,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
        MUL	r6,r11,lr

        LDRB	r11,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MUL	r9,r12,lr

        LDRB	lr,[r10],#1
        LDRB	r12,[r0,#1]!
	STMIA	r1!,{r6,r9}

        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
        MUL	r6,r11,lr

        LDRB	r11,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MUL	r9,r12,lr
	SUBS	r5,r5,#4
	STMIA	r1!,{r6,r9}

	BGT	recho_noadd_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	recho_noadd_jloop ; When taken, C set

        EXIT
arecho_add
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR R10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUBS	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; Now allow for increments as we go
        SUB	r7,r7,r6
        SUB	r2,r2,r7
        RSB	r3,r7,#8
        ; scratch r4,r9
        ; if (!addflag) {
recho_add
        ; So GT, so C set!
recho_add_jloop
        MOV	r5,r7
        LDRB	r11,[r0]
recho_add_iloop
        LDRB	r12,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
	LDMIA	r1,{r6,r9}
        MLA	r6,r11,lr,r6

        LDRB	r11,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MLA	r9,r12,lr,r9

        LDRB	r12,[r0,#1]!
        LDRB	lr,[r10],#1
	STMIA	r1!,{R6,r9}

        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
	LDMIA	r1,{r6,r9}
        MLA	r6,r11,lr,r6

        LDRB	r11,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MLA	r9,r12,lr,r9
	SUBS	r5,r5,#4
	STMIA	r1!,{R6,r9}

	BGT	recho_add_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	recho_add_jloop ; When taken, C set

        EXIT

;recvo (unsigned char *s, int *d, int lx, int lx2, int addflag,int c, int xa, int xb, int ya, int yb));
arecvo
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <addflag, c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR	r10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUB	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
        SUBS	r7,r7,r6
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; r4 = 1 line above r0
        ADD	r4,r0,r2
	; Now allow for increments as we go
        SUB	r2,r2,r7
	RSB	r3,r7,#8
        ; So GT, so C set!
recvo_noadd_jloop
	; r5 = i = xa
        MOV	r5,r7
recvo_noadd_iloop
        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
        MUL	r6,r11,lr

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MUL	r9,r12,lr

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        STMIA	r1!,{r6,r9}

        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
        MUL	r6,r11,lr

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MUL	r9,r12,lr
	SUBS	r5,r5,#4
        STMIA	r1!,{r6,r9}

	BGT	recvo_noadd_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r4,r4,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	recvo_noadd_jloop ; When taken, C set

        EXIT
arecvo_add
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <addflag, c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR	r10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUB	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
        SUBS	r7,r7,r6
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; r4 = 1 line above r0
        ADD	r4,r0,r2
	; Now allow for increments as we go
        SUB	r2,r2,r7
	RSB	r3,r7,#8
recvo_add
        ; So GT, so C set!
recvo_add_jloop
	; r5 = i = xa
        MOV	r5,r7
recvo_add_iloop
        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
	LDMIA	r1,{r6,r9}
        MLA	r6,r11,lr,r6

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MLA	r9,r12,lr,r9

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
	STMIA	r1!,{r6,r9}

        ADC	r11,r11,r12
        MOV	r11,r11,ASR#1
	LDMIA	r1,{r6,r9}
        MLA	r6,r11,lr,r6

        LDRB	r11,[r0],#1
        LDRB	r12,[r4],#1
        LDRB	lr,[r10],#1
        ADC	r12,r11,r12
        MOV	r12,r12,ASR#1
        MLA	r9,r12,lr,r9
	SUBS	r5,r5,#4
	STMIA	r1!,{r6,r9}

	BGT	recvo_add_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r4,r4,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	recvo_add_jloop ; When taken, C set

        EXIT

OM_table
	DCB 4
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 4

	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5

	DCB 5
	DCB 5
	DCB 6
	DCB 6
	DCB 6
	DCB 6
	DCB 5
	DCB 5

	DCB 5
	DCB 5
	DCB 6
	DCB 6
	DCB 6
	DCB 6
	DCB 5
	DCB 5

	DCB 5
	DCB 5
	DCB 6
	DCB 6
	DCB 6
	DCB 6
	DCB 5
	DCB 5

	DCB 5
	DCB 5
	DCB 6
	DCB 6
	DCB 6
	DCB 6
	DCB 5
	DCB 5

	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5

	DCB 4
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 5
	DCB 4
;
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2

	DCB 1
	DCB 1
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 1
	DCB 1

	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1

	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
;
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1

	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1
	DCB 1

	DCB 1
	DCB 1
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 1
	DCB 1

	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
	DCB 2
;
	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 1
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 2
	DCB 2

	DCB 0
	DCB 0
	DCB 0
	DCB 0
	DCB 1
	DCB 1
	DCB 1
	DCB 2
;
	DCB 2
	DCB 1
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 2
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

	DCB 2
	DCB 1
	DCB 1
	DCB 1
	DCB 0
	DCB 0
	DCB 0
	DCB 0

;rec4o (unsigned char *s, int *d, int lx, int lx2, int addflag,int c, int xa, int xb, int ya, int yb));
; xa,ya,xb,yb are all 0, 4, or 8
arec4o
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <addflag, c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR	r10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUBS	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
        ; scratch r4,r9
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; r4 = 1 line above r0
        ADD	r4,r0,r2
	; Now allow for increments as we go
        SUB	r7,r7,r6
        SUB	r2,r2,r7
        RSB	r3,r7,#8
        ; C set!
rec4o_noadd_jloop
	; r5 = i = xa
	; r11 = sp[i]
        LDRB	r11,[r0]
        LDRB	lr,[r4]
        MOV	r5,r7
        ADC	r11,lr,r11
rec4o_noadd_iloop
        LDRB	r9,[r0,#1]!
        LDRB	r12,[r4,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r9,r12
        ADD	r11,r11,r12
        MOV	r11,r11,ASR#2
        MUL	r9,r11,lr

        LDRB	r11,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r9,r11
        ADD	r12,r11,r12
        MOV	r12,r12,ASR#2
        MUL	r9,r12,lr

        LDRB	r12,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r9,r12
        ADD	r11,r11,r12
        MOV	r11,r11,ASR#2
        MUL	r9,r11,lr

        LDRB	r11,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r9,r11
        ADD	r12,r11,r12
        MOV	r12,r12,ASR#2
        MUL	r9,r12,lr
	SUBS	r5,r5,#4
	STR	r9,[r1],#4

	BGT	rec4o_noadd_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r4,r4,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	rec4o_noadd_jloop ; When taken, C set

        EXIT
arec4o_add
	; r0 = sp = s
	; r1 = dp = d
	; r2 = lx2
	; r3 = c
        ; <addflag, c, xa, xb, ya, yb, omp>
	; push 7*4 = 28 on the stack
	;MOV	r12,sp
        Entry   "r1,r2,r4,r10,r11"
        ;LDMFD	r12,{r6-r9}
	; r6 = xa
	; r7 = xb
	; r8 = ya
	; r9 = yb
	ADR	r10,OM_table
        ; r10= omp
        ; r10= &omp[c]
        ADD	r10,r10,r3,LSL #6
        ; scratch r5
        ; r6 = &omp[c][ya]
        ADD	r10,r10,r8,LSL #3
        ; r8 = yb-ya = yrange
        SUBS	r8,r9,r8
	; r1 = dp-4 to allow for the fact we will be incrementing first
        ; scratch r4,r9
	; pretranslate by x
        ADD	r0,r0,r6
        ADD	r1,r1,r6,LSL#2
	ADD	r10,r10,r6
	; r4 = 1 line above r0
        ADD	r4,r0,r2
	; Now allow for increments as we go
        SUB	r7,r7,r6
        SUB	r2,r2,r7
        RSB	r3,r7,#8
        ; C set!
rec4o_add
        ; So GT, so C set!
rec4o_add_jloop
	; r5 = i = xa
	; r11 = sp[i]
        LDRB	r11,[r0]
        LDRB	lr,[r4]
        MOV	r5,r7
        ADC	r11,lr,r11
rec4o_add_iloop
        LDRB	r9,[r0,#1]!
        LDRB	r12,[r4,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r9,r12
        ADD	r11,r11,r12
	LDR	r9,[r1]
        MOV	r11,r11,ASR#2
        MLA	r9,r11,lr,r9
        LDRB	r11,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r9,r11
        ADD	r12,r11,r12
	LDR	r9,[r1]
        MOV	r12,r12,ASR#2
        MLA	r9,r12,lr,r9
        LDRB	r12,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r12,r9,r12
        ADD	r11,r11,r12
	LDR	r9,[r1]
        MOV	r11,r11,ASR#2
        MLA	r9,r11,lr,r9
        LDRB	r11,[r4,#1]!
	STR	r9,[r1],#4

        LDRB	r9,[r0,#1]!
        LDRB	lr,[r10],#1
        ADC	r11,r9,r11
        ADD	r12,r11,r12
	LDR	r9,[r1]
        MOV	r12,r12,ASR#2
        MLA	r9,r12,lr,r9
	SUBS	r5,r5,#4
	STR	r9,[r1],#4

	BGT	rec4o_add_iloop ; if taken, GT, so C set

	ADD	r0,r0,r2
	ADD	r4,r4,r2
	ADD	r1,r1,r3,LSL#2
	ADD	r10,r10,r3

	SUBS	r8,r8,#1
	BGT	rec4o_add_jloop ; When taken, C set

        EXIT


arecon_comp
	; r0 = src
	; r1 = dst
	; r2 = lx
	; r3 = lx2

        MOV      r12,sp
        FunctionEntry "r4-r11"
        LDMFD	 r12,{r6-r10}
        MOV	r5,r6
        ; r5 = w
        ; r6 = h
        ;CMP	r6,#0
        ;Return "r4-r11",, LE
        ; r7 = x
        ; r8 = y
        ; r9 = dx
        ; r10= dy


        ; r1 = d = dst + lx*y
        MLA	r1,r2,r8,r1
	; r8 = y+yint
	ADD	r8,r8,r10,ASR#1
        ; r1 = d = dst + lx*y + x
        ADD	r1,r1,r7

	; r0 = s = src + lx2*(y+yint) + x + xint
	MLA	r0,r3,r8,r0
	AND	r10,r10,#1
	ADD	r0,r0,r7
	ADD	r0,r0,r9,ASR#1
	; scratch r7,r8

	AND	r9,r9,#1
	ORR	r9,r9,r10,LSL#1
	; r9 bit 0 = xh, bit 1 = yh
	; scratch r10

	CMP	r5,#8
	ORRNE	r9,r9,#4
	; r9 bit 0 = xh, bit 1 = yh, bit 2 = (w!=8)
	; scratch r5

	ADD	pc, pc, r9, LSL#2
	MOV	pc,#0
	; !xh & !yh & (w==8)
	B arecc
	;  xh & !yh & (w==8)
	B arechc
	; !xh &  yh & (w==8)
	B arecvc
	;  xh &  yh & (w==8)
	B arec4c

	; !xh & !yh & (w!=8)
	B arec
	;  xh & !yh & (w!=8)
	B arech
	; !xh &  yh & (w!=8)
	B arecv
	;  xh &  yh & (w!=8)
	B arec4

recon_comp_obmc
        MOV      r12,sp
        FunctionEntry "r4-r11"
	LDMFD	 r12,{r4-r6}
	; r0 = comp
	; r1 = x
	; r2 = y
	; r3 = lx2
	; r4 = src	(unsigned char *)
	; r5 = dst	(unsigned char *)
	; r6 = lx
	; r7-r13,r14 scratch

        MOV      r8,#1
        ADD      r7,r8,r1,ASR #4; xmb = (x>>4)+1
        ADD      r8,r8,r2,ASR #4; ymb = (y>>4)+1

        ADD	 r4,r4,r1	; r4 = src + x
        ADD	 r5,r5,r1	; r5 = dst + x
        ; scratch r1

	LDR      r10,MV_d3_log
	LDR      r9,modemap
	ADD      r1,r8,r7,LSL r10	; r1 = xmb<<MV_d3_log + ymb

	LDRB	 r1,[r9,r1]!	; (*MM_INDEX(ymb, xmb))
	MLA	 r5,r6,r2,r5	; r5 = dst + x + lx*y
	AND	r1,r1,#7	; MODE_MASK
	CMP	 r1,#2	; = MODE_INTER4V
	MOVEQ	 r12,#1

	; Now we note that we only need t8/ti8 if (comp&2 == 0)
	; We can't avoid all the work, but we can avoid the stores...
	LDRB	 r1,[r9,#-1]		; *(ptr-1)
	MOVNE	 r12,#0			; r12 = c8 = (*ptr == MODE_INTER4V)
	AND	r1,r1,#7	; MODE_MASK
	CMP	 r1,#2
	MOVNE	 r1,#0
	MOVEQ	 r1,#1
	TST	r0,#2
	STREQ	 r1,t8			; t8 = (*ptr-1) == MODE_INTER4V
	RSC	r1,r1,#1
	STREQ	 r1,ti8			; ti8= (*ptr-1) >  MODE_INTER4V

	MOV	 r11,#1
	MOV	 r11,r11,LSL r10	; r11 = 1<<MV_d3_log

	; Now we note that r8/ri8 and l8/li8 are never used at the same time.
	; so only calculate one of them... If comp&1 then r else l
	; For r we add, for l we sub
	TST	r0,#1
	RSBEQ	r11,r11,#0
	LDRB	 r1,[r9,r11]	; *(ptr+1<<MV_d3_log)
        LDR      r14,pb_frame
	AND	r1,r1,#7
	CMP	 r1,#2
	MOV	 r1,#0
	MOVEQ	 r1,#1
	STR	 r1,lr8			; r8 = (*ptr+1<<MV_d3_log)==MODE_INTER4V
	RSC	r1,r1,#1

	STR	 r1,lri8		; ri8= (*ptr+1<<MV_d3_log)> MODE_INTER4V
        TEQ      r14,#0			; if (pb_frame)
        MOVNE    r14,#0
        STRNE    r14,ti8			;   ti8 = li8 = ri8 = 0
        STRNE    r14,lri8

	CMP	r0,#4 ; Should be 4	; switch comp
	LDRLO	pc,[pc,r0,LSL#2]
        Return  "r4-r11"

	DCD	case_0
	DCD	case_1
	DCD	case_2
	DCD	case_3
case_0
	MOV	r1,r12,LSL#1
	STR	r1,vecr			; vecr = c8<<1

	ADD	r1,r12,r12,LSL#1	; vecb = c8+c8<<1
	STR	r1,vecb

	LDR	r1,ti8
	; remember: r8 = ymb
	STR	r8,yib			; yib = ymb
	CMP	r1,#0
	MOVNE	r11,r12
	LDREQ	r11,t8
	STR	r8,yir			; yir = ymb
	ADDEQ	r11,r11,r11,LSL#1	; r11 = vect = (ti8? c8 : t8+t8<<1)
	SUBEQ	r1,r8,#1
	MOVNE	r1,r8			; r1 = yit = (ti8? ymb : ymb-1)
	STR	r8,yil			; yil = ymb

	CMP	r8,#1			; if (ymb == 1) {
	MOVEQ	r1,#1			;   yit = ymb
	STR	r1,yit			;   vect = c8
	MOVEQ	r11,r12			; }
	STR	r11,vect
	;scratch r1,r11

	LDR	r11,lri8
	; remember: r7 = xmb
	STR	r7,xit			; xit = xmb
	CMP	r11,#0
	MOVNE	r11,r12
	LDREQ	r11,lr8
	STR	r7,xib			; xib = xmb
	MOVEQ	r11,r11,LSL#1		; r11 = vecl = (li8 ? c8 : (l8<<1))
	MOVNE	r1,r7
	SUBEQ	r1,r7,#1		; r1 = xil = (li8 ? xmb : xmb-1)
	STR	r7,xir			; xir = xmb

	CMP	r7,#1			; if (xmb == 1) {
	MOVEQ	r1,#1			;   xil = xmb;
	STR	r1,xil			;   vecl = c8;
	MOVEQ	r11,r12			; }
	STR	r11,vecl

	B after_switch
case_1
	STR	r12,vecl			; vecl = c8
	MOV	r1,r12,LSL#2
	STR	r1,vecb			; vecb = c8<<2

	LDR	r1,ti8
	; remember: r8 = ymb
	STR	r8,yib					; yib = ymb
	CMP	r1,#0
	MOVNE	r1,r12,LSL#1
	LDREQ	r1,t8
	STR	r8,yil			; yil = ymb
	MOVEQ	r1,r1,LSL#2		; r1 = vect = (ti8? c8<<1 : t8<<2)
	MOVNE	r11,r8
	STR	r8,yir			; yir = ymb
	SUBEQ	r11,r8,#1		; r11 = yit = (ti8 ? ymb : ymb-1)

	CMP	r8,#1			; if (ymb == 1) {
	MOVEQ	r11,r8			;   yit = ymb
	STR	r11,yit			;   vect = c8<<1
	MOVEQ	r1,r12,LSL#1		; }
	STR	r1,vect
        ;scratch r1,r11

	LDR	r1,lri8
	STR	r7,xib			; xib = xmb
	CMP	r1,#0
	MOVNE	r1,r12,LSL#1
	LDREQ	r1,lr8			; r1 = vecr = (ri8? c8<<1 : r8)
	; remember: r7 = xmb
	STR	r7,xit			; xit = xmb
	MOVNE	r11,r7
	ADDEQ	r11,r7,#1		; r11 = xir = (ri8? xmb : xmb+1)

	LDR	r14,mb_width		; r14 = mb_width
	STR	r7,xil			; xil = xmb
	CMP	r7,r14			; if (xmb == mb_width) {
	MOVEQ	r11,r7			;   xir = xmb;
	STR	r11,xir			;   vecr = c8<<1
	MOVEQ	r1,r12,LSL#1		; }
	STR	r1,vecr

	B after_switch
case_2
	STR	r12,vect		; vect = c8
	MOV	r1,r12,LSL#2

	STR	r1,vecr			; vecr = c8<<2
	ADD	r1,r12,r12,LSL#1
	LDR	r11,lri8
	STR	r1,vecb			; vecb = c8+c8<<1
	CMP	r11,#0
	STR	r8,yit			; yit = ymb
	;r1 has right value from above
	;ADDNE	r1,r12,r12,LSL#1
	STR	r8,yib			; yib = ymb
	LDREQ	r1,lr8
	STR	r8,yil			; yil = ymb
	MOVEQ	r1,r1,LSL#2		; r1 = vecl = (li8 ? c8+c8<<1 : l8<<2)
	STR	r8,yir			; yir = ymb
	MOVNE	r11,r7
	STR	r7,xib			; xib = xmb
	SUBEQ	r11,r7,#1		; r11 = xil = (li8 ? xmb : xmb+1)
	STR	r7,xit			; xit = xmb

	CMP	r7,#1                   ; if (xmb == 1) {
	STR	r7,xir			;                  NOT IN IF: xir = xmb
	MOVEQ	r11,#1			;   xil = xmb
	STR	r11,xil			;   vecl = c8+c8<<1
	ADDEQ	r1,r12,r12,LSL#1	; }
	STR	r1,vecl

	B after_switch
case_3
	STR	r8,yit			; yit= ymb
	MOV	r1,r12,LSL#1		; vect = c8<<1
	STR	r1,vect

	ADD	r1,r12,r12,LSL#1	; vecl = c8+c8<<1
	STR	r1,vecl

	MOV	r1,r12,LSL#2		; vecb = c8<<2

	LDR	r11,lri8
	STR	r1,vecb
	CMP	r11,#0
	STR	r8,[pc,#yib-.-8]	; yib = ymb
	; r1 has this value already
	;MOVNE	r1,r12,LSL#2
	LDREQ	r1,lr8
	STR	r8,yil			; yil = ymb
	ADDEQ	r1,r1,r1,LSL#1		; r1 = vecr= (ri8 ? c8<<2 : r8+r8<<1)
	STR	r8,yir			; yir = ymb
	MOVNE	r11,r7
	STR	r7,xib			; xib = xmb
	ADDEQ	r11,r7,#1		; r11= xir = (ri8 ? xmb : xmb+1)

	LDR	r14,mb_width		; r14 = mb_width
	STR	r7,xit	; xit = xmb
	CMP	r7,r14			; if (xmb == mb_width) {
	STR	r7,xil			;                   NOT IN IF: xil = xmb
	MOVEQ	r11,r7			;   xir = xmb
	STR	r11,xir	;   vecr = c8<<2
	MOVEQ	r1,r12,LSL#2		; }
	STR	r1,vecr

after_switch
        LDR     r11,MV
        ADD     r7,r8,r7,LSL r10	; r7 = xmb<<MV_d3_log + ymb

	CMP	r12,#1			; if (c8)
	; The next line adds an extra 1 to r7 if the C flag is set. The C
	; flag will be set if r12 = 1 (which si what we want). This flows
	; through to make the r12 8 bigger at the end of the paragraph. Sorted.
        ADC     r7,r7,r7,LSL #2		; r7 =(xmb<<MV_d3_log + ymb)*5
        ADD	r12,r11,r7,LSL#3	; *4 for words, *2 for array
	ADDEQ	r12,r12,r0,LSL#3	;   ptr += (comp<<1)+2
	; scratch r12,r8

        ; scratch r7
	LDMIA	r12!,{r7,r8}

	ADD	r9,r2,r8,ASR#1		; r9 = y+(yint=ny>>1)
	MLA	r9,r3,r9,r4		; r9 = lx2*(y+yint) + src + x
	AND	r8,r8,#1
	ADD	r9,r9,r7,ASR#1		; r9 = lx2*(y+yint) + xint + src + x
	STR	r9,s0
	AND	r7,r7,#1
	STR	r7,xh0

	LDR	r7,yit
	LDR	r9,xit
	STR	r8,yh0
	ADD	r7,r7,r9,LSL r10	; r9 = xit<<MV_d3_log+yit
	LDR	r9,vect
	ADD	r7,r7,r7,LSL #2		; r9 =(xit<<MV_d3_log+yit)*5
	ADD	r9,r9,r7;,LSL#1
	ADD	r9,r11,r9,LSL#3
	LDMIA	r9,{r7,r8}		; r9 = *ptr = *MV_INDEX(o,vect,yit,xit)
					; r12= *(ptr+1)

	ADD	r9,r2,r8,ASR#1		; r9 = y+(yint=ny>>1)
	MLA	r9,r3,r9,r4		; r9 = lx2*(y+yint) + src + x
	AND	r8,r8,#1
	ADD	r9,r9,r7,ASR#1		; r9 = lx2*(y+yint) + xint + src + x
	STR	r9,s1
	AND	r7,r7,#1
	STR	r7,xh1
	STR	r8,yh1

	LDR	r7,yib
	LDR	r8,xib
	LDR	r9,vecb
	ADD	r7,r7,r8,LSL r10	; r7 = xib<<MV_d3_log+yib
	ADD	r7,r7,r7,LSL #2		; r7 =(xib<<MV_d3_log+yib)*5
	ADD	r9,r9,r7;,LSL#1
	ADD	r9,r11,r9,LSL#3
	LDMIA	r9,{r7,r8}		; r7 = *ptr = *MV_INDEX(o,vecb,yib,xib)
					; r8= *(ptr+1)

	ADD	r9,r2,r8,ASR#1		; r9 = y+(yint=ny>>1)
	MLA	r9,r3,r9,r4		; r9 = lx2*(y+yint) + src + x
	AND	r8,r8,#1
	ADD	r9,r9,r7,ASR#1		; r9 = lx2*(y+yint) + xint + src + x
	STR	r9,s2
	AND	r7,r7,#1
	STR	r7,xh2
	STR	r8,yh2

	LDR	r7,yir
	LDR	r8,xir
	LDR	r9,vecr
	ADD	r7,r7,r8,LSL r10	; r7 = xir<<MV_d3_log+yir
	ADD	r7,r7,r7,LSL #2		; r7 =(xir<<MV_d3_log+yir)*5
	ADD	r9,r9,r7;,LSL#1
	ADD	r9,r11,r9,LSL#3
	LDMIA	r9,{r7,r8}		; r7 = *ptr = *MV_INDEX(o,vecr,yir,xir)
					; r8= *(ptr+1)

	ADD	r9,r2,r8,ASR#1		; r9 = y+(yint=ny>>1)
	MLA	r9,r3,r9,r4		; r9 = lx2*(y+yint) + src + x
	AND	r8,r8,#1
	ADD	r9,r9,r7,ASR#1		; r9 = lx2*(y+yint) + xint + src + x
	STR	r9,s3
	AND	r7,r7,#1
	STR	r7,xh3
	STR	r8,yh3

	LDR	r7,yil
	LDR	r8,xil
	LDR	r9,vecl
	ADD	r7,r7,r8,LSL r10	; r7 = xil<<MV_d3_log+yil
	ADD	r7,r7,r7,LSL #2		; r7 =(xil<<MV_d3_log+yil)*5
	ADD	r9,r9,r7;,LSL#1
	ADD	r9,r11,r9,LSL#3
	LDMIA	r9,{r7,r8}		; r7 = *ptr = *MV_INDEX(o,vecl,yil,xil)
					; r8= *(ptr+1)

	ADD	r9,r2,r8,ASR#1		; r9 = y+(yint=ny>>1)
	MLA	r9,r3,r9,r4		; r9 = lx2*(y+yint) + src + x
	AND	r8,r8,#1
	ADD	r9,r9,r7,ASR#1		; r9 = lx2*(y+yint) + xint + src + x
	STR	r9,s4
	AND	r7,r7,#1
	STR	r7,xh4
	STR	r8,yh4

	ADR	r10,xh
	ADR	r11,yh
	MOV	r2,r3
	ADR	r4,s
	ADR	r1,p

	STMFD	r13!,{r5,r6}

acall_recs
	; r0 = xh
	; r1 = yh
	; r2 = lx2
	; r3 = s
	; <p, d, lx>
; First call
	LDR	r0,[r4]
	MOV	r3,#0
	MOV	r6,#0
	MOV	r7,#8
	MOV	r8,#0
	MOV	r9,#8

        LDR	r12,[r10]
        LDR	lr,[r11]
	ADR	r5,cr_table
	ORR	r12,r12,lr,LSL#1

	MOV	r14,pc
	LDR	PC,[r5,r12,LSL#2]
;Second call
	LDR	r0,[r4,#4]
	MOV	r3,#1
	MOV	r6,#0
	MOV	r7,#8
	MOV	r8,#0
	MOV	r9,#4

        LDR	r12,[r10,#4]
        LDR	lr,[r11,#4]
	ADR	r5,cr_table_add
	ORR	r12,r12,lr,LSL#1

	MOV	r14,pc
	LDR	PC,[r5,r12,LSL#2]
;Third call
	LDR	r0,[r4,#8]
	ADD	r0,r0,r2,LSL#2
	ADD	r1,r1,#32<<2
	MOV	r3,#2
	MOV	r6,#0
	MOV	r7,#8
	MOV	r8,#4
	MOV	r9,#8

        LDR	r12,[r10,#8]
        LDR	lr,[r11,#8]
	ADR	r5,cr_table_add
	ORR	r12,r12,lr,LSL#1

	MOV	r14,pc
	LDR	PC,[r5,r12,LSL#2]

;Fourth call
	LDR	r0,[r4,#12]
	SUB	r1,r1,#32<<2
	MOV	r3,#3
	MOV	r6,#4
	MOV	r7,#8
	MOV	r8,#0
	MOV	r9,#8

        LDR	r12,[r10,#12]
        LDR	lr,[r11,#12]
	ADR	r5,cr_table_add
	ORR	r12,r12,lr,LSL#1

	MOV	r14,pc
	LDR	PC,[r5,r12,LSL#2]

;Fifth call
	LDR	r0,[r4,#16]
	MOV	r3,#4
	MOV	r6,#0
	MOV	r7,#4
	MOV	r8,#0
	MOV	r9,#8

        LDR	r12,[r10,#16]
        LDR	lr,[r11,#16]
	ADR	r5,cr_table_add
	ORR	r12,r12,lr,LSL#1

	MOV	r14,pc
	LDR	PC,[r5,r12,LSL#2]

	ADR	r0,p
	LDMFD	sp!,{r1-r2}
;i2c
	MOV R3,#8
	MOV R12,#&FF
i2c_loop

	LDMIA R0!,{R4-r11}
	ADD R4,R4,#4
	ADD R5,R5,#4
	ADD R6,R6,#4
	ADD R7,R7,#4
	ADD R8,R8,#4
	ADD R9,R9,#4
	ADD R10,R10,#4
	ADD R11,R11,#4

	AND R4,R12,R4, LSR #3
	AND R5,R12,R5, LSR #3
	ORR R5,R4,R5, LSL #8

	AND R6,R12,R6, LSR #3
	AND R7,R12,R7, LSR #3
	ORR R7,R6,R7, LSL #8

	ORR R7,R5,R7,LSL #16

	AND R8,R12,R8, LSR #3
	AND R9,R12,R9, LSR #3
	ORR R9,R8,R9, LSL #8

	AND R10,R12,R10, LSR #3
	AND R11,R12,R11, LSR #3
	ORR R11,R10,R11, LSL #8

	ORR R11,R9,R11,LSL #16

	STMIA R1,{R7,R11}
	ADD R1,R1,R2
	SUBS R3,R3,#1
	BNE  i2c_loop

        Return  "r4-r11"
cr_table
	DCD areco
	DCD arecho
	DCD arecvo
	DCD arec4o
cr_table_add
	DCD areco_add
	DCD arecho_add
	DCD arecvo_add
	DCD arec4o_add


return
        Return  "r4-r11"
xh
xh0
	DCD 0
xh1
	DCD 0
xh2
	DCD 0
xh3
	DCD 0
xh4
	DCD 0
yh
yh0
	DCD 0
yh1
	DCD 0
yh2
	DCD 0
yh3
	DCD 0
yh4
	DCD 0
vecl
	DCD 0
vecr
	DCD 0
vect
	DCD 0
vecb
	DCD 0
xil
	DCD 0
xir
	DCD 0
xit
	DCD 0
xib
	DCD 0
yil
	DCD 0
yir
	DCD 0
yit
	DCD 0
yib
	DCD 0
lr8
	DCD 0
t8
	DCD 0
lri8
	DCD 0
ti8
	DCD 0
s
s0
	DCD 0
s1
	DCD 0
s2
	DCD 0
s3
	DCD 0
s4
	DCD 0
	DCD 0
p
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0
	DCD 0

reconstruct
	; r0 = P
	; r1 = bx
	; r2 = by
	; r3 = bdx
        FunctionEntry "r4-r11"

	LDR	r4,[sp,#9*4]
	; r4 = bdy

	MOV	r6,#1
	ADD	r5,r6,r1,ASR#4		; r5 = x = (bx>>4)+1
	LDR	r7,coded_picture_width	; r7 = lx = coded_picture_width
	ADD	r6,r6,r2,ASR#4		; r6 = y = (by>>4)+1
        ;LDR      lr,mv_outside_frame
	ADD	r7,r7,#64
	MOV	r8,r7			; r8 = lx2 = lx

	;CMP      lr,#0				; if (mv_outside_frame) {
        ;ADDNE    r8,r8,#&40			;   r8 = lx2+=64
						; } else {
        LDR      r10,adv_pred_mode
        ;ADRNE    r9,edgeframe			;   r9 = src = &edgeframe
        ADRL    r9,oldrefframe			;   r9 = src = &oldrefframe
        					; }
        LDR	r12,MV_d3_log
        MOVS	 r11,r10			; r11 = 0 or 1, and EQ iff R10=0

        LDRNE	r11,modemap			;r11= modemap

	ADD	r6,r6,r5,LSL r12		;lr = x<<MV_d3_log + y
	LDRNEB	r11,[r11,r6]		;r11=*(modemap+(x<<MV_d3_log+y)*2)
						;r11= mode = *MM_INDEX(y,x)
        ORR	r0,r0,r10,LSL#1
	AND	r11,r11,#7		; MODE_MASK
	CMP	r11,#2				; if (mode == 2)
        ADDEQ	r0,r0,#2			;   r0 +=2

        LDR      r10,MV
	ADD	r6,r6,r6,LSL#2
	ADD	r10,r10,r6,LSL#3	; r10 = MV_INDEX(0,0,y,x)
	; r0 = scratch (jump offset)
	; r1 = bx
	; r2 = by
	; r3 = bdx
	; r4 = bdy
	; r5 = x
	; r6 = y
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= MV
	; r11= mode/scratch
	; r12= MV_d3_log
	; r14= scratch
	LDR	pc,[pc,r0,LSL#2]

	DCD	0
	; P = 0, adv_pred_mode = 0
	DCD	P0apm0
	DCD	P1apm0
	DCD	P0apm1modenot2
	DCD	P1apm1
	DCD	P0apm1mode2
	DCD	P1apm1
P1apm1
	; scratch r3,r4,r5,r12
	LDR	r3,[r9]
	LDR	r5,newframe
	STMFD   r13!,{r3,r5,r7}		; <src[0],newframe[0],lx>
	MOV	r0,#0
	MOV	r4,r1			; r4 = bx
	MOV	r5,r2			; r5 = by
	MOV	r3,r8
	BL	recon_comp_obmc

 	MOV	r0,#1
	ADD	r1,r4,#8
	MOV	r2,r5
	MOV	r3,r8
	BL	recon_comp_obmc

 	MOV	r0,#2
	MOV	r1,r4
 	ADD	r2,r5,#8
	MOV	r3,r8
	BL	recon_comp_obmc

 	MOV	r0,#3
	ADD	r1,r4,#8
	ADD	r2,r5,#8
	MOV	r3,r8
	BL	recon_comp_obmc

	ADD	sp,sp,#4*3
	;scratch r0,r1,r2,r3,r12,r14
	CMP	r11,#2
	BNE	P1apm1modenot2
P1apm1mode2
	; scratch r11
	; scratch r6
	ADD	r10,r10,#8
	LDMIA	r10,{r0,r1,r2,r3,r6,r10,r12,r14}

	ADD	r6,r6,r0
	ADD	r10,r10,r1
	ADD	r6,r6,r2
	ADRL	r0,roundtab
	ADD	r10,r10,r3
	ADDS	r6,r6,r12		; r6 = sum = *(p+2)+*(p+4)+*(p+6)+*(p+8);
	RSBLT	r6,r6,#0
	AND	r2,r6,#15
	LDRB	r2,[r0,r2]		; r2= roundtab[abs(sum)&15]
	MOV	r6,r6,ASR#4
	ADD	r6,r2,r6,LSL#1		; r6 = dx = r2+(abs(sum)>>4)*2
	RSBLT	r6,r6,#0		; if (sum<0) dx = -dx

	ADDS	r10,r10,r14		; r10= sum = *(p+3)+*(p+5)+*(p+7)+*(p+9);
	RSBLT	r10,r10,#0
	AND	r2,r10,#15
	LDRB	r2,[r0,r2]		; r2 = roundtab[abs(sum)&15]
	MOV	r10,r10,ASR#4
	ADD	r10,r2,r10,LSL#1	; r10 = dy = r2+(abs(sum)>>4)*2
	RSBLT	r10,r10,#0		; if (sum<0) dy = -dy
P1apm1lastbit
	; r0 =
	; r1 =
	; r2 =
	; r3 =
	; r4 = bx
	; r5 = by
	; r6 = dx
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= dy
	; r11= mode/scratch
	; r12= MV_d3_log
	; r14= scratch
	MOV	r0,#8
	MOV	r4,r4,ASR#1
	MOV	r5,r5,ASR#1
	STMFD	r13!,{r0,r4,r5,r6,r10}
	LDR	r0,[r9,#4]
	LDR	r1,newframe+4
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp
	LDR	r0,[r9,#8]
	LDR	r1,newframe+8
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp
	ADD	r13,r13,#5*4
        Return  "r4-r11"
P1apm1modenot2
	LDMIA	r10,{r6,r10}	; dx = *(p++); dy = *p;

	TST	r6,#3
	MOV	r6,r6,ASR#1
	ORRNE	r6,r6,#1

	TST	r10,#3		; dy = (dy>>1) | (dy & 3 != 0)
	MOV	r10,r10,ASR#1
	ORRNE	r10,r10,#1

	B P1apm1lastbit
P1apm0
	; r0 = scratch (jump offset)
	; r1 = bx
	; r2 = by
	; r3 = bdx
	; r4 = bdy
	; r5 = x
	; r6 = y
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= MV
	; r11= mode/scratch
	; r12= MV_d3_log
	; r14= scratch
	LDMIA	r10,{r10,r11}
	MOV	r0,#16
	MOV	r5,r1,ASR#1
	MOV	r6,r2,ASR#1
	STMFD	r13!,{r0,r1,r2,r10,r11}
	LDR	r0,[r9]
	LDR	r1,newframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp

	TST	r10,#3
	MOV	r10,r10,ASR#1
	ORRNE	r10,r10,#1
	TST	r11,#3
	MOV	r11,r11,ASR#1
	ORRNE	r11,r11,#1

	MOV	r0,#8
	STMIA	r13,{r0,r5,r6,r10,r11}

	LDR	r0,[r9,#4]
	LDR	r1,newframe+4
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	LDR	r0,[r9,#8]
	LDR	r1,newframe+8
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	ADD	r13,r13,#5*4
        Return  "r4-r11"
P0apm1mode2
	; r0 = scratch (jump offset)
	; r1 = bx
	; r2 = by
	; r3 = bdx
	; r4 = bdy
	; r5 = x
	; r6 = y
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= MV
	; r11= mode/scratch
	; r12= MV_d3_log
	; r14= scratch
	LDR	r11,trb
	LDR	r14,itrd
	ADD	r10,r10,#8
	MUL	r11,r14,r11
	LDMIA	r10!,{r12,r14}
	MOV	r0,#8
	STR	r11,mulf
	; r11=trb*itrd
	MULS	r12,r11,r12
	MVN	r5,#0
	ADDMI	r12,r12,r5,LSR#17
	MULS	r14,r11,r14
	ADD	r12,r3,r12,ASR#15
	ADDMI	r14,r14,r5,LSR#17
	ADD	r14,r4,r14,ASR#15
	STR	r12,xvec
	STR	r14,yvec
;comp=0
	MOV	r5,r3
	STMFD 	r13!,{r0,r1,r2,r12,r14}
	MOV	r6,r1
	MOV	r11,r2
	LDR	r0,[r9]
	LDR	r1,bframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp
;comp=1
	LDMIA	r10!,{r12,r14}
	LDR	r0,mulf
	MVN	r1,#0
	MULS	r12,r0,r12
	; Stall cos MULS
	ADDMI	r12,r12,r1,LSR#17
	MULS	r14,r0,r14
	; Stall cos MULS
	ADD	r12,r5,r12,ASR#15
	ADDMI	r14,r14,r1,LSR#17
	LDR	r0,xvec
	ADD	r14,r4,r14,ASR#15
	LDR	r1,yvec
	ADD	r0,r0,r12
	STR	r0,xvec
	ADD	r1,r1,r14
	STR	r1,yvec

	LDMIB	r13,{r6,r11}
	ADD	r6,r6,#8
	STMIB	r13,{r6,r11,r12,r14}
	LDR	r0,[r9]
	LDR	r1,bframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp
;comp=2
	LDMIA	r10!,{r12,r14}
	LDR	r0,mulf
	MVN	r1,#0
	MULS	r12,r0,r12
	; Stall cos MULS
	ADDMI	r12,r12,r1,LSR#17
	MULS	r14,r0,r14
	; Stall cos MULS
	ADD	r12,r5,r12,ASR#15
	ADDMI	r14,r14,r1,LSR#17
	LDR	r0,xvec
	ADD	r14,r4,r14,ASR#15
	LDR	r1,yvec
	ADD	r0,r0,r12
	STR	r0,xvec
	ADD	r1,r1,r14
	STR	r1,yvec

	LDMIB	r13,{r6,r11}
	SUB	r6,r6,#8
	ADD	r11,r11,#8
	STMIB	r13,{r6,r11,r12,r14}
	LDR	r0,[r9]
	LDR	r1,bframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp
;comp=3
	LDMIA	r10!,{r12,r14}
	LDR	r0,mulf
	MVN	r1,#0
	MULS	r12,r0,r12
	; Stall cos MULS
	ADDMI	r12,r12,r1,LSR#17
	MULS	r14,r0,r14
	; Stall cos MULS
	ADD	r12,r5,r12,ASR#15
	ADDMI	r14,r14,r1,LSR#17
	LDR	r6,xvec
	ADD	r14,r4,r14,ASR#15
	LDR	r11,yvec
	ADDS	r6,r6,r12
	ADD	r11,r11,r14

	LDMIB	r13,{r0,r1}
	ADD	r0,r0,#8
	STMIB	r13,{r0,r1,r12,r14}
	LDR	r0,[r9]
	LDR	r1,bframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp
	; scratch r0,r1,r2,r3,r12,r14
	; r4 = bdy
	; r5 = bdx
	; r6 = xvec
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= bframe
	; r11= yvec
        ; Conditon flags are still set from ADDS r6 above, only if APCS-32 not in use
      [ {CONFIG} <> 26
        CMP     r6,#0
      ]
	RSBLT	r6,r6,#0		; r6 = abs(xvec)
	ADR	r0,roundtab
	AND	r2,r6,#15
	LDRB	r2,[r0,r2]		; r2= roundtab[abs(xvec)&15]
	MOV	r6,r6,ASR#4
	ADD	r6,r2,r6,LSL#1		; r6 = dx = r2+(abs(sum)>>4)*2
	RSBLT	r6,r6,#0		; if (xvec_before_abs<0) dx = -dx

	CMP	r11,#0
	RSBLT	r11,r11,#0		; r11= abs(yvec)
	AND	r2,r11,#15
	LDRB	r2,[r0,r2]		; r2= roundtab[abs(yvec)&15]
	MOV	r11,r11,ASR#4
	ADD	r11,r2,r11,LSL#1	; r11= dx = r2+(abs(yvec)>>4)*2
	RSBLT	r11,r11,#0		; if (yvec_before_abs<0) dx = -dx

	LDMIB	r13,{r1,r2}
	MOV	r3,#4
	RSB	r1,r3,r1,ASR#1
	RSB	r2,r3,r2,ASR#1
	STMIB	r13,{r1,r2,r6,r11}

	LDR	r0,[r9,#4]
	LDR	r1,bframe+4
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	LDR	r0,[r9,#8]
	LDR	r1,bframe+8
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	ADD	r13,r13,#5*4
        Return  "r4-r11"
P0apm1modenot2
P0apm0
	; r0 = scratch (jump offset)
	; r1 = bx
	; r2 = by
	; r3 = bdx
	; r4 = bdy
	; r5 = x
	; r6 = y
	; r7 = lx
	; r8 = lx2
	; r9 = src
	; r10= MV
	; r11= mode/scratch
	; r12= MV_d3_log
	; r14= scratch
	LDR	r5,trb
	LDR	r6,itrd
	LDMIA	r10,{r10,r11}
	MUL	r5,r6,r5
	MVN	r6,#0
	MULS	r10,r5,r10
	; Stall cos MULS
	MOV	r0,#16
	ADDMI	r10,r10,r6,LSR#17
	MULS	r11,r5,r11
	; Stall cos MULS
	ADD	r10,r3,r10,ASR#15
	ADDMI	r11,r11,r6,LSR#17
	ADD	r11,r4,r11,ASR#15
	STMFD 	r13!,{r0,r1,r2,r10,r11}

	LDR	r0,[r9]
	LDR	r1,bframe
	MOV	r2,r7
	MOV	r3,r8
	BL	arecon_comp

	CMP	r10,#0
	RSBLT	r10,r10,#0		; r10= abs(xvec)
	AND	r2,r10,#3
	ADR	r0,roundtab
	LDRB	r2,[r0,r2,LSL#2]	; r2= roundtab[abs(xvec)&15]
	MOV	r10,r10,ASR#2
	ADD	r10,r2,r10,LSL#1	; r10= dx = r2+(abs(xvec)>>4)*2
	RSBLT	r10,r10,#0		; if (xvec_before_abs<0) dx = -dx

	CMP	r11,#0
	RSBLT	r11,r11,#0		; r10= abs(xvec)
	AND	r2,r11,#3
	LDRB	r2,[r0,r2,LSL#2]	; r2= roundtab[abs(xvec)&15]
	MOV	r11,r11,ASR#2
	ADD	r11,r2,r11,LSL#1	; r10= dx = r2+(abs(xvec)>>4)*2
	RSBLT	r11,r11,#0		; if (xvec_before_abs<0) dx = -dx

	LDMIB	r13,{r4,r5}
	MOV	r4,r4,ASR#1
	MOV	r5,r5,ASR#1
	MOV	r0,#8
	STMIA	r13,{r0,r4,r5,r10,r11}

	LDR	r0,[r9,#4]
	LDR	r1,bframe+4
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	LDR	r0,[r9,#8]
	LDR	r1,bframe+8
	MOV	r2,r7,ASR#1
	MOV	r3,r8,ASR#1
	BL	arecon_comp

	ADD	r13,r13,#5*4

        Return  "r4-r11"


	; find_pmv is *NOT* an APCS function. It leaves its return values in r2 and r3...
find_pmv
	; r2 = x
	; r3 = y
	LDMFD	r13,{r12}	; r12 = block
        FunctionEntry "r4-r8"

	LDR	r14,modemap
	LDR	r8,MV_d3_log
	MOV	r5,#1
	MOV	r5,r5,LSL r8		; r5 = 4 << MV_d3_log
	ADD	r4,r3,r2,LSL r8		; r4 = x<<MV_d3_log + y
	ADD	r14,r14,r4		; r14 = MM_INDEX(y,x)
	LDRB	r6,[r14,#1]		; r6 = l8_value
	LDRB	r7,[r14,r5]		; r7 = o8
	LDRB	r5,[r14,r5,LSL#1]	; r5 = or8
	AND	r6,r6,#7		; MODE_MASK
	SUBS	r6,r6,#2		; r6 = 0 iff l8 = 1
	MOVNE	r6,#1			; r6 = !l8
	EOR	r6,r6,#1		; r6 = l8
	AND	r7,r7,#7		; MODE_MASK
	SUBS	r7,r7,#2		; r7 = 0 iff o8 = 1
	MOVNE	r7,#1			; r7 = !o8
	EOR	r7,r7,#1		; r7 = o8
	AND	r5,r5,#7		; MODE_MASK
	SUBS	r5,r5,#2		; r5 = 0 iff or8 = 1
	MOVNE	r5,#1			; r5 = !or8

	LDR	r4,MV
	EOR	r5,r5,#1		; r5 = or8

	ADD	PC,PC,r12,LSL#5+2
	MOV	PC,#0
	; r4 = MV + comp
	; r6 = l8
	; r7 = o8
	; r5 = or8
fpmv_block0
	ADD	r14,r3,#1		; yin1 = y+1
	ADD	r14,r14,r2,LSL r8	; r14 = yin1 + x<<MV_d3_log
	ADD	r14,r14,r14,LSL#2	; r14 = (yin1 + x<<MV_d3_log)*5
	ADD	r14,r14,r6,LSL#1	; r14 = l8<<1 + (yin1 + x<<MV_d3_log)*5

	ADD	r14,r4,r14,LSL#3	; r14 = MV_INDEX(comp,vec1,yin1,xin1)

	ADD	r6,r2,#1		; xin2 = x + 1
	ADD	r6,r3,r6,LSL r8		; r6 = y + (xin2<<MV_d3_log)
	ADD	r6,r6,r6,LSL#2		; r6 = (y + (xin2<<MV_d3_log))*5

	ADD	r7,r7,r7,LSL#1		; vec2 = o8+(o8<<1)
	ADD	r6,r7,r6		; r6 = vec2 + (y + (xin2<<MV_d3_log))*5
	ADD	r6,r4,r6,LSL#3		; r6 = MV_INDEX(comp,vec2,yin2,xin2)

	ADD	r7,r2,#2		; xin3 = x + 2

	ADD	r7,r3,r7,LSL r8		; r7 = y + (xin3<<MV_d3_log)
	ADD	r7,r7,r7,LSL#2		; r7 = (y + (xin3<<MV_d3_log))*5
	ADD	r5,r5,r5,LSL#1		; vec3 = or8+(or8<<1)
	ADD	r7,r5,r7		; r7 = vec3 + (y + (xin2<<MV_d3_log))*5

	ADD	r7,r4,r7,LSL#3		; r7 = MV_INDEX(comp,vec3,yin3,xin3)

	B	fpmv_endbit
	DCD	0
long_vectors
	DCD	0
roundtab
        DCD     &01000000
        DCD     &01010101
        DCD     &01010101
        DCD     &02020101
chrom_width
	DCD	0
coded_picture_width
        DCD     &00000000
mv_outside_frame
        DCD     &00000000
adv_pred_mode
        DCD     &00000000
trb
        DCD     &00000000
trd
        DCD     &00000000
itrd
        DCD     &00000000
newgob
        DCD     &00000000
fpmv_block1
        ASSERT  (fpmv_block1 - fpmv_block0) = 32*4
	ADD	r14,r3,#1		; yin1 = y+1
	ADD	r14,r14,r2,LSL r8	; r14 = yin1 + x<<MV_d3_log
	ADD	r14,r14,r14,LSL#2	; r14 = (yin1 + x<<MV_d3_log)*5
	ADD	r14,r14,r6,LSL#1	; r14 = l8<<1 + (yin1 + x<<MV_d3_log)*5

	ADD	r14,r4,r14,LSL#3	; r14 = MV_INDEX(comp,vec1,yin1,xin1)

	ADD	r6,r2,#1		; xin2 = x + 1
	ADD	r6,r3,r6,LSL r8	; r6 = y + (xin2<<MV_d3_log)
	ADD	r6,r6,r6,LSL#2		; r6 = (y + (xin2<<MV_d3_log))*5

	ADD	r7,r7,r7,LSL#1		; vec2 = o8+(o8<<1)
	ADD	r6,r7,r6		; r6 = vec2 + (y + (xin2<<MV_d3_log))*5
	ADD	r6,r4,r6,LSL#3		; r6 = MV_INDEX(comp,vec2,yin2,xin2)

	ADD	r7,r2,#2		; xin3 = x + 2

	ADD	r7,r3,r7,LSL r8	; r7 = y + (xin3<<MV_d3_log)
	ADD	r7,r7,r7,LSL#2		; r7 = (y + (xin3<<MV_d3_log))*5
	ADD	r5,r5,r5,LSL#1		; vec3 = or8+(or8<<1)
	ADD	r7,r5,r7		; r7 = vec3 + (y + (xin2<<MV_d3_log))*5

	ADD	r7,r4,r7,LSL#3		; r7 = MV_INDEX(comp,vec3,yin3,xin3)

	B	fpmv_endbit
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0
fpmv_block2
        ASSERT  (fpmv_block2 - fpmv_block1) = 32*4
	ADD	r14,r3,#1		; yin1 = y+1
	ADD	r6,r2,#1		; xin1 = xin2 = x + 1
	ADD	r14,r14,r6,LSL r8	; r14 = yin1 + (x+1)<<MV_d3_log
	ADD	r14,r14,r14,LSL#2	; r14 = (yin1 + (x+1)<<MV_d3_log)*5

	ADD	r14,r14,#1		; r14 = 1 + (yin1 + (x+1)<<MV_d3_log)*5
	ADD	r14,r4,r14,LSL#3	; r14 = MV_INDEX(comp,vec1,yin1,xin1)
	ADD	r6,r3,r6,LSL r8		; r6 = y + (xin2<<MV_d3_log)
	ADD	r6,r6,r6,LSL#2		; r6 = (y + (xin2<<MV_d3_log))*5
					; vec2 = (o8<<2)
	ADD	r6,r6,r7,LSL#2		; r6 = vec2 + (y + (xin2<<MV_d3_log))*5
	ADD	r6,r4,r6,LSL#3		; r6 = MV_INDEX(comp,vec2,yin2,xin2)

	ADD	r7,r2,#2		; xin3 = x + 2
	ADD	r7,r3,r7,LSL r8		; r7 = y + (xin3<<MV_d3_log)

	ADD	r7,r7,r7,LSL#2		; r7 = (y + (xin3<<MV_d3_log))*5
	ADD	r5,r5,r5,LSL#1		; vec3 = or8+(or8<<1)
	ADD	r7,r5,r7		; r7 = vec3 + (y + (xin2<<MV_d3_log))*5
	ADD	r7,r4,r7,LSL#3		; r7 = MV_INDEX(comp,vec3,yin3,xin3)

	B	fpmv_endbit
bframe
	DCD 0
	DCD 0
	DCD 0
oldrefframe
        DCD     0
        DCD     0
        DCD     0
;edgeframe
        DCD     0
        DCD     0
        DCD     0
newframe
        DCD     0
        DCD     0
        DCD     0
mulf
	DCD 0
xvec
	DCD 0
yvec
	DCD 0
fpmv_block3
        ASSERT  (fpmv_block3 - fpmv_block2) = 32*4
	ADD	r3,r3,#1		; yin1 = y+1
	ADD	r14,r3,r2,LSL r8	; r14 = yin1 + (x+1)<<MV_d3_log
	ADD	r14,r14,r14,LSL#2	; r14 = (yin1 + (x+1)<<MV_d3_log)*5
	ADD	r14,r14,r6,LSL#2	; r14 = l8<<2 + (yin1 + (x+1)<<MV_d3_log)*5

	ADD	r14,r4,r14,LSL#3	; r14 = MV_INDEX(comp,vec1,yin1,xin1)
	ADD	r2,r2,#1
	ADD	r3,r3,r2,LSL r8		; r1 = y + (xin2<<MV_d3_log)
	ADD	r3,r3,r3,LSL#2		; r1 = (y + (xin2<<MV_d3_log))*5

	ADD	r6,r3,#1		; r6 = vec2 + (y + (xin2<<MV_d3_log))*5
	ADD	r6,r4,r6,LSL#3		; r6 = MV_INDEX(comp,vec2,yin2,xin2)
	ADD	r7,r3,#2		; vec3 = 2
	ADD	r7,r4,r7,LSL#3

	B	fpmv_endbit
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0
fpmv_block4
        ASSERT  (fpmv_block4 - fpmv_block3) = 32*4
	ADD	r3,r3,#1		; yin1 = y+1
	ADD	r2,r2,#1
	ADD	r2,r3,r2,LSL r8	; r14 = yin1 + (x+1)<<MV_d3_log
	ADD	r2,r2,r2,LSL#2		; r14 = (yin1 + (x+1)<<MV_d3_log)*5

	ADD	r14,r2,#3		; r14 = 3 + (yin1 + (x+1)<<MV_d3_log)*5
	ADD	r14,r4,r14,LSL#3	; r14 = MV_INDEX(comp,vec1,yin1,xin1)
	ADD	r6,r2,#1		; r6 = vec2 + (y + (xin2<<MV_d3_log))*5
	ADD	r6,r4,r6,LSL#3		; r6 = MV_INDEX(comp,vec2,yin2,xin2)

	ADD	r7,r2,#2		; vec3 = 2
	ADD	r7,r4,r7,LSL#3
fpmv_endbit
	RSBS	r12,r12,#3
	LDRGT	r5,newgob
	LDMIA	r14,{r8,r14}	; r8 = p1x
				; r14 = p1y
	CMPGT	r5,#0
	LDMLEIA	r6,{r5,r6}	; r6 = p2x
				; r6 = p2y
	MOVGT	r5,#996
	MOVGT	r6,#996
	LDMLEIA	r7,{r4,r7}	; r4 = p3x
				; r7 = p3y
	CMP	r5,#996
	MOVEQ	r5,r8
	MOVEQ	r4,r8
	CMP	r6,#996
	MOVEQ	r6,r14
	MOVEQ	r7,r14

	CMP	r8,r5
	EORGT	r8,r5,r8
	EORGT	r5,r8,r5	; r5 = x2 = max(r8,r5)
	EORGT	r8,r5,r8	; r8 = x1 = min(r8,r5)
	CMP	r14,r6
	EORGT	r14,r6,r14
	EORGT	r6,r14,r6	; r6  = y2 = max(r14,r6)
	EORGT	r14,r6,r14	; r14 = y1 = min(r14,r6)

	MOV	r2,r4
	CMP	r4,r8
	MOVLT	r2,r8
	CMP	r4,r5
	MOVGT	r2,r5

	MOV	r3,r7
	CMP	r7,r14
	MOVLT	r3,r14
	CMP	r7,r6
	MOVGT	r3,r6

	LDMFD	r13!,{r4-r8,r14}
	; and drop through to...
motion_decode
motion_decode_noapcs
	; r0 = xvec
	; r1 = yvec
	; r2 = xpmv
	; r3 = ypmv
	CMP	r0,#31
	SUBGT	r0,r0,#64
	CMP	r1,#31
	SUBGT	r1,r1,#64
	LDR	r12,long_vectors
	ADD	r0,r0,r2
	ADD	r1,r1,r3
	CMP	r12,#0
	BNE	md_lv
	CMP	r0,#31
	SUBGT	r0,r0,#64
	CMN	r0,#32
	ADDLT	r0,r0,#64
	CMP	r1,#31
	SUBGT	r1,r1,#64
	CMN	r1,#32
	ADDLT	r1,r1,#64
        Return  , LinkNotStacked
md_lv
	CMN	r2,#31
	CMNLT	r0,#63
	ADDLT	r0,r0,#64
	CMP	r2,#32
	CMPGT	r0,#63
	SUBGT	r0,r0,#64
	CMN	r3,#31
	CMNLT	r1,#63
	ADDLT	r1,r1,#64
	CMP	r3,#32
	CMPGT	r1,#63
	SUBGT	r1,r1,#64
        Return  , LinkNotStacked
motion_decode_ret
	MOV	r0,r1
        Return  , LinkNotStacked
modemap
        DCD     0
MV_d3_log
        DCD     0
MV
        DCD     0
pb_frame
        DCD     0
pict_type
	DCD	0
mb_width
        DCD     0
rbb_chroma
	; r0 = comp
	; r1 = bx
	; r2 = by
	; r3 = mode
	; r4 = bdx
	; r5 = bdy
	; r6 = (y + x<<MV_d3_log)*5
	; r12= MV_d3_log
	; r14= MV
	ADD	r14,r14,r6,LSL#3
	CMP	r3,#2
	BEQ	rbb_chrom_4v

	LDMIA	r14!,{r6,r7}	; r6 = mvx
				; r7 = mvy
	MOV	r9,#1
	RSB	r9,r9,r9,LSL#15
	LDR	r14,trb
	LDR	r12,trd
	LDR	r11,itrd
	CMP	r4,#0		; bdx == 0 ?
	SUBEQ	r8,r14,r12	; r8 = bdx == 0 ? (trb-trd) : trb
	MOVNE	r8,r14
	MUL	r8,r6,r8
	SUBNE	r4,r4,r6	; r4 = bdx-mvx
	MULS	r8,r11,r8	; r8 = (bdx == 0 ? (trb-trd)*mvx*itrd : trb*mvx*itrd)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r8,r8,r9
	ADD	r8,r4,r8,ASR#15	;r8=xvec=(bdx==0?(trb-trd)*mvx*itrd/TRDDIV:trb*mvx*itrd/TRDDIV+bdx-mvx)

	CMP	r5,#0		; bdy == 0 ?
	SUBEQ	r14,r14,r12	; r14 = bdy == 0 ? (trb-trd) : trb
	MUL	r14,r7,r14
	SUBNE	r5,r5,r7	; r5 = bdy - mvy
	MULS	r14,r11,r14	; r14 = (bdy == 0 ? (trb-trd)*mvx*itrd : trb*mvx*itrd)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r14,r14,r9
	ADD	r14,r5,r14,ASR#15;r14=yvec=bdy==0?(trb-trd)*mvx*itrd/TRDDIV:trb*mvx*itrd/TRDDIV+bdx-mvx
	MOV	r8,r8,LSL#2	; r8 = xvec *= 4
	MOV	r14,r14,LSL#2	; r14= yvec *= 4
rbb_chrom_cont
	; r0 = comp
	; r1 = bx
	; r2 = by
	; r4 = bdx
	; r5 = bdy
	; r8 = xvec
	; r14= yvec
	ADR	r10,roundtab
	MOVS	r3,r8
	RSBLT	r3,r3,#0	; r3 = abs(xvec)
	AND	r8,r3,#15	; r8 = abs(xvec)&15
	LDRB	r8,[r10,r8]
	MOV	r3,r3,ASR#4	; r3 = abs(xvec)/16
	ADD	r8,r8,r3,LSL#1	; r8 = roundtab[r8] + r3*2
	RSBLT	r8,r8,#0	; r8 = BMVx

	MOVS	r3,r14
	RSBLT	r3,r3,#0	; r3 = abs(yvec)
	AND	r14,r3,#15	; r14= abs(yvec)&15
	LDRB	r14,[r10,r14]
	MOV	r3,r3,ASR#4	; r3 = abs(yvec)/16
	ADD	r14,r14,r3,LSL#1; r14= roundtab[r14] + r3*2
	RSBLT	r14,r14,#0	; r14= BMVy

	RSB	r4,r8,#1	; r4 = 1-vec
	MOVS	r4,r4,ASR#1
	MOVLT	r4,#0		; r4 = xa = mmax(0, (1-vec)/2)

	ADD	r5,r8,#1	; r5 = 1+vec
	MOVS	r5,r5,ASR#1
	RSBGT	r5,r5,#8
	MOVLE	r5,#8		; r5 = xb = mmin(8, 8-(vec+1)/2)

	RSB	r6,r14,#1	; r6 = 1-vec
	MOVS	r6,r6,ASR#1
	MOVLT	r6,#0		; r6 = ya = mmax(0, (1-vec)/2)

	ADD	r7,r14,#1	; r7 = 1+vec
	MOVS	r7,r7,ASR#1
	RSBGT	r7,r7,#8
	MOVLE	r7,#8		; r7 = yb = mmin(8, 8-(vec+1)/2)

	MOV	r1,r1,ASR#1	; bx >>= 1
	MOV	r2,r2,ASR#1	; by >>= 1
	LDR	r12,chrom_width	; ii = chrom_width
	AND	r9,r0,#2
	ADD	r2,r2,r9,LSL#2
	ADD	r12,r12,#32
	MLA	r2,r12,r2,r1
	ADR	r3,newframe+4
	AND	r9,r0,#8
	ADD	r2,r2,r9	; r2 = t = (chrom_width+32)*(by+(comp&2)<<2) + bx + comp&8
	AND	r10,r0,#1
	LDR	r10,[r3,r10,LSL#2]!		; ffr = newframe[cc]
	LDR	r9,[r3,#bframe-newframe]	; bfr = bframe[cc]
	ADD	r10,r10,r2
	ADD	r9,r9,r2
	; r1 = bx - scratch
	; r2 = scratch
	; r4 = xa	OK
	; r5 = xb	OK
	; r6 = ya	OK
	; r7 = yb	OK
	; r8 = BMVx	OK
	; r9 = bfr	OK
	; r10= ffr	OK
	; r12= ii	OK
	; r14= BMVy	OK
	; scratch r0, r3, r11
	B	rbb_merge
rbb_chrom_4v
	; r0 = comp
	; r1 = bx
	; r2 = by
	; r3 = mode
	; r4 = bdx
	; r5 = bdy
	; r6 = (y + x<<MV_d3_log)*5
	; r14= &MV_INDEX(0,0,y,x)
	STMFD	r13!,{r0,r2}
	ADD	r3,r14,#8

	MOV	r10,#4
	MOV	r8,#0		; r8 = xvec = 0
	MOV	r14,#0		; r14= yvec = 0
	LDR	r0,trb
	LDR	r12,trd
	LDR	r11,itrd
	; r0 = trb
	; r3 = &MV_INDEX(0,1,y,x)
	; r4 = bdx
	; r5 = bdy
	; r8 = xvec
	; r9 = 2^15 -1
	; r10= k (loop counter)
	; r11= itrd
	; r12= trd
	; r14= yvec
	CMP	r4,#0
	SUBEQ	r2,r0,r12	; r2 = (bdx == 0 ? (trb-trd) : trb)
	MOVNE	r2,r0
	MUL	r2,r11,r2	; r2 = (bdx == 0 ? (trb-trd)*itrd : trb*itrd)
	CMP	r5,#0
	SUBEQ	r0,r0,r12	; r0 = (bdy == 0 ? (trb-trd) : trb)
	MUL	r0,r11,r0	; r0 = (bdy == 0 ? (trb-trd)*itrd : trb*itrd)
	MOV	r9,#1
	RSB	r9,r9,r9,LSL#15
	; scratch r1,r2,r6,r7,r11,r12
rbb_chrom_4v_lp
	LDMIA	r3!,{r6,r7}	; r6 = mvx
				; r7 = mvy
	MULS	r11,r2,r6	; r11= (bdx == 0 ? (trb-trd)*itrd*mvx : trb*itrd*mvx)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r11,r11,r9
	ADD	r11,r4,r11,ASR#15;r11=(bdx==0 ? (trb-trd)*itrd*mvx/TRDDIV :trb*itrd*mvx/TRDDIV+bdx)
	CMP	r4,#0
	SUBNE	r11,r11,r6	; r11=(bdx==0 ? (trb-trd)*itrd*mvx/TRDDIV :trb*itrd*mvx/TRDDIV+bdx-mvx)

	MULS	r6,r0,r7	; r6 =(bdy==0 ? (trb-trd)*itrd*mvy : trb*itrd*mvy)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r6,r6,r9
	ADD	r6,r5,r6,ASR#15	; r6 =(bdy==0 ? (trb-trd)*itrd*mvy/TRDDIV :trb*itrd*mvy/TRDDIV+bdy)
	CMP	r5,#0
	SUBNE	r6,r6,r7	; r6 =(bdy==0 ? (trb-trd)*itrd*mvy/TRDDIV :trb*itrd*mvy/TRDDIV+bdy-mvy)

	ADD	r8,r8,r11
	ADD	r14,r14,r6
	SUBS	r10,r10,#1
	BGT	rbb_chrom_4v_lp

	LDMFD	r13!,{r0,r2}
	; r0 = comp
	; r1 = bx
	; r2 = by
	; r4 = bdx
	; r5 = bdy
	; r8 = xvec	OK
	; r14= yvec	OK
	B	rbb_chrom_cont
reconblock_b
	; r0 = comp
	; r1 = bx
	; r2 = by
	; r3 = mode
	; r4 = bdx
	; r5 = bdy
	MOV	r12,r13
        FunctionEntry "r4-r11"
	LDMFD	r12,{r4,r5}

	MOV	r14,#1
	MOVS	r6,r1
	SUBLT	r6,r6,#15
	ADDS	r6,r14,r6,ASR#4		; r6 = x = bx/16+1
	MOVS	r7,r2
	SUBLT	r7,r7,#15
	ADDS	r7,r14,r7,ASR#4		; r7 = y = by/16+1

	LDR	r12,MV_d3_log
	LDR	r14,MV
	ADD	r6,r7,r6,LSL r12	; r6 = y + x<<MV_d3_log
	ADD	r6,r6,r6,LSL#2		; r6 = (y + x<<MV_d3_log)*5

	; r0 = comp
	; r1 = bx
	; r2 = by
	; r3 = mode
	; r4 = bdx
	; r5 = bdy
	; r6 = (y + x<<MV_d3_log)*5
	CMP	r0,#4
	BGE	rbb_chroma

	CMP	r3,#2			; if (mode == MODE_INTER4V) (Sets C flag if GE)
	ADCEQ	r6,r6,r0
	ADD	r14,r14,r6,LSL#3	; r6 = &MV_INDEX(0,(mode == MODE_INTER4V)? comp+1 : 0,y,x);
	LDMIA	r14,{r6,r7}		; r6 = mvx
					; r7 = mvy

	MOV	r9,#1
	RSB	r9,r9,r9,LSL#15
	LDR	r14,trb
	LDR	r12,trd
	LDR	r11,itrd
	CMP	r4,#0		; bdx == 0 ?
	SUBEQ	r8,r14,r12	; r8 = bdx == 0 ? (trb-trd) : trb
	MOVNE	r8,r14
	MUL	r8,r6,r8
	SUBNE	r4,r4,r6	; r4 = bdx-mvx
	MULS	r8,r11,r8	; r8 = (bdx == 0 ? (trb-trd)*mvx*itrd : trb*mvx*itrd)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r8,r8,r9
	ADD	r8,r4,r8,ASR#15	;r8=BMVx=(bdx==0?(trb-trd)*mvx*itrd/TRDDIV:trb*mvx*itrd/TRDDIV+bdx-mvx)

	CMP	r5,#0		; bdy == 0 ?
	SUBEQ	r14,r14,r12	; r14 = bdy == 0 ? (trb-trd) : trb
	MUL	r14,r7,r14
	SUBNE	r5,r5,r7	; r5 = bdy - mvy
	MULS	r14,r11,r14	; r14 = (bdy == 0 ? (trb-trd)*mvx*itrd : trb*mvx*itrd)
	; No stall, cos we've lost it anyway cos of MULS
	ADDLT	r14,r14,r9
	ADD	r14,r5,r14,ASR#15;r14=BMVy=bdy==0?(trb-trd)*mvx*itrd/TRDDIV:trb*mvx*itrd/TRDDIV+bdx-mvx

	RSB	r4,r8,#1	; r4 = 1-vec
	AND	r12,r0,#1	; r12=comp&1
	MOV	r4,r4,ASR#1
	SUBS	r4,r4,r12,LSL#3
	MOVLT	r4,#0		; r4 = xa = mmax(0, (1-vec)/2-nhv*8)

	ADD	r5,r8,#1	; r5 = 1+vec
	MOV	r5,r5,ASR#1
	ADD	r5,r5,r12,LSL#3
	RSB	r5,r5,#16
	CMP	r5,#8
	MOVGT	r5,#8		; r5 = xb = mmin(8, 16-(vec+1)/2-nhv*8)

	RSB	r6,r14,#1	; r6 = 1-vec
	AND	r11,r0,#2	; r11= comp&2
	MOV	r6,r6,ASR#1
	SUBS	r6,r6,r11,LSL#2
	MOVLT	r6,#0		; r6 = ya = mmax(0, (1-vec)/2-nhv*8)

	ADD	r7,r14,#1	; r7 = 1+vec
	MOV	r7,r7,ASR#1
	ADD	r7,r7,r11,LSL#2
	RSB	r7,r7,#16
	CMP	r7,#8
	MOVGT	r7,#8		; r7 = yb = mmin(8, 16-(vec+1)/2-nhv*8)

	ADD	r9,r1,r12,LSL#3		; r9 = bx + (comp&1)<<3
	LDR	r12,coded_picture_width
	ADD	r11,r2,r11,LSL#2	; r11= by + (comp&2)<<2
	ADD	r12,r12,#64
	MLA	r0,r11,r12,r9		; r0 = (coded_picture_width+64)*(by+(comp&2)<<2)+bx+(comp&1)<<3

	LDR	r9,bframe
	LDR	r10,newframe
	ADD	r9,r9,r0
	ADD	r10,r10,r0
	; r1 = bx - scratch
	; r2 = by - scratch
	; r4 = xa
	; r5 = xb
	; r6 = ya
	; r7 = yb
	; r8 = BMVx
	; r9 = bfr
	; r10= ffr
	; r12= ii
	; r14= BMVy
	; scratch r0, r3, r11
rbb_merge
	MOV	r0,r8,ASR#1		; r0 = xint
	SUB	r8,r8,r0,ASL#1		; r8 = xhalf
	MOV	r3,r14,ASR#1		; r3 = yint
	SUB	r14,r14,r3,ASL#1	; r14= yhalf
	ORR	r8,r8,r14,LSL#1

	ADD	r3,r6,r3		; r3 = yint+ya
	MLA	r3,r12,r3,r0		; r3 = xint + (yint+ya)*ii
	SUB	r7,r7,r6		; r7 = ycount = yb - ya
	MLA	r9,r12,r6,r9		; r1 = bfr += ya*ii
	ADD	r10,r10,r3		; r10= ffr += xint + (yint+ya)*ii
	ADD	r10,r10,r4
	ADD	r9,r9,r4

	SUB	r5,r5,r4		; r5 = xcount = xb - xa
	SUBS	r12,r12,r5		; r12= ii - xcount

	; C set
	ADD	PC,PC,r8,LSL#5+2
        MOV	PC,#0
rbb_00
	MOV	r4,r5
rbb_00lp
	LDRB	r6,[r10],#1
	LDRB	r0,[r9]
	SUBS	r4,r4,#1

	ADD	r6,r6,r0
	MOV	r6,r6,ASR#1
	STRB	r6,[r9],#1
	BGT	rbb_00lp

	ADD	r10,r10,r12
	ADD	r9,r9,r12
	SUBS	r7,r7,#1
	BGT	rbb_00

        Return  "r4-r11"
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0
rbb_01
        ASSERT  (rbb_01 - rbb_00) = 32*4
	MOV	r4,r5
	LDRB	r1,[r10]
rbb_01lp
	LDRB	r6,[r10,#1]!
	LDRB	r0,[r9]

	SUBS	r4,r4,#1
	ADC	r1,r6,r1
	ADD	r0,r0,r1,ASR#1
	MOV	r0,r0,ASR#1

	STRB	r0,[r9],#1
	MOV	r1,r6
	BGT	rbb_01lp
	ADD	r10,r10,r12

	ADD	r9,r9,r12
	SUBS	r7,r7,#1
	BGT	rbb_01
        Return  "r4-r11"

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

rbb_02
        ASSERT  (rbb_02 - rbb_01) = 32*4
	ADD	r11,r10,r12
	ADD	r11,r11,r5
rbb_02lp2
	MOV	r4,r5
rbb_02lp
	LDRB	r6,[r10],#1

	LDRB	r1,[r11],#1
	LDRB	r0,[r9]
	ADC	r6,r6,r1
	SUBS	r4,r4,#1

	ADD	r0,r0,r6,ASR#1
	MOV	r0,r0,ASR#1
	STRB	r0,[r9],#1
	BGT	rbb_02lp

	ADD	r10,r10,r12
	ADD	r11,r11,r12
	ADD	r9,r9,r12
	SUBS	r7,r7,#1

	BGT	rbb_02lp2
        Return  "r4-r11"
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0

	DCD	0
	DCD	0
	DCD	0
	DCD	0
rbb_03
        ASSERT  (rbb_03 - rbb_02) = 32*4
	ADD	r11,r10,r12
	ADD	r11,r11,r5
rbb_03lp2
	LDRB	r2,[r10]
	LDRB	r3,[r11]

	MOV	r4,r5
	ADC	r2,r2,r3
rbb_03lp
	LDRB	r6,[r10,#1]!
	LDRB	r1,[r11,#1]!

	LDRB	r0,[r9]
	ADC	r6,r6,r1
	ADD	r2,r2,r6
	SUBS	r4,r4,#1

	ADD	r0,r0,r2,ASR#2
	MOV	r0,r0,ASR#1
	STRB	r0,[r9],#1
	MOV	r2,r6

	BGT	rbb_03lp
	ADD	r10,r10,r12
	ADD	r11,r11,r12
	ADD	r9,r9,r12
	SUBS	r7,r7,#1

	BGT	rbb_03lp2
        Return  "r4-r11"



gMBsac_startcode
	BL	startcode
	MOV	r0,#22
	BL	ashowbits
	CMP	r0,#32+31
	CMPNE	r0,#32
	CMPNE	r4,#0			; if (!xpos)
	BEQ	gMBsac_gob_finished	; {
	AND	r0,r0,#31		;   if ((showbits(22) & 31)
	CMP	r0,r5			;			    != ypos)
	BNE	gMBsac_finish_gob	;     goto finish_gob;
	BL	getheader		; ypos = (getheader()
	SUB	r5,r0,#1		;                    - 1)
	CMP	r5,r6
        Return  "r4-r11",, GT           ;   return
	MOV	r0,#7
	BL	agetbits
	LDR	r1,quants_stored_ptr
	AND	r7,r0,#31		; quant = getbits(7) & 31;
	STRB	r7,[r1],#1
	STR	r1,quants_stored_ptr
	MOV	r4,#0			; xpos = 0
	MOV	r0,#1
	STR	r0,newgob
	BL	decoder_reset
	B	gMBsac_gob_finished
cumf_COD
	DCD	16383, 6849, 0
cumf_MCBPC
	DCD	16383, 4105, 3088, 2367, 1988, 1621, 1612, 1609, 1608, 496, 353, 195, 77, 22, 17, 12, 5, 4, 3, 2, 1, 0
cumf_MCBPC_intra
	DCD	16383, 7410, 6549, 5188, 442, 182, 181, 141, 1, 0
cumf_MODB
	DCD	16383, 6062, 2130, 0
cumf_UVCBPB
	DCD	16383, 491, 0
cumf_YCBPB
	DCD	16383, 6062, 0
cumf_CBPY_intra
	DCD	16383, 13619, 13211, 12933, 12562, 12395, 11913, 11783, 11004
	DCD	10782, 10689, 9928, 9353, 8945, 8407, 7795, 0
cumf_CBPY
	DCD	16383, 14481, 13869, 13196, 12568, 11931, 11185, 10814, 9796
	DCD	9150, 8781, 7933, 6860, 6116, 4873, 3538, 0
cumf_DQUANT
	DCD	16383, 12287, 8192, 4095, 0
cumf_MVD
	DCD	16383, 16380, 16369, 16365, 16361, 16357, 16350, 16343, 16339
	DCD	16333, 16326, 16318, 16311, 16306, 16298, 16291, 16283, 16272
	DCD	16261, 16249, 16235, 16222, 16207, 16175, 16141, 16094, 16044
	DCD	15936, 15764, 15463, 14956, 13924, 11491, 4621, 2264, 1315
	DCD	854, 583, 420, 326, 273, 229, 196, 166, 148, 137, 123, 114, 101
	DCD	91, 82, 76, 66, 59, 53, 46, 36, 30, 26, 24, 18, 14, 10, 5, 0
agetMBs_sac
        FunctionEntry "r4-r11"

	BL	mark_top_mvs

	MOV	r4,#0
	STR	r4,newgob
	MOV	r5,#0
getMBs_sac_mainloop
	LDR	r6,mb_height
	LDR	r7,quant
	; r4 = xpos
	; r5 = ypos
	; r6 = mb_height
	; r7 = quant
	MOV	r0,#22
	BL	ashowbits
	MOVS	r0,r0,ASR#6
	BEQ	gMBsac_startcode
gMBsac_finish_gob
	; The following works by the observation that xpos >= 0 at all times.
	RSBS	r0,r4,#0	; if ((xpos <= 0) &&
	CMPGE	r5,#1		;		     (ypos > 0))
	STRGE	r0,newgob	;   newgob = 0
gMBsac_gob_finished
gMBsac_startcode_SE
	CMP	r5,r6			; if (ypos >= mb_height)
        Return  "r4-r11",, GE           ;   return
gMBsac_read_cod
	LDR	r8,pict_type
	MOV	r0,#0
	CMP	r8,#1
	MOVEQ	R1,#3
	ADREQ	r0,cumf_COD
	BLEQ	decode_a_symbol		; r0 = COD
	MOVS	r9,r0			; if (COD == 1)
	BNE	gMBsac_cod1		;   {skip forwards to that bit}
	; if (COD == 0)
	CMP	r8,#1			; if (pict_type == PCT_INTER) {
	ADREQ	r0,cumf_MCBPC
	ADRNE	r0,cumf_MCBPC_intra
	MOVEQ	r1,#22
	MOVNE	r1,#10
      [ {CONFIG} <> 26
        ; A handy spare register steps in to save the day
        MOV     r11,r8
      ]
	SUB	r8,r1,#2		; r8 = Illegal value
	BL	decode_a_symbol		; MCBPC = r0 = decode_a_symbol(...,...);
      [ {CONFIG} <> 26
        ; Flags aren't preserved across decode_a_symbol any more,
        ; so we need to re-calculate the condition...
        CMP     r11,#1                  ; if (pict_type == PCT_INTER) {
      ]
	MOV	r11,r0,LSR#2		; Mode = MCBPC>>2;
	ADDNE	r11,r11,#3		; Mode = MCBPC>>2 ( + 3 maybe);
	CMP	r0,r8			; if (MCBPC == r0)
	BEQ	gMBsac_read_cod		;   goto read_cod_sac;
	LDR	r1,pb_frame
	AND	r10,r0,#3		; CBP = (MCBPC & 3);
	; r4 = xpos
	; r5 = ypos
	; r6 = mb_height
	; r7 = quant
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r1,#1			; if (pb_frame) {
	BLT	gMBsac_nopb		;   (done so we get there with LT)
	ORR	r10,r10,#15<<14		; CBP = CBP | (15<<14)
	MOV	r1,#4
	ADR	r0,cumf_MODB
	BL	decode_a_symbol
	SUBS	r8,r0,#2		; r8 = MODB-2
	BLT	gMBsac_nopb
gMBsac_pblp1
	TST	r10,#1<<(14+3)
	ADREQ	r0,cumf_UVCBPB
	ADRNE	r0,cumf_YCBPB
	MOV	r1,#3
	BL	decode_a_symbol		; d = decode_a_symbol(cumf_?CBPB,3)
	ORR	r10,r0,r10,LSL#1	; CBP = d | (CBP << 1)
	CMP	r10,#1<<(14+3+6)
	BLT	gMBsac_pblp1
gMBsac_nopb
	; So GE when we fall through to here
	; LT when we get here from above
	MOVLT	r10,r10,LSL#6
	; r4 = xpos
	; r5 = ypos
	; r6 = mb_height
	; r7 = quant
	; r8 = MODB-2
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r11,#3	; if (Mode == MODE_INTRA or MODE_INTRA_Q) {
	ADRGE	r0,cumf_CBPY_intra
	ADRLT	r0,cumf_CBPY
	MOV	r1,#17
	BL	decode_a_symbol
      [ {CONFIG} <> 26
        ; Flags now corrupted by decode_a_symbol
        CMP     r11,#3  ; if (Mode == MODE_INTRA or MODE_INTRA_Q) {
      ]
	RSBLT	r0,r0,#15
	ORR	r10,r10,r0,LSL#8	; CBP |= (CBPY<<8)
	CMP	r11,#1			; if (Mode == MODE_INTER_Q ||
	CMPNE	r11,#4			; 		MODE == MODE_INTRA_Q) {
	BNE	gMBsac_nodq		; (1 or 4)
	MOV	r1,#5
	ADR	r0,cumf_DQUANT
	BL	decode_a_symbol		; d = decode_a_symbol(cumf_DQUANT,5)
	SUBS	r0,r0,#1		; 0 => -1, 1 => 0, 2 => 1, 3 => 2
	SUBEQ	r0,r0,#2		; 0 => -1, 1 =>-2, 2 => 1, 3 => 2
	ADDS	r7,r7,r0		; quant += dquanttab[d]
	MOVLE	r7,#1			; if (quant < 1) quant = 1
	CMP	r7,#31			; if (quant > 31)
	MOVGT	r7,#31			;   quant = 31;
gMBsac_nodq
	STR	r7,quant
	RSBS	r0,r11,#2		; if ((Mode <= 2)      === (2-Mode >= 0)
	LDR	r12,pb_frame		;                 ||
	MOVEQ	r0,#1
	MOVNE	r0,#0			; r0 = (Mode == MODE_INTER4V ? 1 : 0)
	CMPLT	r12,#1			;                    pbframe)
	BLT	gMBsac_nomv		; {
	STMFD	r13!,{r9,r10}				; {{{ 2 on stack }}}
	MOV	r10,r4			; r10= xpos
	MOVS	r4,r0			; r4 = startMV = (Mode == 2)
	MOV	r7,r4,LSL#2		; r7 = stopMV
	; Set up R6 = MV_INDEX(0,startmv,ypos+1,xpos+1)
	LDR	r6,MV
	ADD	r0,r5,#1		; r0 = ypos+1
	LDR	r2,MV_d3_log
	ADD	r1,r10,#1		; r1 = xpos+1
	ADD	r0,r0,r1,LSL r2
	ADD	r0,r0,r0,LSL#2
	ADD	r6,r6,r0,LSL#3	; r10 = MV_INDEX(0,0,y,x)
	ADDNE	r6,r6,#8	; r10 = MV_INDEX(0,startmv,y,x)
gMBsac_mvlp1
	ADR	r0,cumf_MVD
	MOV	r1,#65
	BL	decode_a_symbol
	EOR	r9,r0,#32
	ADR	r0,cumf_MVD
	MOV	r1,#65
	BL	decode_a_symbol
	EOR	r1,r0,#32	; r1 = mvy
	MOV	r0,r9		; r0 = mvx
	MOV	r2,r10		; r2 = xpos
	MOV	r3,r5		; r3 = ypos
	BL	find_pmv
	STMIA	r6!,{r0,r1}
	ADD	r4,r4,#1
	CMP	r4,r7
	BLE	gMBsac_mvlp1
	MOV	r4,r10
	LDR	r12,pb_frame
	LDMFD	r13!,{r9,r10}				; {{{ 0 on stack }}}
	; r4 = xpos
	; r5 = ypos
	; r8 = MODB-2
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r12,#0
	BEQ	gMBsac_nopb2
	CMP	r8,#-2
	MOVEQ	r0,#0
	MOVEQ	r1,#0
	BEQ	gMBsac_endpb2
	ADR	r0,cumf_MVD
	MOV	r1,#65
	BL	decode_a_symbol
	EOR	r8,r0,#32
	ADR	r0,cumf_MVD
	MOV	r1,#65
	BL	decode_a_symbol
	EOR	r1,r0,#32
	MOV	r0,r8
	MOV	r2,#0
	MOV	r3,#0
	BL	motion_decode
gMBsac_endpb2
	STMFD	r13!,{r0,r1}				; {{{ 2 on stack }}}
gMBsac_nopb2
gMBsac_nomv
	; r4 = xpos
	; r5 = ypos
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	MOV	r7,#5		; r7 = 5-comp
	LDR	r8,base+&2c	; bp = ld->block;
	CMP	r11,#3
	BLT	gMBsac_non_intra
gMBsac_bbintralp		; for (comp=0; comp<6; comp++) {
	ADR	r0,cumf_INTRADC	;   bp[0] = decode_a_symbol(cumf_INTRADC,255)+1;
	MOV	r1,#255
	BL	decode_a_symbol
	ADD	r0,r0,#1
	MOV	r0,r0,LSL#3	;   bp[0] *= 8; /* Iquant */
	STR	r0,[r8]
	TST	r10,#2048		;   if (CBP & 32) {
	BEQ	gMBsac_bbintra_emptycomp
	MOV	r0,r8
	BL	memset63	;     memset63(bp);
	RSB	r0,r7,#5	;     r0 = comp
	MOV	r1,#1		;     r1 = 1
	BL	get_sac_block	;     get_sac_block(comp,1);
				;   }
	MOV	r10,r10,LSL#1	;   CBP <<= 1;
	ADD	r8,r8,#64*4	;   bp += 64;
	SUBS	r7,r7,#1	; }
	BGE	gMBsac_bbintralp
	B	gMBsac_afterdecblk
cumf_INTRADC
	DCD	16383, 16380, 16379, 16378, 16377, 16376, 16370, 16361, 16360
	DCD	16359, 16358, 16357, 16356, 16355, 16343, 16238, 16237, 16236
	DCD	16230, 16221, 16220, 16205, 16190, 16169, 16151, 16130, 16109
	DCD	16094, 16070, 16037, 16007, 15962, 15938, 15899, 15854, 15815
	DCD	15788, 15743, 15689, 15656, 15617, 15560, 15473, 15404, 15296
	DCD	15178, 15106, 14992, 14868, 14738, 14593, 14438, 14283, 14169
	DCD	14064, 14004, 13914, 13824, 13752, 13671, 13590, 13515, 13458
	DCD	13380, 13305, 13230, 13143, 13025, 12935, 12878, 12794, 12743
	DCD	12656, 12596, 12521, 12443, 12359, 12278, 12200, 12131, 12047
	DCD	12002, 11948, 11891, 11828, 11744, 11663, 11588, 11495, 11402
	DCD	11288, 11204, 11126, 11039, 10961, 10883, 10787, 10679, 10583
	DCD	10481, 10360, 10227, 10113, 9961, 9828, 9717, 9584, 9485, 9324
	DCD	9112, 9019, 8908, 8766, 8584, 8426, 8211, 7920, 7663, 7406, 7152
	DCD	6904, 6677, 6453, 6265, 6101, 5904, 5716, 5489, 5307, 5056, 4850
	DCD	4569, 4284, 3966, 3712, 3518, 3342, 3206, 3048, 2909, 2773, 2668
	DCD	2596, 2512, 2370, 2295, 2232, 2166, 2103, 2022, 1956, 1887, 1830
	DCD	1803, 1770, 1728, 1674, 1635, 1599, 1557, 1500, 1482, 1434, 1389
	DCD	1356, 1317, 1284, 1245, 1200, 1179, 1140, 1110, 1092, 1062, 1044
	DCD	1035, 1014, 1008, 993, 981, 954, 936, 912, 894, 876, 864, 849
	DCD	828, 816, 801, 792, 777, 756, 732, 690, 660, 642, 615, 597, 576
	DCD	555, 522, 489, 459, 435, 411, 405, 396, 387, 375, 360, 354, 345
	DCD	344, 329, 314, 293, 278, 251, 236, 230, 224, 215, 214, 208, 199
	DCD	193, 184, 178, 169, 154, 127, 100, 94, 73, 37, 36, 35, 34, 33
	DCD	32, 31, 30, 29, 28, 27, 26, 20, 19, 18, 17, 16, 15, 9, 0
quants_stored_ptr
	DCD	0
gMBsac_cod1
	; r4 = xpos
	; r5 = ypos
	; r8 = MODB-2
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r5,r6			; if (ypos >= mb_height)
        Return  "r4-r11",, GE           ;   return
	MOV	r11,#8			; Mode = MODE_INTER | MODE_COD;
	MOV	r10,#0			; /* Reset CBP */ CBP = 0;
	; /* reset motion vectors */
	LDR	r6,MV
	ADD	r0,r5,#1		; r0 = ypos+1
	LDR	r2,MV_d3_log
	ADD	r1,r4,#1		; r1 = xpos+1
	ADD	r2,r0,r1,LSL r2
	ADD	r0,r2,r2,LSL#2
	ADD	r6,r6,r0,LSL#3		; r6 = MV_INDEX(0,0,y,x)
	; p = MV_INDEX(0,0,ypos+1,xpos+1);
	MOV	r0,#0
	MOV	r1,#0
	LDR	r12,pb_frame
	STMIA	r6!,{r0-r1}	; *(p)   = 0;
				; *(p+1) = 0;
	CMP	r12,#0
	STMNEFD	r13!,{r0-r1}	; mvdbx = 0;
				; mvdby = 0;
	B	gMBsac_decdone2
gMBsac_bbnonintra_emptycomp
	SUBS	r7,r7,#1	; }
	MOV	r10,r10,LSL#1	;   CBP <<= 1;
	ADD	r8,r8,#64*4	;   bp += 64;
	BLT	gMBsac_afterdecblk
gMBsac_non_intra
		; for (comp=0; comp<6; comp++) {
gMBsac_non_intralp
	TST	r10,#2048		;   if (CBP & 32) {
	BEQ	gMBsac_bbnonintra_emptycomp
	MOV	r0,r8		;     memset64(bp);
	BL	memset64
	RSB	r0,r7,#5	;     get_sac_block(comp,0);
	MOV	r1,#0
	BL	get_sac_block 	;   }
	MOV	r10,r10,LSL#1	;   CBP <<= 1;
	ADD	r8,r8,#64*4	;   bp += 64;
	SUBS	r7,r7,#1	; }
	BGE	gMBsac_non_intralp
gMBsac_afterdecblk
	LDR	r12,pb_frame
	MOV	r7,#6
	CMP	r12,#0
	MOVEQ	r10,r10,LSL#6
	BEQ	gMBsac_nopbtodec
gMBsac_pbdeclp
	TST	r10,#2048		;   if (CBP & 2048) {
	BEQ	gMBsac_pbdecskip
	MOV	r0,r8		;     memset64(bp);
	BL	memset64
	MOV	r0,r7		;     get_sac_block(comp,0);
	MOV	r1,#0
	BL	get_sac_block
gMBsac_pbdecskip			;   }
	MOV	r10,r10,LSL#1	;   CBP <<= 1;
	ADD	r8,r8,#64*4	;   bp += 64;
	ADD	r7,r7,#1	; }
	CMP	r7,#12
	BLT	gMBsac_pbdeclp
gMBsac_nopbtodec
	; r4 = xpos
	; r5 = ypos
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
gMBsac_decdone
	LDR	r2,MV_d3_log
	ADD	r1,r4,#1	; r2 = xpos+1
	ADD	r3,r5,#1	; r3 = ypos+1
	ADD	r2,r3,r1,LSL r2	; r2 =    (ypos+1) + (xpos+1)<<MV_d3_log
	LDR	r12,pb_frame
gMBsac_decdone2
	LDR	r0,modemap
	LDR	r1,MV
	STRB	r11,[r0,r2]	; *MM_INDEX(ypos+1, xpos+1) = Mode
	AND	r11,r11,#7	; MODE_MASK
	RSBS	r0,r11,#3	; if (Mode==MODE_INTRA || Mode==MODE_INTRA_Q)
				; === if (Mode>=3)
				; === if (3-Mode <= 0)
	CMPLE	r12,#0		;   if (!pb_frame)
	BGT	gMBsac_not_intra_pb
	ADD	r2,r2,r2,LSL#2	; r3 = 5*((ypos+1) + (xpos+1)<<MV_d3_log)
	MOV	r0,#0		; p = MV_INDEX(0,0,ypos+1,xpos+1);
	STR	r0,[r1,r2,LSL#3]!;*(p) = 0;
	STR	r0,[r1,#4]	; *(p+1) = 0;
gMBsac_not_intra_pb
	; r4 = xpos
	; r5 = ypos
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r12,#0
	BEQ	gMBsac_not_pb2
	MOV	r0,#0
	MOV	r1,r4,LSL#4
	MOV	r2,r5,LSL#4
	LDMFD	r13!,{r6,r7}
	MOV	r3,r6
	STMFD	r13!,{r7}	; mvdby on stack
	BL	reconstruct
	ADD	r13,r13,#4
gMBsac_not_pb2
	; r4 = xpos
	; r5 = ypos
	; r6 = mvdbx (if defined)
	; r7 = mvdby (if defined)
	; r9 = cod
	; r10 = CBP
	; r11 = Mode
	CMP	r11,#3
	BGE	gMBsac_norecon
	MOV	r0,#1
	MOV	r1,r4,LSL#4
	MOV	r2,r5,LSL#4
	MOV	r3,#0
	STMFD	r13!,{r3}	; 0 on stack
	BL	reconstruct
	ADD	r13,r13,#4	; Pop remaining word off stack.
gMBsac_norecon
	MOV	r8,#5
gMBsac_reconlp
	CMP	r11,#2
	MOV	r3,#1
	MOVGT	r3,#0		; GT (& hence NE) if Mode=INTRA or INTRA_Q
	TSTLE	r10,#8388608
	RSB	r0,r8,#5
	MOV	r1,r4,LSL#4
	MOV	r2,r5,LSL#4
	BLNE	addblock
	MOV	r10,r10,LSL#1
	SUBS	r8,r8,#1
	BGE	gMBsac_reconlp
	LDR	r12,pb_frame
	MOV	r8,#5
	CMP	r12,#1
	BNE	gMBsac_nopbrecon
	CMP	r9,#0
	BNE	gMBsac_pbreconcod1
	STMFD	r13!,{r6,r7}	; mvdbx mvdby on stack
gMBsac_pbreconlp1
	RSB	r0,r8,#5
	MOV	r1,r4,LSL#4
	MOV	r2,r5,LSL#4
	MOV	r3,r11
	BL	reconblock_b
	SUBS	r8,r8,#1
	BGE	gMBsac_pbreconlp1
	ADD	r13,r13,#8
gMBsac_pbreconcod1
	MOV	r8,#6
gMBsac_pbreconlp2
	MOV	r0,r8
	MOV	r1,r4,LSL#4
	MOV	r2,r5,LSL#4
	MOV	r3,#1
	TST	r10,#8388608
	BLNE	addblock
	MOV	r10,r10,LSL#1
	ADD	r8,r8,#1
	CMP	r8,#12
	BLT	gMBsac_pbreconlp2
gMBsac_nopbrecon
	LDR	r0,mb_width
	ADD	r4,r4,#1
	CMP	r4,r0
	MOVGE	r4,#0
	ADDGE	r5,r5,#1
	B	getMBs_sac_mainloop
gMBsac_bbintra_emptycomp
	LDR	r1,base+&30
	MOV	r0,#63
	SUB	r1,r1,r7,LSL#2	; r1 = &ld->zsc[comp-5]
	STR	r0,[r1,#5*4]	; ld->zsc[comp] = 63;
	MOV	r10,r10,LSL#1	;   CBP <<= 1;
	ADD	r8,r8,#64*4	;   bp += 64;
	SUBS	r7,r7,#1	; }
	BGE	gMBsac_bbintralp
	B	gMBsac_afterdecblk

mb_height
        DCD     0
base
	DCD	1	; unsigned char *rdptr
	DCD	0	; unsigned char inbrf[16]
	DCD	0
	DCD	0
	DCD	0
	DCD	0	; int incnt
	DCD	0	; int bitcnt
	DCD	0	; unsigned char *source
	DCD	0	; unsigned char *dest
	DCD	0	; unsigned char *table
	DCD	0	; int bitsthru
	DCD	0	; int *block
	DCD	0	; int *zsc
bquant
        DCD     0
quant
        DCD     0
escape
        MOV      r0, #&f
        BL       agetbits
        MOV      r2,#&3f
        AND      r3,r2,r0,LSR #8
        AND      r2,r0,#&ff
        MOV      r0,r0,LSR #14
        MOVS     r1,r2,LSR #7
        RSBNE    r2,r2,#&100
        B escape_return
DCT3Dtab0
	DCD (4225+(7<<16))
	DCD (4209+(7<<16))
	DCD (4193+(7<<16))
	DCD (4177+(7<<16))
	DCD (193+(7<<16))
	DCD (177+(7<<16))
	DCD (161+(7<<16))
	DCD (4+(7<<16))
	DCD (4161+(6<<16))
	DCD (4161+(6<<16))
	DCD (4145+(6<<16))
	DCD (4145+(6<<16))
	DCD (4129+(6<<16))
	DCD (4129+(6<<16))
	DCD (4113+(6<<16))
	DCD (4113+(6<<16))
	DCD (145+(6<<16))
	DCD (145+(6<<16))
	DCD (129+(6<<16))
	DCD (129+(6<<16))
	DCD (113+(6<<16))
	DCD (113+(6<<16))
	DCD (97+(6<<16))
	DCD (97+(6<<16))
	DCD (18+(6<<16))
	DCD (18+(6<<16))
	DCD (3+(6<<16))
	DCD (3+(6<<16))
	DCD (81+(5<<16))
	DCD (81+(5<<16))
	DCD (81+(5<<16))
	DCD (81+(5<<16))
	DCD (65+(5<<16))
	DCD (65+(5<<16))
	DCD (65+(5<<16))
	DCD (65+(5<<16))
	DCD (49+(5<<16))
	DCD (49+(5<<16))
	DCD (49+(5<<16))
	DCD (49+(5<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (4097+(4<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (1+(2<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (17+(3<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (33+(4<<16))
	DCD (2+(4<<16))
	DCD (2+(4<<16))
	DCD (2+(4<<16))
 	DCD (2+(4<<16))
	DCD (2+(4<<16))
	DCD (2+(4<<16))
	DCD (2+(4<<16))
	DCD (2+(4<<16))
DCT3Dtab1
	DCD (9+(10<<16))
	DCD (8+(10<<16))
	DCD (4481+(9<<16))
	DCD (4481+(9<<16))
	DCD (4465+(9<<16))
	DCD (4465+(9<<16))
	DCD (4449+(9<<16))
	DCD (4449+(9<<16))
	DCD (4433+(9<<16))
	DCD (4433+(9<<16))
	DCD (4417+(9<<16))
	DCD (4417+(9<<16))
	DCD (4401+(9<<16))
	DCD (4401+(9<<16))
	DCD (4385+(9<<16))
	DCD (4385+(9<<16))
	DCD (4369+(9<<16))
	DCD (4369+(9<<16))
	DCD (4098+(9<<16))
	DCD (4098+(9<<16))
	DCD (353+(9<<16))
	DCD (353+(9<<16))
	DCD (337+(9<<16))
	DCD (337+(9<<16))
	DCD (321+(9<<16))
	DCD (321+(9<<16))
	DCD (305+(9<<16))
	DCD (305+(9<<16))
	DCD (289+(9<<16))
	DCD (289+(9<<16))
	DCD (273+(9<<16))
	DCD (273+(9<<16))
	DCD (257+(9<<16))
	DCD (257+(9<<16))
	DCD (241+(9<<16))
	DCD (241+(9<<16))
	DCD (66+(9<<16))
	DCD (66+(9<<16))
	DCD (50+(9<<16))
	DCD (50+(9<<16))
	DCD (7+(9<<16))
	DCD (7+(9<<16))
	DCD (6+(9<<16))
	DCD (6+(9<<16))
	DCD (4353+(8<<16))
	DCD (4353+(8<<16))
	DCD (4353+(8<<16))
	DCD (4353+(8<<16))
	DCD (4337+(8<<16))
	DCD (4337+(8<<16))
	DCD (4337+(8<<16))
	DCD (4337+(8<<16))
	DCD (4321+(8<<16))
	DCD (4321+(8<<16))
	DCD (4321+(8<<16))
	DCD (4321+(8<<16))
	DCD (4305+(8<<16))
	DCD (4305+(8<<16))
	DCD (4305+(8<<16))
	DCD (4305+(8<<16))
	DCD (4289+(8<<16))
	DCD (4289+(8<<16))
	DCD (4289+(8<<16))
	DCD (4289+(8<<16))
	DCD (4273+(8<<16))
	DCD (4273+(8<<16))
	DCD (4273+(8<<16))
	DCD (4273+(8<<16))
	DCD (4257+(8<<16))
	DCD (4257+(8<<16))
	DCD (4257+(8<<16))
	DCD (4257+(8<<16))
	DCD (4241+(8<<16))
	DCD (4241+(8<<16))
	DCD (4241+(8<<16))
	DCD (4241+(8<<16))
	DCD (225+(8<<16))
	DCD (225+(8<<16))
	DCD (225+(8<<16))
	DCD (225+(8<<16))
	DCD (209+(8<<16))
	DCD (209+(8<<16))
	DCD (209+(8<<16))
	DCD (209+(8<<16))
	DCD (34+(8<<16))
	DCD (34+(8<<16))
	DCD (34+(8<<16))
	DCD (34+(8<<16))
	DCD (19+(8<<16))
	DCD (19+(8<<16))
	DCD (19+(8<<16))
	DCD (19+(8<<16))
	DCD (5+(8<<16))
	DCD (5+(8<<16))
	DCD (5+(8<<16))
	DCD (5+(8<<16))

DCT3Dtab2
	DCD (4114+(11<<16))
	DCD (4114+(11<<16))
	DCD (4099+(11<<16))
	DCD (4099+(11<<16))
	DCD (11+(11<<16))
	DCD (11+(11<<16))
	DCD (10+(11<<16))
	DCD (10+(11<<16))
	DCD (4545+(10<<16))
	DCD (4545+(10<<16))
	DCD (4545+(10<<16))
	DCD (4545+(10<<16))
	DCD (4529+(10<<16))
	DCD (4529+(10<<16))
	DCD (4529+(10<<16))
	DCD (4529+(10<<16))
	DCD (4513+(10<<16))
	DCD (4513+(10<<16))
	DCD (4513+(10<<16))
	DCD (4513+(10<<16))
	DCD (4497+(10<<16))
	DCD (4497+(10<<16))
	DCD (4497+(10<<16))
	DCD (4497+(10<<16))
	DCD (146+(10<<16))
	DCD (146+(10<<16))
	DCD (146+(10<<16))
	DCD (146+(10<<16))
	DCD (130+(10<<16))
	DCD (130+(10<<16))
	DCD (130+(10<<16))
	DCD (130+(10<<16))
	DCD (114+(10<<16))
	DCD (114+(10<<16))
	DCD (114+(10<<16))
	DCD (114+(10<<16))
	DCD (98+(10<<16))
	DCD (98+(10<<16))
	DCD (98+(10<<16))
	DCD (98+(10<<16))
	DCD (82+(10<<16))
	DCD (82+(10<<16))
	DCD (82+(10<<16))
	DCD (82+(10<<16))
	DCD (51+(10<<16))
	DCD (51+(10<<16))
	DCD (51+(10<<16))
	DCD (51+(10<<16))
	DCD (35+(10<<16))
	DCD (35+(10<<16))
	DCD (35+(10<<16))
	DCD (35+(10<<16))
	DCD (20+(10<<16))
	DCD (20+(10<<16))
	DCD (20+(10<<16))
	DCD (20+(10<<16))
	DCD (12+(11<<16))
	DCD (12+(11<<16))
	DCD (21+(11<<16))
	DCD (21+(11<<16))
	DCD (369+(11<<16))
	DCD (369+(11<<16))
	DCD (385+(11<<16))
	DCD (385+(11<<16))
	DCD (4561+(11<<16))
	DCD (4561+(11<<16))
	DCD (4577+(11<<16))
	DCD (4577+(11<<16))
	DCD (4593+(11<<16))
	DCD (4593+(11<<16))
	DCD (4609+(11<<16))
	DCD (4609+(11<<16))
	DCD (22+(12<<16))
	DCD (36+(12<<16))
	DCD (67+(12<<16))
	DCD (83+(12<<16))
	DCD (99+(12<<16))
	DCD (162+(12<<16))
	DCD (401+(12<<16))
	DCD (417+(12<<16))
	DCD (4625+(12<<16))
	DCD (4641+(12<<16))
	DCD (4657+(12<<16))
	DCD (4673+(12<<16))
	DCD (4689+(12<<16))
	DCD (4705+(12<<16))
	DCD (4721+(12<<16))
	DCD (4737+(12<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
	DCD (7167+(7<<16))
getblock
        FunctionEntry "r4-r11"
        MOV      r5,r0
        LDR      r8,quant			; r8=quant
        CMP      r5,#6
        BLT      calcQP_over
        LDR      r12,bquant			; r12= bquant
        ADD	 r12,r12,#5			; bquant_tab[bquant]
        MUL      r8,r12,r8	; r8=bquant_tab[bquant]*quant
        MOVS	r8,r8,ASR #2	; r8=bquant_tab[bquant]*quant>>2
	MOVLE	r8,#1		; r8=max(1,bquant_tab[bquant]*quant>>2)
        CMP      r8,#31
        MOVGT    r8,#31		; r8=min(31,max(1,bquant_tab[bquant]*quant>>2))
calcQP_over	; r8 = QP
        MOV      r4,r1			; r4 = i;
        LDR      r0,base+&2c
        ADR      r11,zig_zag_scan
        ADD      r9,r0,r5,LSL #8	; r9 = ld->block+comp<<6
	MOV	r6,#&1bc0
	ADD	r6,r6,#&3f
gb_loop
        MOV      r0,#&c
        BL       ashowbits		; r0 = code = showbits(12)
        ;CMP      r0,#8			; if (code<8)
        ;BLT      error			;   goto getblockerror
	ADR	 r1,DCT3Dtab2			; r1 = &DCT3dtab2[0]
        MOV      r2,#8			; r2 = sub = 8
        CMP      r0,#128		; if (code>=128) {
        ADRGE    r1,DCT3Dtab1		;   tab -= ???
        MOVGE    r0,r0,ASR #2		;   code >>= 2
        MOVGE    r2,#32			;   sub = 32; }
        CMP      r0,#(512>>2)		; if (code>=(512>>2)) {
        MOVGE    r0,r0,ASR #3		;   code >>= 3;
        MOVGE    r2,#16			;   sub = 16; }
	SUB	 r0,r0,r2		; code - sub
        ADRGEL   r1,DCT3Dtab0		;   tab -= ???;
        LDR      r7,[r1,r0,LSL#2]	; level = *(tab + code - sub);
        MOV      r0,r7,ASR #16		; flushbits(level>>16);
        BL       aflushbits
        MOV      r0,r7,LSL #16		;
        MOV      r0,r0,LSR #16          ;
        CMP	r6,r0			; if ((level & 65535) != ESCAPE)
        BEQ      escape			; {
        BL       agetbits1		;   sign = getbits(1);
        MOV      r1,r0			;   r1 = sign
        MOV      r0,#&ff		;
        AND      r3,r0,r7,LSR #4	;   r3 = run = (level>>4) & 255
        MOV      r0,r7,LSR #12		;   r0 = last = level>>12
        AND      r2,r7,#&f		;   r2 = level = level & 15
escape_return
        ; r0 = last
        ; r1 = sign
        ; r2 = level
        ; r3 = run
        ADD      r4,r4,r3		; r4 = i += run
;Consider shifting i left by 24
        ;CMP      r4,#64			; if (i>=64)
        ;BGE      error			;   goto getblockerror

	MOV	 r2,r2,LSL#1            ;                2*level
        ADD      r2,r2,#1		;                2*level+1
        MUL      r2,r8,r2		; r2 = x = QP * (2*level+1)
        TST      r8,#1			; if (QP & 1 == 0)
        SUBEQ	 r2,r2,#1		;   x -= 1
        CMP	 r1,#0			; if (sign)
        LDRB     r1,[r11,r4]		; zig_zag_scan[i]
        RSBNE    r2,r2,#0		;   x = -x;
        STR      r2,[r9,r1,LSL #2]	; bp[zig_zag_scan[i]] = x;

        TST      r0,#1			; if (last & 1 == 0) {
        ADDEQ    r4,r4,#1		;   i++
        BEQ      gb_loop			;   loop back }

        LDR      r1,base+&30
        RSB	R0,R4,#&3f
        STR      r0,[r1,r5,LSL #2]
        Return   "r4-r11"
zig_zag_scan
	DCB	0
	DCB	8
	DCB	1
	DCB	2
	DCB	9
	DCB	16
	DCB	24
	DCB	17

	DCB	10
	DCB	3
	DCB	4
	DCB	11
	DCB	18
	DCB	25
	DCB	32
	DCB	40

	DCB	33
	DCB	26
	DCB	19
	DCB	12
	DCB	5
	DCB	6
	DCB	13
	DCB	20

	DCB	27
	DCB	34
	DCB	41
	DCB	48
	DCB	56
	DCB	49
	DCB	42
	DCB	35

	DCB	28
	DCB	21
	DCB	14
	DCB	7
	DCB	15
	DCB	22
	DCB	29
	DCB	36

	DCB	43
	DCB	50
	DCB	57
	DCB	58
	DCB	51
	DCB	44
	DCB	37
	DCB	30

	DCB	23
	DCB	31
	DCB	38
	DCB	45
	DCB	52
	DCB	59
	DCB	60
	DCB	53

	DCB	46
	DCB	39
	DCB	47
	DCB	54
	DCB	61
	DCB	62
	DCB	55
	DCB	63
;error
;        MOV      r0,#1
;        STR      r0,fault
;        Return  "r4-r11"
;fault
;        DCD     0
get_sac_block
	; r0 = int comp
	; r1 = int ptype
        FunctionEntry "r4-r9,r11"

	MOV	r9,r0
	LDR	r8,quant
        CMP	r0,#6
        BLT	calcQP_over2
	LDR	r12,bquant	; r12= bquant
        ADD	r12,r12,#5	; bquant_tab[bquant]
        MUL	r8,r12,r8	; r8=bquant_tab[bquant]*quant
        MOVS	r8,r8,ASR #2	; r8=bquant_tab[bquant]*quant>>2
	MOVLE	r8,#1		; r8=max(1,bquant_tab[bquant]*quant>>2)
        CMP	r8,#31
        MOVGT	r8,#31		; r8=min(31,max(1,bquant_tab[bquant]*quant>>2))
calcQP_over2			; r8 = QP
        MOV	r4,r1		; r4 = i;
        LDR	r6,base+&2c
        MOV	r7,r1		; r7 = position<<1|ptype;
        ADD	r6,r6,r0,LSL #8	; r6 = ld->block+comp<<6
gsb_loop
	ADD	r7,r7,#2	; r7 = position++
	; TCOEF_index = aDecodeTCoef
	CMP	r7,#8
	ANDGE	r0,r7,#1
	MOVLT	r0,r7
	; Times by 104
	ADR	r1,cumf_TCOEFr
	ADD	r1,r1,r0,LSL#3+2
	ADD	r1,r1,r0,LSL#5+2
	ADD	r0,r1,r0,LSL#6+2
	MOV	r1,#104
	BL	decode_a_symbol
	CMP	r0,#102		; if (TCOEF_index == ESCAPE_INDEX) {
	BEQ	gsb_escape 	; } else {
	ADR	r1,tcoeftab
	LDR	r11,[r1,r0,LSL#2]
	; vlc_word_decode
        ADR	r0,cumf_SIGN
        MOV	r1,#3
        BL	decode_a_symbol
        ; r0 = sign
	AND	r2,r11,#15
	MOV	r1,r11,LSR#12	; r1 = last
	AND	r3,r11,#255<<4
	ADD	r4,r4,r3,LSR#4	; r4 = i += run
gsb_escaperet
        ; r0 = sign
        ; r1 = last
	; r2 = val
        ; r3 = run

	MOV	r2,r2,LSL#1		;                2*level
        ADD	r2,r2,#1		;                2*level+1
        MUL	r2,r8,r2		; r2 = x = QP * (2*level+1)
        TST	r8,#1			; if (QP & 1 == 0)
        SUBEQ	r2,r2,#1		;   x -= 1
        CMP	r0,#0			; if (sign)
	ADR	r0,zig_zag_scan
        LDRB	r0,[r0,r4]		; zig_zag_scan[i]
        RSBNE	r2,r2,#0		;   x = -x;
        STR	r2,[r6,r0,LSL #2]	; bp[zig_zag_scan[i]] = x;

        TST	r1,#1			; if (last & 1 == 0) {
        ADDEQ	r4,r4,#1		;   i++
        BEQ	gsb_loop		;   loop back }

        LDR	r1,base+&30
        RSB	r0,r4,#&3f		; zsc[comp] = zsl+63-i; (zsl === 0)
        STR	r0,[r1,r9,LSL #2]

        Return  "r4-r9,r11"
cumf_SIGN
	DCD	16383
	DCD	8416
	DCD	0
tcoeftab
	DCD	1
	DCD	2
	DCD	3
	DCD	4
	DCD	5
	DCD	6
	DCD	7
	DCD	8
	DCD	9
	DCD	10
	DCD	11
	DCD	12
	DCD	17
	DCD	18
	DCD	19
	DCD	20
	DCD	21
	DCD	22
	DCD	33
	DCD	34
	DCD	35
	DCD	36
	DCD	49
	DCD	50
	DCD	51
	DCD	65
	DCD	66
	DCD	67
	DCD	81
	DCD	82
	DCD	83
	DCD	97
	DCD	98
	DCD	99
	DCD	113
	DCD	114
	DCD	129
	DCD	130
	DCD	145
	DCD	146
	DCD	161
	DCD	162
	DCD	177
	DCD	193
	DCD	209
	DCD	225
	DCD	241
	DCD	257
	DCD	273
	DCD	289
	DCD	305
	DCD	321
	DCD	337
	DCD	353
	DCD	369
	DCD	385
	DCD	401
	DCD	417
	DCD	4097
	DCD	4098
	DCD	4099
	DCD	4113
	DCD	4114
	DCD	4129
	DCD	4145
	DCD	4161
	DCD	4177
	DCD	4193
	DCD	4209
	DCD	4225
	DCD	4241
	DCD	4257
	DCD	4273
	DCD	4289
	DCD	4305
	DCD	4321
	DCD	4337
	DCD	4353
	DCD	4369
	DCD	4385
	DCD	4401
	DCD	4417
	DCD	4433
	DCD	4449
	DCD	4465
	DCD	4481
	DCD	4497
	DCD	4513
	DCD	4529
	DCD	4545
	DCD	4561
	DCD	4577
	DCD	4593
	DCD	4609
	DCD	4625
	DCD	4641
	DCD	4657
	DCD	4673
	DCD	4689
	DCD	4705
	DCD	4721
	DCD	4737
	DCD	7167

cumf_TCOEFr
	DCD 16383
	DCD 13216
	DCD 12233
	DCD 11931
	DCD 11822
	DCD 11776
	DCD 11758
	DCD 11748
	DCD 11743
	DCD 11742
	DCD 11741
	DCD 11740
	DCD 11739
	DCD 10203
	DCD 9822
	DCD 9725
	DCD 9691
	DCD 9677
	DCD 9674
	DCD 8759
	DCD 8609
	DCD 8576
	DCD 8566
	DCD 7901
	DCD 7787
	DCD 7770
	DCD 7257
	DCD 7185
	DCD 7168
	DCD 6716
	DCD 6653
	DCD 6639
	DCD 6276
	DCD 6229
	DCD 6220
	DCD 5888
	DCD 5845
	DCD 5600
	DCD 5567
	DCD 5348
	DCD 5327
	DCD 5160
	DCD 5142
	DCD 5004
	DCD 4900
	DCD 4798
	DCD 4743
	DCD 4708
	DCD 4685
	DCD 4658
	DCD 4641
	DCD 4622
	DCD 4610
	DCD 4598
	DCD 4589
	DCD 4582
	DCD 4578
	DCD 4570
	DCD 4566
	DCD 3824
	DCD 3757
	DCD 3748
	DCD 3360
	DCD 3338
	DCD 3068
	DCD 2835
	DCD 2592
	DCD 2359
	DCD 2179
	DCD 1984
	DCD 1804
	DCD 1614
	DCD 1445
	DCD 1234
	DCD 1068
	DCD 870
	DCD 739
	DCD 668
	DCD 616
	DCD 566
	DCD 532
	DCD 489
	DCD 453
	DCD 426
	DCD 385
	DCD 357
	DCD 335
	DCD 316
	DCD 297
	DCD 283
	DCD 274
	DCD 266
	DCD 259
	DCD 251
	DCD 241
	DCD 233
	DCD 226
	DCD 222
	DCD 217
	DCD 214
	DCD 211
	DCD 209
	DCD 208
	DCD 0

cumf_TCOEFr_intra
	DCD 16383
	DCD 12514
	DCD 10776
	DCD 9969
	DCD 9579
	DCD 9306
	DCD 9168
	DCD 9082
	DCD 9032
	DCD 9000
	DCD 8981
	DCD 8962
	DCD 8952
	DCD 7630
	DCD 7212
	DCD 7053
	DCD 6992
	DCD 6961
	DCD 6940
	DCD 6195
	DCD 5988
	DCD 5948
	DCD 5923
	DCD 5370
	DCD 5244
	DCD 5210
	DCD 4854
	DCD 4762
	DCD 4740
	DCD 4384
	DCD 4300
	DCD 4288
	DCD 4020
	DCD 3968
	DCD 3964
	DCD 3752
	DCD 3668
	DCD 3511
	DCD 3483
	DCD 3354
	DCD 3322
	DCD 3205
	DCD 3183
	DCD 3108
	DCD 3046
	DCD 2999
	DCD 2981
	DCD 2974
	DCD 2968
	DCD 2961
	DCD 2955
	DCD 2949
	DCD 2943
	DCD 2942
	DCD 2939
	DCD 2935
	DCD 2934
	DCD 2933
	DCD 2929
	DCD 2270
	DCD 2178
	DCD 2162
	DCD 1959
	DCD 1946
	DCD 1780
	DCD 1651
	DCD 1524
	DCD 1400
	DCD 1289
	DCD 1133
	DCD 1037
	DCD 942
	DCD 849
	DCD 763
	DCD 711
	DCD 591
	DCD 521
	DCD 503
	DCD 496
	DCD 474
	DCD 461
	DCD 449
	DCD 442
	DCD 436
	DCD 426
	DCD 417
	DCD 407
	DCD 394
	DCD 387
	DCD 377
	DCD 373
	DCD 370
	DCD 367
	DCD 366
	DCD 365
	DCD 364
	DCD 363
	DCD 362
	DCD 358
	DCD 355
	DCD 352
	DCD 351
	DCD 350
	DCD 0
cumf_TCOEF1
	DCD 16383
	DCD 13455
	DCD 12458
	DCD 12079
	DCD 11885
	DCD 11800
	DCD 11738
	DCD 11700
	DCD 11681
	DCD 11661
	DCD 11651
	DCD 11645
	DCD 11641
	DCD 10572
	DCD 10403
	DCD 10361
	DCD 10346
	DCD 10339
	DCD 10335
	DCD 9554
	DCD 9445
	DCD 9427
	DCD 9419
	DCD 9006
	DCD 8968
	DCD 8964
	DCD 8643
	DCD 8627
	DCD 8624
	DCD 8369
	DCD 8354
	DCD 8352
	DCD 8200
	DCD 8192
	DCD 8191
	DCD 8039
	DCD 8036
	DCD 7920
	DCD 7917
	DCD 7800
	DCD 7793
	DCD 7730
	DCD 7727
	DCD 7674
	DCD 7613
	DCD 7564
	DCD 7513
	DCD 7484
	DCD 7466
	DCD 7439
	DCD 7411
	DCD 7389
	DCD 7373
	DCD 7369
	DCD 7359
	DCD 7348
	DCD 7321
	DCD 7302
	DCD 7294
	DCD 5013
	DCD 4819
	DCD 4789
	DCD 4096
	DCD 4073
	DCD 3373
	DCD 3064
	DCD 2674
	DCD 2357
	DCD 2177
	DCD 1975
	DCD 1798
	DCD 1618
	DCD 1517
	DCD 1421
	DCD 1303
	DCD 1194
	DCD 1087
	DCD 1027
	DCD 960
	DCD 890
	DCD 819
	DCD 758
	DCD 707
	DCD 680
	DCD 656
	DCD 613
	DCD 566
	DCD 534
	DCD 505
	DCD 475
	DCD 465
	DCD 449
	DCD 430
	DCD 395
	DCD 358
	DCD 335
	DCD 324
	DCD 303
	DCD 295
	DCD 286
	DCD 272
	DCD 233
	DCD 215
	DCD 0
cumf_TCOEF1_intra
	DCD 16383
	DCD 13383
	DCD 11498
	DCD 10201
	DCD 9207
	DCD 8528
	DCD 8099
	DCD 7768
	DCD 7546
	DCD 7368
	DCD 7167
	DCD 6994
	DCD 6869
	DCD 6005
	DCD 5474
	DCD 5220
	DCD 5084
	DCD 4964
	DCD 4862
	DCD 4672
	DCD 4591
	DCD 4570
	DCD 4543
	DCD 4397
	DCD 4337
	DCD 4326
	DCD 4272
	DCD 4240
	DCD 4239
	DCD 4212
	DCD 4196
	DCD 4185
	DCD 4158
	DCD 4157
	DCD 4156
	DCD 4140
	DCD 4139
	DCD 4138
	DCD 4137
	DCD 4136
	DCD 4125
	DCD 4124
	DCD 4123
	DCD 4112
	DCD 4111
	DCD 4110
	DCD 4109
	DCD 4108
	DCD 4107
	DCD 4106
	DCD 4105
	DCD 4104
	DCD 4103
	DCD 4102
	DCD 4101
	DCD 4100
	DCD 4099
	DCD 4098
	DCD 4097
	DCD 3043
	DCD 2897
	DCD 2843
	DCD 1974
	DCD 1790
	DCD 1677
	DCD 1552
	DCD 1416
	DCD 1379
	DCD 1331
	DCD 1288
	DCD 1251
	DCD 1250
	DCD 1249
	DCD 1248
	DCD 1247
	DCD 1236
	DCD 1225
	DCD 1224
	DCD 1223
	DCD 1212
	DCD 1201
	DCD 1200
	DCD 1199
	DCD 1198
	DCD 1197
	DCD 1196
	DCD 1195
	DCD 1194
	DCD 1193
	DCD 1192
	DCD 1191
	DCD 1190
	DCD 1189
	DCD 1188
	DCD 1187
	DCD 1186
	DCD 1185
	DCD 1184
	DCD 1183
	DCD 1182
	DCD 1181
	DCD 1180
	DCD 1179
	DCD 0
cumf_TCOEF2
	DCD 16383
	DCD 13582
	DCD 12709
	DCD 12402
	DCD 12262
	DCD 12188
	DCD 12150
	DCD 12131
	DCD 12125
	DCD 12117
	DCD 12113
	DCD 12108
	DCD 12104
	DCD 10567
	DCD 10180
	DCD 10070
	DCD 10019
	DCD 9998
	DCD 9987
	DCD 9158
	DCD 9037
	DCD 9010
	DCD 9005
	DCD 8404
	DCD 8323
	DCD 8312
	DCD 7813
	DCD 7743
	DCD 7726
	DCD 7394
	DCD 7366
	DCD 7364
	DCD 7076
	DCD 7062
	DCD 7060
	DCD 6810
	DCD 6797
	DCD 6614
	DCD 6602
	DCD 6459
	DCD 6454
	DCD 6304
	DCD 6303
	DCD 6200
	DCD 6121
	DCD 6059
	DCD 6012
	DCD 5973
	DCD 5928
	DCD 5893
	DCD 5871
	DCD 5847
	DCD 5823
	DCD 5809
	DCD 5796
	DCD 5781
	DCD 5771
	DCD 5763
	DCD 5752
	DCD 4754
	DCD 4654
	DCD 4631
	DCD 3934
	DCD 3873
	DCD 3477
	DCD 3095
	DCD 2758
	DCD 2502
	DCD 2257
	DCD 2054
	DCD 1869
	DCD 1715
	DCD 1599
	DCD 1431
	DCD 1305
	DCD 1174
	DCD 1059
	DCD 983
	DCD 901
	DCD 839
	DCD 777
	DCD 733
	DCD 683
	DCD 658
	DCD 606
	DCD 565
	DCD 526
	DCD 488
	DCD 456
	DCD 434
	DCD 408
	DCD 380
	DCD 361
	DCD 327
	DCD 310
	DCD 296
	DCD 267
	DCD 259
	DCD 249
	DCD 239
	DCD 230
	DCD 221
	DCD 214
	DCD 0
cumf_TCOEF2_intra
	DCD 16383
	DCD 13242
	DCD 11417
	DCD 10134
	DCD 9254
	DCD 8507
	DCD 8012
	DCD 7556
	DCD 7273
	DCD 7062
	DCD 6924
	DCD 6839
	DCD 6741
	DCD 6108
	DCD 5851
	DCD 5785
	DCD 5719
	DCD 5687
	DCD 5655
	DCD 5028
	DCD 4917
	DCD 4864
	DCD 4845
	DCD 4416
	DCD 4159
	DCD 4074
	DCD 3903
	DCD 3871
	DCD 3870
	DCD 3765
	DCD 3752
	DCD 3751
	DCD 3659
	DCD 3606
	DCD 3580
	DCD 3541
	DCD 3540
	DCD 3514
	DCD 3495
	DCD 3494
	DCD 3493
	DCD 3474
	DCD 3473
	DCD 3441
	DCD 3440
	DCD 3439
	DCD 3438
	DCD 3425
	DCD 3424
	DCD 3423
	DCD 3422
	DCD 3421
	DCD 3420
	DCD 3401
	DCD 3400
	DCD 3399
	DCD 3398
	DCD 3397
	DCD 3396
	DCD 2530
	DCD 2419
	DCD 2360
	DCD 2241
	DCD 2228
	DCD 2017
	DCD 1687
	DCD 1576
	DCD 1478
	DCD 1320
	DCD 1281
	DCD 1242
	DCD 1229
	DCD 1197
	DCD 1178
	DCD 1152
	DCD 1133
	DCD 1114
	DCD 1101
	DCD 1088
	DCD 1087
	DCD 1086
	DCD 1085
	DCD 1072
	DCD 1071
	DCD 1070
	DCD 1069
	DCD 1068
	DCD 1067
	DCD 1066
	DCD 1065
	DCD 1064
	DCD 1063
	DCD 1062
	DCD 1061
	DCD 1060
	DCD 1059
	DCD 1058
	DCD 1057
	DCD 1056
	DCD 1055
	DCD 1054
	DCD 1053
	DCD 1052
	DCD 0
cumf_TCOEF3
	DCD 16383
	DCD 13532
	DCD 12677
	DCD 12342
	DCD 12195
	DCD 12112
	DCD 12059
	DCD 12034
	DCD 12020
	DCD 12008
	DCD 12003
	DCD 12002
	DCD 12001
	DCD 10586
	DCD 10297
	DCD 10224
	DCD 10202
	DCD 10195
	DCD 10191
	DCD 9223
	DCD 9046
	DCD 8999
	DCD 8987
	DCD 8275
	DCD 8148
	DCD 8113
	DCD 7552
	DCD 7483
	DCD 7468
	DCD 7066
	DCD 7003
	DCD 6989
	DCD 6671
	DCD 6642
	DCD 6631
	DCD 6359
	DCD 6327
	DCD 6114
	DCD 6103
	DCD 5929
	DCD 5918
	DCD 5792
	DCD 5785
	DCD 5672
	DCD 5580
	DCD 5507
	DCD 5461
	DCD 5414
	DCD 5382
	DCD 5354
	DCD 5330
	DCD 5312
	DCD 5288
	DCD 5273
	DCD 5261
	DCD 5247
	DCD 5235
	DCD 5227
	DCD 5219
	DCD 4357
	DCD 4277
	DCD 4272
	DCD 3847
	DCD 3819
	DCD 3455
	DCD 3119
	DCD 2829
	DCD 2550
	DCD 2313
	DCD 2104
	DCD 1881
	DCD 1711
	DCD 1565
	DCD 1366
	DCD 1219
	DCD 1068
	DCD 932
	DCD 866
	DCD 799
	DCD 750
	DCD 701
	DCD 662
	DCD 605
	DCD 559
	DCD 513
	DCD 471
	DCD 432
	DCD 403
	DCD 365
	DCD 336
	DCD 312
	DCD 290
	DCD 276
	DCD 266
	DCD 254
	DCD 240
	DCD 228
	DCD 223
	DCD 216
	DCD 206
	DCD 199
	DCD 192
	DCD 189
	DCD 0
cumf_TCOEF3_intra
	DCD 16383
	DCD 12741
	DCD 10950
	DCD 10071
	DCD 9493
	DCD 9008
	DCD 8685
	DCD 8516
	DCD 8385
	DCD 8239
	DCD 8209
	DCD 8179
	DCD 8141
	DCD 6628
	DCD 5980
	DCD 5634
	DCD 5503
	DCD 5396
	DCD 5327
	DCD 4857
	DCD 4642
	DCD 4550
	DCD 4481
	DCD 4235
	DCD 4166
	DCD 4151
	DCD 3967
	DCD 3922
	DCD 3907
	DCD 3676
	DCD 3500
	DCD 3324
	DCD 3247
	DCD 3246
	DCD 3245
	DCD 3183
	DCD 3168
	DCD 3084
	DCD 3069
	DCD 3031
	DCD 3030
	DCD 3029
	DCD 3014
	DCD 3013
	DCD 2990
	DCD 2975
	DCD 2974
	DCD 2973
	DCD 2958
	DCD 2943
	DCD 2928
	DCD 2927
	DCD 2926
	DCD 2925
	DCD 2924
	DCD 2923
	DCD 2922
	DCD 2921
	DCD 2920
	DCD 2397
	DCD 2298
	DCD 2283
	DCD 1891
	DCD 1799
	DCD 1591
	DCD 1445
	DCD 1338
	DCD 1145
	DCD 1068
	DCD 1006
	DCD 791
	DCD 768
	DCD 661
	DCD 631
	DCD 630
	DCD 615
	DCD 592
	DCD 577
	DCD 576
	DCD 561
	DCD 546
	DCD 523
	DCD 508
	DCD 493
	DCD 492
	DCD 491
	DCD 476
	DCD 475
	DCD 474
	DCD 473
	DCD 472
	DCD 471
	DCD 470
	DCD 469
	DCD 468
	DCD 453
	DCD 452
	DCD 451
	DCD 450
	DCD 449
	DCD 448
	DCD 447
	DCD 446
	DCD 0
cumf_LEVEL_intra
	DCD	16383
	DCD	16379
	DCD	16378
	DCD	16377
	DCD	16376
	DCD	16375
	DCD	16374
	DCD	16373
	DCD	16372
	DCD	16371
	DCD	16370
	DCD	16369
	DCD	16368
	DCD	16367
	DCD	16366
	DCD	16365
	DCD	16364
	DCD	16363
	DCD	16362
	DCD	16361
	DCD	16360
	DCD	16359
	DCD	16358
	DCD	16357
	DCD	16356
	DCD	16355
	DCD	16354
	DCD	16353
	DCD	16352
	DCD	16351
	DCD	16350
	DCD	16349
	DCD	16348
	DCD	16347
	DCD	16346
	DCD	16345
	DCD	16344
	DCD	16343
	DCD	16342
	DCD	16341
	DCD	16340
	DCD	16339
	DCD	16338
	DCD	16337
	DCD	16336
	DCD	16335
	DCD	16334
	DCD	16333
	DCD	16332
	DCD	16331
	DCD	16330
	DCD	16329
	DCD	16328
	DCD	16327
	DCD	16326
	DCD	16325
	DCD	16324
	DCD	16323
	DCD	16322
	DCD	16321
	DCD	16320
	DCD	16319
	DCD	16318
	DCD	16317
	DCD	16316
	DCD	16315
	DCD	16314
	DCD	16313
	DCD	16312
	DCD	16311
	DCD	16268
	DCD	16267
	DCD	16224
	DCD	16223
	DCD	16180
	DCD	16179
	DCD	16136
	DCD	16135
	DCD	16134
	DCD	16133
	DCD	16132
	DCD	16131
	DCD	16130
	DCD	16129
	DCD	16128
	DCD	16127
	DCD	16126
	DCD	16061
	DCD	16018
	DCD	16017
	DCD	16016
	DCD	16015
	DCD	16014
	DCD	15971
	DCD	15970
	DCD	15969
	DCD	15968
	DCD	15925
	DCD	15837
	DCD	15794
	DCD	15751
	DCD	15750
	DCD	15749
	DCD	15661
	DCD	15618
	DCD	15508
	DCD	15376
	DCD	15288
	DCD	15045
	DCD	14913
	DCD	14781
	DCD	14384
	DCD	13965
	DCD	13502
	DCD	13083
	DCD	12509
	DCD	12289
	DCD	12135
	DCD	11892
	DCD	11738
	DCD	11429
	DCD	11010
	DCD	10812
	DCD	10371
	DCD	9664
	DCD	9113
	DCD	8117
	DCD	8116
	DCD	8028
	DCD	6855
	DCD	5883
	DCD	4710
	DCD	4401
	DCD	4203
	DCD	3740
	DCD	3453
	DCD	3343
	DCD	3189
	DCD	2946
	DCD	2881
	DCD	2661
	DCD	2352
	DCD	2132
	DCD	1867
	DCD	1558
	DCD	1382
	DCD	1250
	DCD	1162
	DCD	1097
	DCD	1032
	DCD	967
	DCD	835
	DCD	681
	DCD	549
	DCD	439
	DCD	351
	DCD	350
	DCD	307
	DCD	306
	DCD	305
	DCD	304
	DCD	303
	DCD	302
	DCD	301
	DCD	300
	DCD	299
	DCD	298
	DCD	255
	DCD	212
	DCD	211
	DCD	210
	DCD	167
	DCD	166
	DCD	165
	DCD	164
	DCD	163
	DCD	162
	DCD	161
	DCD	160
	DCD	159
	DCD	158
	DCD	115
	DCD	114
	DCD	113
	DCD	112
	DCD	111
	DCD	68
	DCD	67
	DCD	66
	DCD	65
	DCD	64
	DCD	63
	DCD	62
	DCD	61
	DCD	60
	DCD	59
	DCD	58
	DCD	57
	DCD	56
	DCD	55
	DCD	54
	DCD	53
	DCD	52
	DCD	51
	DCD	50
	DCD	49
	DCD	48
	DCD	47
	DCD	46
	DCD	45
	DCD	44
	DCD	43
	DCD	42
	DCD	41
	DCD	40
	DCD	39
	DCD	38
	DCD	37
	DCD	36
	DCD	35
	DCD	34
	DCD	33
	DCD	32
	DCD	31
	DCD	30
	DCD	29
	DCD	28
	DCD	27
	DCD	26
	DCD	25
	DCD	24
	DCD	23
	DCD	22
	DCD	21
	DCD	20
	DCD	19
	DCD	18
	DCD	17
	DCD	16
	DCD	15
	DCD	14
	DCD	13
	DCD	12
	DCD	11
	DCD	10
	DCD	9
	DCD	8
	DCD	7
	DCD	6
	DCD	5
	DCD	4
	DCD	3
	DCD	2
	DCD	1
	DCD	0

gsb_escape
	TST	r7,#1
	ADRNE	r0,cumf_LAST_intra
	ADREQ	r0,cumf_LAST
	MOV	r1,#3
	BL	decode_a_symbol
      [ {CONFIG} <> 26
        ; decode_a_symbol now corrupts flags
        TST     r7,#1
      ]
	MOV	r11,r0			; r11 = last
	ADRNE	r0,cumf_RUN_intra
	ADREQ	r0,cumf_RUN
	MOV	r1,#65
	BL	decode_a_symbol
      [ {CONFIG} <> 26
        ; decode_a_symbol now corrupts flags
        TST     r7,#1
      ]
	ADD	r4,r4,r0
	ADRNEL	r0,cumf_LEVEL_intra
	ADREQ	r0,cumf_LEVEL
	MOV	r1,#255
	BL	decode_a_symbol
	SUBS	r2,r0,#126
	RSBLE	r2,r2,#1
	MOVLE	r0,#1
	MOVGT	r0,#0
        ; r0 = sign
        ; r1 = last
	; r2 = val
        ; r3 = run
	MOV	r1,r11
        B	gsb_escaperet
cumf_LAST
	DCD	16383
	DCD	9469
	DCD	0
cumf_LAST_intra
	DCD	16383
	DCD	2820
	DCD	0

cumf_RUN
	DCD	16383
	DCD	15310
	DCD	14702
	DCD	13022
	DCD	11883
	DCD	11234
	DCD	10612
	DCD	10192
	DCD	9516
	DCD	9016
	DCD	8623
	DCD	8366
	DCD	7595
	DCD	7068
	DCD	6730
	DCD	6487
	DCD	6379
	DCD	6285
	DCD	6177
	DCD	6150
	DCD	6083
	DCD	5989
	DCD	5949
	DCD	5922
	DCD	5895
	DCD	5828
	DCD	5774
	DCD	5773
	DCD	5394
	DCD	5164
	DCD	5016
	DCD	4569
	DCD	4366
	DCD	4136
	DCD	4015
	DCD	3867
	DCD	3773
	DCD	3692
	DCD	3611
	DCD	3476
	DCD	3341
	DCD	3301
	DCD	2787
	DCD	2503
	DCD	2219
	DCD	1989
	DCD	1515
	DCD	1095
	DCD	934
	DCD	799
	DCD	691
	DCD	583
	DCD	435
	DCD	300
	DCD	246
	DCD	206
	DCD	125
	DCD	124
	DCD	97
	DCD	57
	DCD	30
	DCD	3
	DCD	2
	DCD	1
	DCD	0

cumf_RUN_intra
	DCD	16383
	DCD	10884
	DCD	8242
	DCD	7124
	DCD	5173
	DCD	4745
	DCD	4246
	DCD	3984
	DCD	3034
	DCD	2749
	DCD	2607
	DCD	2298
	DCD	966
	DCD	681
	DCD	396
	DCD	349
	DCD	302
	DCD	255
	DCD	254
	DCD	253
	DCD	206
	DCD	159
	DCD	158
	DCD	157
	DCD	156
	DCD	155
	DCD	154
	DCD	153
	DCD	106
	DCD	35
	DCD	34
	DCD	33
	DCD	32
	DCD	31
	DCD	30
	DCD	29
	DCD	28
	DCD	27
	DCD	26
	DCD	25
	DCD	24
	DCD	23
	DCD	22
	DCD	21
	DCD	20
	DCD	19
	DCD	18
	DCD	17
	DCD	16
	DCD	15
	DCD	14
	DCD	13
	DCD	12
	DCD	11
	DCD	10
	DCD	9
	DCD	8
	DCD	7
	DCD	6
	DCD	5
	DCD	4
	DCD	3
	DCD	2
	DCD	1
	DCD	0

cumf_LEVEL
	DCD	16383
	DCD	16382
	DCD	16381
	DCD	16380
	DCD	16379
	DCD	16378
	DCD	16377
	DCD	16376
	DCD	16375
	DCD	16374
	DCD	16373
	DCD	16372
	DCD	16371
	DCD	16370
	DCD	16369
	DCD	16368
	DCD	16367
	DCD	16366
	DCD	16365
	DCD	16364
	DCD	16363
	DCD	16362
	DCD	16361
	DCD	16360
	DCD	16359
	DCD	16358
	DCD	16357
	DCD	16356
	DCD	16355
	DCD	16354
	DCD	16353
	DCD	16352
	DCD	16351
	DCD	16350
	DCD	16349
	DCD	16348
	DCD	16347
	DCD	16346
	DCD	16345
	DCD	16344
	DCD	16343
	DCD	16342
	DCD	16341
	DCD	16340
	DCD	16339
	DCD	16338
	DCD	16337
	DCD	16336
	DCD	16335
	DCD	16334
	DCD	16333
	DCD	16332
	DCD	16331
	DCD	16330
	DCD	16329
	DCD	16328
	DCD	16327
	DCD	16326
	DCD	16325
	DCD	16324
	DCD	16323
	DCD	16322
	DCD	16321
	DCD	16320
	DCD	16319
	DCD	16318
	DCD	16317
	DCD	16316
	DCD	16315
	DCD	16314
	DCD	16313
	DCD	16312
	DCD	16311
	DCD	16310
	DCD	16309
	DCD	16308
	DCD	16307
	DCD	16306
	DCD	16305
	DCD	16304
	DCD	16303
	DCD	16302
	DCD	16301
	DCD	16300
	DCD	16299
	DCD	16298
	DCD	16297
	DCD	16296
	DCD	16295
	DCD	16294
	DCD	16293
	DCD	16292
	DCD	16291
	DCD	16290
	DCD	16289
	DCD	16288
	DCD	16287
	DCD	16286
	DCD	16285
	DCD	16284
	DCD	16283
	DCD	16282
	DCD	16281
	DCD	16280
	DCD	16279
	DCD	16278
	DCD	16277
	DCD	16250
	DCD	16223
	DCD	16222
	DCD	16195
	DCD	16154
	DCD	16153
	DCD	16071
	DCD	15989
	DCD	15880
	DCD	15879
	DCD	15878
	DCD	15824
	DCD	15756
	DCD	15674
	DCD	15606
	DCD	15538
	DCD	15184
	DCD	14572
	DCD	13960
	DCD	10718
	DCD	7994
	DCD	5379
	DCD	2123
	DCD	1537
	DCD	992
	DCD	693
	DCD	611
	DCD	516
	DCD	448
	DCD	421
	DCD	380
	DCD	353
	DCD	352
	DCD	284
	DCD	257
	DCD	230
	DCD	203
	DCD	162
	DCD	161
	DCD	160
	DCD	133
	DCD	132
	DCD	105
	DCD	104
	DCD	103
	DCD	102
	DCD	101
	DCD	100
	DCD	99
	DCD	98
	DCD	97
	DCD	96
	DCD	95
	DCD	94
	DCD	93
	DCD	92
	DCD	91
	DCD	90
	DCD	89
	DCD	88
	DCD	87
	DCD	86
	DCD	85
	DCD	84
	DCD	83
	DCD	82
	DCD	81
	DCD	80
	DCD	79
	DCD	78
	DCD	77
	DCD	76
	DCD	75
	DCD	74
	DCD	73
	DCD	72
	DCD	71
	DCD	70
	DCD	69
	DCD	68
	DCD	67
	DCD	66
	DCD	65
	DCD	64
	DCD	63
	DCD	62
	DCD	61
	DCD	60
	DCD	59
	DCD	58
	DCD	57
	DCD	56
	DCD	55
	DCD	54
	DCD	53
	DCD	52
	DCD	51
	DCD	50
	DCD	49
	DCD	48
	DCD	47
	DCD	46
	DCD	45
	DCD	44
	DCD	43
	DCD	42
	DCD	41
	DCD	40
	DCD	39
	DCD	38
	DCD	37
	DCD	36
	DCD	35
	DCD	34
	DCD	33
	DCD	32
	DCD	31
	DCD	30
	DCD	29
	DCD	28
	DCD	27
	DCD	26
	DCD	25
	DCD	24
	DCD	23
	DCD	22
	DCD	21
	DCD	20
	DCD	19
	DCD	18
	DCD	17
	DCD	16
	DCD	15
	DCD	14
	DCD	13
	DCD	12
	DCD	11
	DCD	10
	DCD	9
	DCD	8
	DCD	7
	DCD	6
	DCD	5
	DCD	4
	DCD	3
	DCD	2
	DCD	1
	DCD	0

	END
